{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"The geneXplain platform The geneXplain platform provides a comprehensive environment to analyze biomedical and biological data. Its functionality includes, among other things, data storage, data management, data sharing, running bioinformatics and systems biology analysis tools, building and running analysis pipelines and workflows, building and visualizing molecular network models, or developing quantitative models and simulation. More details about the platform can be found here and in corresponding research articles . Interfaces of the geneXplain platform The platform can be used through a graphical web interface or through APIs that have been implemented in the languages Java and R . Besides being integrated as a software library, the genexplain-api package provides several commandline utilities. The exec tool allows to configure and run remote analyses using JSON input files. The JSON interface is described in detail in the genexplain-api documentation . The following figure sketches some of the tasks that can be carried out with the platform APIs. All analysis and utility tools provided by the geneXplain platform as well as integrated Galaxy tools and workflows can be executed using API functions. In addition, there are methods to manage, organize and download research data and analysis results. Notably, analysis jobs can run asynchronously so that one is not required to wait for long analysis tasks. Figure 1. Overview of API tasks that can be carried out on a remote platform server. This tutorial The goal of this tutorial is to demonstrate how to carry out analyses on the geneXplain platform using the programming and commandline interfaces. For those who would like to firstly see an example analysis, a quick start is provided here . Platform version The exercises shown in this tutorial use geneXplain platform version 7.0 . Prerequisites for tutorial exercises A user account for the genexplain platform. This can be obtained here . For parts requiring the Java API: Java JDK version 8 For parts requiring geneXplainR: R version \u2265 3.3 For parts that depend on analysis of transcription factor binding sites: a TRANSFAC\u00ae license. This can be obtained here . For parts that depend on information from HumanPSD TM : a HumanPSD TM license. This can be obtained here . An API package, Java or R. Please see below how to obtain them. We recommend obtaining the Java API package even if a user prefers R as the programming language, because the Java package provides a few additional utilities. Obtaining the APIs The genexplain-api and geneXplainR projects are available at GitHub . Hence, there are easy ways to download the Git projects either as ZIP archives from respective GitHub sites ( here and here ) or by cloning them using the Git clone tool in a console as shown below. 1 2 3 4 5 # Cloning the Java API project into a destination directory named 'genexplain-api' git clone https://github.com/genexplain/genexplain-api.git # Cloning geneXplainR into a destination directory named 'geneXplainR' git clone https://github.com/genexplain/geneXplainR.git Building the Java API JAR After obtaining the genexplain-api source tree, the JAR is created using the Gradle build tool . 1 2 cd genexplain-api gradle build The Gradle script creates the JAR file genexplain-api-1.0.jar in the build/libs subfolder. Installing geneXplainR The geneXplainR package can be installed from its GitHub repository using the install_github function of the devtools package . 1 2 3 # R commands to install geneXplainR library ( devtools ) install_github ( \"genexplain/geneXplainR\" )","title":"Introduction"},{"location":"index.html#the-genexplain-platform","text":"The geneXplain platform provides a comprehensive environment to analyze biomedical and biological data. Its functionality includes, among other things, data storage, data management, data sharing, running bioinformatics and systems biology analysis tools, building and running analysis pipelines and workflows, building and visualizing molecular network models, or developing quantitative models and simulation. More details about the platform can be found here and in corresponding research articles .","title":"The geneXplain platform"},{"location":"index.html#interfaces-of-the-genexplain-platform","text":"The platform can be used through a graphical web interface or through APIs that have been implemented in the languages Java and R . Besides being integrated as a software library, the genexplain-api package provides several commandline utilities. The exec tool allows to configure and run remote analyses using JSON input files. The JSON interface is described in detail in the genexplain-api documentation . The following figure sketches some of the tasks that can be carried out with the platform APIs. All analysis and utility tools provided by the geneXplain platform as well as integrated Galaxy tools and workflows can be executed using API functions. In addition, there are methods to manage, organize and download research data and analysis results. Notably, analysis jobs can run asynchronously so that one is not required to wait for long analysis tasks. Figure 1. Overview of API tasks that can be carried out on a remote platform server.","title":"Interfaces of the geneXplain platform"},{"location":"index.html#this-tutorial","text":"The goal of this tutorial is to demonstrate how to carry out analyses on the geneXplain platform using the programming and commandline interfaces. For those who would like to firstly see an example analysis, a quick start is provided here .","title":"This tutorial"},{"location":"index.html#platform-version","text":"The exercises shown in this tutorial use geneXplain platform version 7.0 .","title":"Platform version"},{"location":"index.html#prerequisites-for-tutorial-exercises","text":"A user account for the genexplain platform. This can be obtained here . For parts requiring the Java API: Java JDK version 8 For parts requiring geneXplainR: R version \u2265 3.3 For parts that depend on analysis of transcription factor binding sites: a TRANSFAC\u00ae license. This can be obtained here . For parts that depend on information from HumanPSD TM : a HumanPSD TM license. This can be obtained here . An API package, Java or R. Please see below how to obtain them. We recommend obtaining the Java API package even if a user prefers R as the programming language, because the Java package provides a few additional utilities.","title":"Prerequisites for tutorial exercises"},{"location":"index.html#obtaining-the-apis","text":"The genexplain-api and geneXplainR projects are available at GitHub . Hence, there are easy ways to download the Git projects either as ZIP archives from respective GitHub sites ( here and here ) or by cloning them using the Git clone tool in a console as shown below. 1 2 3 4 5 # Cloning the Java API project into a destination directory named 'genexplain-api' git clone https://github.com/genexplain/genexplain-api.git # Cloning geneXplainR into a destination directory named 'geneXplainR' git clone https://github.com/genexplain/geneXplainR.git","title":"Obtaining the APIs"},{"location":"index.html#building-the-java-api-jar","text":"After obtaining the genexplain-api source tree, the JAR is created using the Gradle build tool . 1 2 cd genexplain-api gradle build The Gradle script creates the JAR file genexplain-api-1.0.jar in the build/libs subfolder.","title":"Building the Java API JAR"},{"location":"index.html#installing-genexplainr","text":"The geneXplainR package can be installed from its GitHub repository using the install_github function of the devtools package . 1 2 3 # R commands to install geneXplainR library ( devtools ) install_github ( \"genexplain/geneXplainR\" )","title":"Installing geneXplainR"},{"location":"api_overview.html","text":"Overview of R, Java and JSON interfaces Main API methods The programming and JSON interfaces provide a common set of functionality to carry out data management and analysis tasks. The following table gives an overview of available functions. Methods in R, Java APIs and JSON interface geneXplainR genexplain-api Java method JSON executor Description gx.analysis GxHttpClient.analyze ( isWorkflow: false ) analyze ( workflow: false ) Runs a platform analysis method with specified parameters gx.analysis.list GxHttpClient.listApplications apps, listItems ( type applications ) Lists available platform tools gx.analysis.parameters GxHttpClient.getAnalysisParameters itemParameters ( type application ) Lists parameters for a platform tool gx.createFolder GxHttpClient.createFolder createFolder Creates a folder in the platform workspace gx.createProject GxHttpClient.createProject Creates a project in the platform workspace gx.delete GxHttpClient.deleteElement Deletes specified folder or data item gx.export GxHttpClient.export export Exports data using a dedicated exporter gx.export.parameters GxHttpClient.getExporterParameters exporter (with specified exporter ), itemParameters ( type exporter ) Lists parameters for an exporter and the export item gx.exporters GxHttpClient.listExporters exporter, listItems ( type exporters ) Lists available exporters gx.get GxHttpClient.getTable get Gets specified table item gx.import GxHttpClient.imPort imPort Imports a data file using a dedicated importer gx.import.parameters GxHttpClient.getImporterParameters importer (with specified importer ), itemParameters ( type importer ) Lists parameters for an importer and the import folder gx.importers GxHttpClient.listImporters importer, listItems ( type importers ) Lists available importers gx.isElement GxHttpClient.existsElement Checks whether a workspace element exists given its platform path gx.job.info GxHttpClient.getJobStatus jobStatus Gets the status for a job id gx.login GxHttpConnection.login Signs into a platform account to start a session gx.logout GxHttpConnection.logout Signs out of a platform account to end a session gx.ls GxHttpClient.list Lists contents of a platform folder gx.put GxHttpClient.putTable put Uploads a data table into specified folder gx.workflow GxHttpClient.analyze ( isWorkflow: true ) analyze ( workflow: true ) Runs a platform workflow geneXplainR-specific functions The following functions were specifically implemented in the geneXplainR package. Function Description gx.classifyChipSeqTargets Runs the workflow ChIP-Seq - Identify and classify target genes (TRANSPATH(R)) gx.ebarraysWorkflow Runs the workflow Compute differentially expressed genes using EBarrays gx.enrichedTFBSGenes Runs the workflow Identify enriched motifs in promoters (TRANSFAC(R)) gx.enrichedUpstreamAnalysis Runs the workflow Enriched upstream analysis (TRANSFAC(R) and TRANSPATH(R)) gx.explainMyGenes Runs the workflow Explain my genes gx.importBedFile Imports a BED file into the platform workspace gx.importTable Imports a data table into the platform workspace gx.limmaWorkflow Computes differentially expressed genes between all condition pairs using Limma gx.mapGenesToOntologies Runs the workflow Mapping to ontologies (Gene table) gx.searchRegulators Searches for signal transduction regulators of input proteins gx.trackToGeneSet Maps one or more tracks to genes of the most recent Ensembl release gx.upstreamAnalysisTransfacGeneWays Runs the workflow Upstream analysis (TRANSFAC(R) and GeneWays) gx.upstreamAnalysisTransfacTranspath Runs the workflow Upstream analysis (TRANSFAC(R) and TRANSPATH(R)) gx.vennDiagrams Creates a Venn diagram for up to three tables genexplain-api-specific Java method The Java API provides the method com.genexplain.api.core.GxHttpClient.importTable to conveniently upload a data table into the platform workspace. Commandline applications of genexplain-api Contents of this section can also be found in the genexplain-api documentation . To focus on general utilities, this presentation does not cover the example and regulator-search applications which are described here and here . apps - Listing available tools The application apps produces a listing of the available analysis tools on a certain server. It takes a single argument that specifies a file containing a JSON object with several properties of which only the server property is required. Example output: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 genexplain-api$ java -jar build/libs/genexplain-api-1.0.jar apps input.json INFO com.genexplain.api.app.APIRunner - Running command apps Data manipulation/Annotate diagram Data manipulation/Annotate table Data manipulation/Annotate track with genes Data manipulation/Composite module to proteins Data manipulation/Convert table Data manipulation/Convert table to track Data manipulation/Convert table via homology Data manipulation/Create folder Data manipulation/Create miRNA promoters Data manipulation/Create random track Data manipulation/Create tissue-specific promoter track Data manipulation/Create transcript region track Data manipulation/Filter one track by another Data manipulation/Filter table Data manipulation/Filter track by condition Data manipulation/Gene set to track [ ... ] The parameters that can be specified with the JSON input file are described in the following table. Parameter Description server Server URL to connect to user Username to use for connection password Password that belongs to the username withParameters If true will produce tsv-table of tools and their parameters withGalaxy If true will also include tools integrated from Galaxy outfile Output file. Prints to standard output if outfile is absent or empty connection Package and name to locate a Java class to use for connection. This class must implement com.genexplain.api.core.GxHttpConnection . client Package and name to locate a Java class to use as platform client. This class must implement com.genexplain.api.core.GxHttpClient . parameters - Parameter descriptions for platform and Galaxy tools The parameters application fetches parameter descriptions in JSON format for one or more tools from a platform server. It takes a single argument that specifies a file containing a JSON object with several properties of which only the server property is required. The output is a JSON object containing the tool names as keys as the retrieved parameter descriptions as values. Parameter Description server Server URL to connect to user Username to use for connection password Password that belongs to the username tools JSON array with tool names outfile Output file. Prints to standard output is outfile is absent or empty connection Package and name to locate a Java class to use for connection. This class must implement com.genexplain.api.core.GxHttpConnection . client Package and name to locate a Java class to use as platform client. This class must implement com.genexplain.api.core.GxHttpClient . importer and exporter - Descriptions of data importers, exporters and their parameters The importer and exporter tools present lists of available data importers or exporters or parameters for specified importer/exporter types. If provided with the path as well as importer or exporter names, the platform parameters for the specified type on given path are extracted. Otherwise (one of the parameters missing or empty) the list of available importers and exporters is printed to standard output or, if an outfile is specified, to an output file. Parameter Description server Server URL to connect to user Username to use for connection password Password that belongs to the username path Platform path. Exporters: the item to export, Importers: the path (usually a data folder) to import to importer/exporter Name of the importer/exporter to get parameters for outfile Output file. Prints to standard output is outfile is absent or empty connection Package and name to locate a Java class to use for connection. This class must implement com.genexplain.api.core.GxHttpConnection . client Package and name to locate a Java class to use as platform client. This class must implement com.genexplain.api.core.GxHttpClient . exec - Executing tasks using the JSON interface The exec application provides a rich interface to interact with platform servers using JSON documents to configure tasks. It is possible to create complex workflows including re-usable workflow templates, loops and conditional branch points. The Hello world-tutorial demonstrates several ways of how to make use of this interface. The exec interface provides a set of executor functions that can be invoked within a task list. The available executors are described in detail below. Parameter Description server Server URL to connect to user Username to use for connection password Password that belongs to the username verbose Set true get more progress info reconnect Set true to allow attempts to reconnect in case the connection is interrupted connection-class Package and name of a Java class that implements com.genexplain.api.core.GxHttpConnection and will be used instead of the standard class client-class Package and name of a Java class that implements com.genexplain.api.core.GxHttpClient and will be used instead of the standard class credentials A file containing a JSON object with user and password properties withoutConnect Set true to execute tasks without connecting to a platform server replaceStrings A JSON array of two-element arrays defining string replacements loadTasks A JSON object of task templates or an array of file paths containing task template definitions nextTask A JSON object or array of the next task to perform Main executors The following table describes available executors. Most of them correspond to public methods of the Java API , but some are only provided by the JSON interface, e.g. branch or external . Each executor and its JSON configuration is described in more detail in the following sections. Their usage is also demonstrated by several examples. Name Description analyze Calls the analysis method with specified parameters branch Executes a branch point createFolder Creates a folder export Export data using a dedicated exporter external Runs an external tool get Gets specified table imPort Import a data file using a dedicated importer itemParameters Lists parameters for specified application, importer, or exporter jobStatus Gets the status for a job id listItems Lists available application, importer, or exporter items list Lists contents of specified folder put Puts table into specified folder setParameters Sets/adds/removes parameter strings analyze The analyze executor runs an analysis tool or workflow on the remote server. method - Name of the platform tool or workflow, where orkflows are specified by their platform path. parameters - A JSON object with parameters of the analysis tool or workflow. workflow - Set true if the called method is a workflow. wait - Set true to wait for the analysis to finish. progress - Set true to obtain more progress information. 1 2 3 4 5 6 7 8 { \"do\" : \"analyze\" , \"method\" : \"name of tool or path to workflow\" , \"parameters\" : { }, \"workflow\" : false , \"wait\" : false , \"progress\" : false } branch Selects the next task or task set using a branch selector. branchSelector - The canonical name of the Java class that implements the executor. The JSON document can contain further properties that configure the selector. In addition, the JSON configuration that was used to invoke the exec application is handed to the selector. Please see example selector implementations in this source repository. 1 2 3 4 5 { \"do\" : \"branch\" , \"branchSelector\" : \"com.branch.selector.Class\" , \"other parameters\" : \"further properties used by the selector\" } createFolder path - Path of the parent folder. name - Name of the new folder. 1 2 3 4 5 { \"do\" : \"createFolder\" , \"path\" : \"platform path\" , \"name\" : \"name of new folder\" } export Exports an item from the platform workspace to a local file. file - Local file to create for the export. path - Path of the platform item to export. exporter - Name of the exporter to apply, e.g. Tab-separated text (*.txt) for a text table. parameters - Parameters to be specified to the exporter. 1 2 3 4 5 6 7 { \"do\" : \"export\" , \"file\" : \"local file path to store export\" , \"path\" : \"platform path to export\" , \"exporter\" : \"name of exporter\" , \"parameters\" : \"JsonObject with exporter parameters\" } external This executor invokes an external program, e.g. a C++ application or an R script. bin - The command to be executed. params - List of parameters to be specified to the external program. showOutput - Set true to get output of the external program printed to standard output. 1 2 3 4 5 6 { \"do\" : \"external\" , \"bin\" : \"command to execute\" , \"params\" : \"simple string or array of parameters to add to commandline\" , \"showOutput\" : \"set true to observe standard output of invoked tool\" } get Downloads a table from the platform workspace and optionally stores it in a local file and/or prints it to standard output. table - Platform path of the table to download. toFile - Path of file to which to write table. toStdout - Set true to get table printed on standard output. 1 2 3 4 5 6 { \"do\" : \"get\" , \"table\" : \"platform path of table to download\" , \"toFile\" : \"path of local file\" , \"toStdout\" : \"to print table object to standard output\" } imPort Imports a local file to the platform workspace. file - Local file to import. path - Platform path including the name of imported item. importer - The importer to apply, e.g. Tabular (*.txt, *.xls, *.tab, etc.) for tables. parameters - Parameters for the importer. 1 2 3 4 5 6 7 { \"do\" : \"imPort\" , \"file\" : \"local file to import\" , \"path\" : \"the designated import location in the platform\" , \"importer\" : \"name of importer\" , \"parameters\" : \"JsonObject with importer parameters\" } itemParameters This is a collectiv function that can get information about the available parameters for an analysis tool (application), exporter or importer. If the item is an exporter or importer, one needs to specify the corresponding target platform path to export or import. name - Item name which may be the name of an analysis tool, an exporter or an importer name. type - Type of item, one of application, exporter or importer. path - If the item is an exporter or importer, the corresponding platform path is required to determine possible context-dependent parameters. 1 2 3 4 5 6 { \"do\" : \"itemParameters\" , \"name\" : \"name of item for which to get parameters\" , \"type\" : \"type of item for which to get parameters: application, exporter, importer\" , \"path\" : \"if exporter or importer, path for which to get parameters in context with ex-/importer\" } jobStatus Returns the status of a running analysis job. jobId - Id of the job whose status is requested. toFile - Path of file to which to write output. toStdout - Set true to get output printed on standard output. 1 2 3 4 5 6 { \"do\" : \"jobStatus\" , \"jobId\" : \"id of platform job to request status\" , \"toFile\" : \"path of local file\" , \"toStdout\" : \"to print output to standard output\" } listItems Gets listings of available applications, importers or exporters. type - Type of items to list, one of application, exporter or importer. toFile - Path of file to which to write output. toStdout - Set true to get output printed on standard output. 1 2 3 4 5 6 { \"do\" : \"listItems\" , \"type\" : \"type of items to list: applications, importers, or exporters\" \"toFile\" : \"path of local file\" , \"toStdout\" : \"to print output to standard output\" } list Gets the listing of specified folder. folder - Platform folder to get listing for. toFile - Path of file to which to write output. toStdout - Set true to get output printed on standard output. 1 2 3 4 5 6 { \"do\" : \"list\" , \"folder\" : \"platform folder to get listing for\" \"toFile\" : \"path of local file\" , \"toStdout\" : \"to print output to standard output\" } put Uploads a table from specified local file into the platform workspace. file - Local file with data table to upload. skip - Number of lines to skip in the beginning of the file. delimiter - Column delimiter string. table - JSON array of arrays with data columns. Note that the table has no title row, but columns are specified separately. columns - Column definition by an array of two-element arrays giving column name and type, where type is one of Integer, Float, Boolean, or Text . path - Platform path to put table which includes the name of the table item in the platform workspace. 1 2 3 4 5 6 7 8 9 { \"do\" : \"put\" , \"file\" : \"file with data table to put into platform\" , \"skip\" : \"number of lines to skip in the beginning of input file\" , \"delimiter\" : \"delimiter of table columns in input file\" , \"table\" : \"array of arrays with data to put into platform\" , \"columns\" : \"array of two-element arrays specifying column names and type. The latter can be Integer, Float, Boolean, Text\" , \"path\" : \"destination path of table in platform\" } setParameters Sets/adds/removes string replacements in the parameter object that will modify parameters of subsequent tasks. set - a JSON object whose keys can be found in the replaceStrings array of the parameter object and whose value will replace the current one. remove - a JSON object whose keys will be removed from the replaceStrings array of the parameter object. before - an array of two-element arrays that are inserted in the beginning of the replaceStrings array. after - an array of two-element arrays that are appended to the replaceStrings array. 1 2 3 4 5 6 7 { \"do\" : \"setParameters\" , \"set\" : \"sets existing parameter to specified value\" , \"remove\" : \"removes existing parameter\" , \"before\" : \"add parameter before others in the parameter array\" , \"after\" : \"add parameter at the end of the parameter array\" }","title":"Overview of APIs"},{"location":"api_overview.html#overview-of-r-java-and-json-interfaces","text":"","title":"Overview of R, Java and JSON interfaces"},{"location":"api_overview.html#main-api-methods","text":"The programming and JSON interfaces provide a common set of functionality to carry out data management and analysis tasks. The following table gives an overview of available functions.","title":"Main API methods"},{"location":"api_overview.html#methods-in-r-java-apis-and-json-interface","text":"geneXplainR genexplain-api Java method JSON executor Description gx.analysis GxHttpClient.analyze ( isWorkflow: false ) analyze ( workflow: false ) Runs a platform analysis method with specified parameters gx.analysis.list GxHttpClient.listApplications apps, listItems ( type applications ) Lists available platform tools gx.analysis.parameters GxHttpClient.getAnalysisParameters itemParameters ( type application ) Lists parameters for a platform tool gx.createFolder GxHttpClient.createFolder createFolder Creates a folder in the platform workspace gx.createProject GxHttpClient.createProject Creates a project in the platform workspace gx.delete GxHttpClient.deleteElement Deletes specified folder or data item gx.export GxHttpClient.export export Exports data using a dedicated exporter gx.export.parameters GxHttpClient.getExporterParameters exporter (with specified exporter ), itemParameters ( type exporter ) Lists parameters for an exporter and the export item gx.exporters GxHttpClient.listExporters exporter, listItems ( type exporters ) Lists available exporters gx.get GxHttpClient.getTable get Gets specified table item gx.import GxHttpClient.imPort imPort Imports a data file using a dedicated importer gx.import.parameters GxHttpClient.getImporterParameters importer (with specified importer ), itemParameters ( type importer ) Lists parameters for an importer and the import folder gx.importers GxHttpClient.listImporters importer, listItems ( type importers ) Lists available importers gx.isElement GxHttpClient.existsElement Checks whether a workspace element exists given its platform path gx.job.info GxHttpClient.getJobStatus jobStatus Gets the status for a job id gx.login GxHttpConnection.login Signs into a platform account to start a session gx.logout GxHttpConnection.logout Signs out of a platform account to end a session gx.ls GxHttpClient.list Lists contents of a platform folder gx.put GxHttpClient.putTable put Uploads a data table into specified folder gx.workflow GxHttpClient.analyze ( isWorkflow: true ) analyze ( workflow: true ) Runs a platform workflow","title":"Methods in R, Java APIs and JSON interface"},{"location":"api_overview.html#genexplainr-specific-functions","text":"The following functions were specifically implemented in the geneXplainR package. Function Description gx.classifyChipSeqTargets Runs the workflow ChIP-Seq - Identify and classify target genes (TRANSPATH(R)) gx.ebarraysWorkflow Runs the workflow Compute differentially expressed genes using EBarrays gx.enrichedTFBSGenes Runs the workflow Identify enriched motifs in promoters (TRANSFAC(R)) gx.enrichedUpstreamAnalysis Runs the workflow Enriched upstream analysis (TRANSFAC(R) and TRANSPATH(R)) gx.explainMyGenes Runs the workflow Explain my genes gx.importBedFile Imports a BED file into the platform workspace gx.importTable Imports a data table into the platform workspace gx.limmaWorkflow Computes differentially expressed genes between all condition pairs using Limma gx.mapGenesToOntologies Runs the workflow Mapping to ontologies (Gene table) gx.searchRegulators Searches for signal transduction regulators of input proteins gx.trackToGeneSet Maps one or more tracks to genes of the most recent Ensembl release gx.upstreamAnalysisTransfacGeneWays Runs the workflow Upstream analysis (TRANSFAC(R) and GeneWays) gx.upstreamAnalysisTransfacTranspath Runs the workflow Upstream analysis (TRANSFAC(R) and TRANSPATH(R)) gx.vennDiagrams Creates a Venn diagram for up to three tables","title":"geneXplainR-specific functions"},{"location":"api_overview.html#genexplain-api-specific-java-method","text":"The Java API provides the method com.genexplain.api.core.GxHttpClient.importTable to conveniently upload a data table into the platform workspace.","title":"genexplain-api-specific Java method"},{"location":"api_overview.html#commandline-applications-of-genexplain-api","text":"Contents of this section can also be found in the genexplain-api documentation . To focus on general utilities, this presentation does not cover the example and regulator-search applications which are described here and here .","title":"Commandline applications of genexplain-api"},{"location":"api_overview.html#apps-listing-available-tools","text":"The application apps produces a listing of the available analysis tools on a certain server. It takes a single argument that specifies a file containing a JSON object with several properties of which only the server property is required. Example output: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 genexplain-api$ java -jar build/libs/genexplain-api-1.0.jar apps input.json INFO com.genexplain.api.app.APIRunner - Running command apps Data manipulation/Annotate diagram Data manipulation/Annotate table Data manipulation/Annotate track with genes Data manipulation/Composite module to proteins Data manipulation/Convert table Data manipulation/Convert table to track Data manipulation/Convert table via homology Data manipulation/Create folder Data manipulation/Create miRNA promoters Data manipulation/Create random track Data manipulation/Create tissue-specific promoter track Data manipulation/Create transcript region track Data manipulation/Filter one track by another Data manipulation/Filter table Data manipulation/Filter track by condition Data manipulation/Gene set to track [ ... ] The parameters that can be specified with the JSON input file are described in the following table. Parameter Description server Server URL to connect to user Username to use for connection password Password that belongs to the username withParameters If true will produce tsv-table of tools and their parameters withGalaxy If true will also include tools integrated from Galaxy outfile Output file. Prints to standard output if outfile is absent or empty connection Package and name to locate a Java class to use for connection. This class must implement com.genexplain.api.core.GxHttpConnection . client Package and name to locate a Java class to use as platform client. This class must implement com.genexplain.api.core.GxHttpClient .","title":"apps - Listing available tools"},{"location":"api_overview.html#parameters-parameter-descriptions-for-platform-and-galaxy-tools","text":"The parameters application fetches parameter descriptions in JSON format for one or more tools from a platform server. It takes a single argument that specifies a file containing a JSON object with several properties of which only the server property is required. The output is a JSON object containing the tool names as keys as the retrieved parameter descriptions as values. Parameter Description server Server URL to connect to user Username to use for connection password Password that belongs to the username tools JSON array with tool names outfile Output file. Prints to standard output is outfile is absent or empty connection Package and name to locate a Java class to use for connection. This class must implement com.genexplain.api.core.GxHttpConnection . client Package and name to locate a Java class to use as platform client. This class must implement com.genexplain.api.core.GxHttpClient .","title":"parameters - Parameter descriptions for platform and Galaxy tools"},{"location":"api_overview.html#importer-and-exporter-descriptions-of-data-importers-exporters-and-their-parameters","text":"The importer and exporter tools present lists of available data importers or exporters or parameters for specified importer/exporter types. If provided with the path as well as importer or exporter names, the platform parameters for the specified type on given path are extracted. Otherwise (one of the parameters missing or empty) the list of available importers and exporters is printed to standard output or, if an outfile is specified, to an output file. Parameter Description server Server URL to connect to user Username to use for connection password Password that belongs to the username path Platform path. Exporters: the item to export, Importers: the path (usually a data folder) to import to importer/exporter Name of the importer/exporter to get parameters for outfile Output file. Prints to standard output is outfile is absent or empty connection Package and name to locate a Java class to use for connection. This class must implement com.genexplain.api.core.GxHttpConnection . client Package and name to locate a Java class to use as platform client. This class must implement com.genexplain.api.core.GxHttpClient .","title":"importer and exporter - Descriptions of data importers, exporters and their parameters"},{"location":"api_overview.html#exec-executing-tasks-using-the-json-interface","text":"The exec application provides a rich interface to interact with platform servers using JSON documents to configure tasks. It is possible to create complex workflows including re-usable workflow templates, loops and conditional branch points. The Hello world-tutorial demonstrates several ways of how to make use of this interface. The exec interface provides a set of executor functions that can be invoked within a task list. The available executors are described in detail below. Parameter Description server Server URL to connect to user Username to use for connection password Password that belongs to the username verbose Set true get more progress info reconnect Set true to allow attempts to reconnect in case the connection is interrupted connection-class Package and name of a Java class that implements com.genexplain.api.core.GxHttpConnection and will be used instead of the standard class client-class Package and name of a Java class that implements com.genexplain.api.core.GxHttpClient and will be used instead of the standard class credentials A file containing a JSON object with user and password properties withoutConnect Set true to execute tasks without connecting to a platform server replaceStrings A JSON array of two-element arrays defining string replacements loadTasks A JSON object of task templates or an array of file paths containing task template definitions nextTask A JSON object or array of the next task to perform","title":"exec - Executing tasks using the JSON interface"},{"location":"api_overview.html#main-executors","text":"The following table describes available executors. Most of them correspond to public methods of the Java API , but some are only provided by the JSON interface, e.g. branch or external . Each executor and its JSON configuration is described in more detail in the following sections. Their usage is also demonstrated by several examples. Name Description analyze Calls the analysis method with specified parameters branch Executes a branch point createFolder Creates a folder export Export data using a dedicated exporter external Runs an external tool get Gets specified table imPort Import a data file using a dedicated importer itemParameters Lists parameters for specified application, importer, or exporter jobStatus Gets the status for a job id listItems Lists available application, importer, or exporter items list Lists contents of specified folder put Puts table into specified folder setParameters Sets/adds/removes parameter strings","title":"Main executors"},{"location":"api_overview.html#analyze","text":"The analyze executor runs an analysis tool or workflow on the remote server. method - Name of the platform tool or workflow, where orkflows are specified by their platform path. parameters - A JSON object with parameters of the analysis tool or workflow. workflow - Set true if the called method is a workflow. wait - Set true to wait for the analysis to finish. progress - Set true to obtain more progress information. 1 2 3 4 5 6 7 8 { \"do\" : \"analyze\" , \"method\" : \"name of tool or path to workflow\" , \"parameters\" : { }, \"workflow\" : false , \"wait\" : false , \"progress\" : false }","title":"analyze"},{"location":"api_overview.html#branch","text":"Selects the next task or task set using a branch selector. branchSelector - The canonical name of the Java class that implements the executor. The JSON document can contain further properties that configure the selector. In addition, the JSON configuration that was used to invoke the exec application is handed to the selector. Please see example selector implementations in this source repository. 1 2 3 4 5 { \"do\" : \"branch\" , \"branchSelector\" : \"com.branch.selector.Class\" , \"other parameters\" : \"further properties used by the selector\" }","title":"branch"},{"location":"api_overview.html#createfolder","text":"path - Path of the parent folder. name - Name of the new folder. 1 2 3 4 5 { \"do\" : \"createFolder\" , \"path\" : \"platform path\" , \"name\" : \"name of new folder\" }","title":"createFolder"},{"location":"api_overview.html#export","text":"Exports an item from the platform workspace to a local file. file - Local file to create for the export. path - Path of the platform item to export. exporter - Name of the exporter to apply, e.g. Tab-separated text (*.txt) for a text table. parameters - Parameters to be specified to the exporter. 1 2 3 4 5 6 7 { \"do\" : \"export\" , \"file\" : \"local file path to store export\" , \"path\" : \"platform path to export\" , \"exporter\" : \"name of exporter\" , \"parameters\" : \"JsonObject with exporter parameters\" }","title":"export"},{"location":"api_overview.html#external","text":"This executor invokes an external program, e.g. a C++ application or an R script. bin - The command to be executed. params - List of parameters to be specified to the external program. showOutput - Set true to get output of the external program printed to standard output. 1 2 3 4 5 6 { \"do\" : \"external\" , \"bin\" : \"command to execute\" , \"params\" : \"simple string or array of parameters to add to commandline\" , \"showOutput\" : \"set true to observe standard output of invoked tool\" }","title":"external"},{"location":"api_overview.html#get","text":"Downloads a table from the platform workspace and optionally stores it in a local file and/or prints it to standard output. table - Platform path of the table to download. toFile - Path of file to which to write table. toStdout - Set true to get table printed on standard output. 1 2 3 4 5 6 { \"do\" : \"get\" , \"table\" : \"platform path of table to download\" , \"toFile\" : \"path of local file\" , \"toStdout\" : \"to print table object to standard output\" }","title":"get"},{"location":"api_overview.html#import","text":"Imports a local file to the platform workspace. file - Local file to import. path - Platform path including the name of imported item. importer - The importer to apply, e.g. Tabular (*.txt, *.xls, *.tab, etc.) for tables. parameters - Parameters for the importer. 1 2 3 4 5 6 7 { \"do\" : \"imPort\" , \"file\" : \"local file to import\" , \"path\" : \"the designated import location in the platform\" , \"importer\" : \"name of importer\" , \"parameters\" : \"JsonObject with importer parameters\" }","title":"imPort"},{"location":"api_overview.html#itemparameters","text":"This is a collectiv function that can get information about the available parameters for an analysis tool (application), exporter or importer. If the item is an exporter or importer, one needs to specify the corresponding target platform path to export or import. name - Item name which may be the name of an analysis tool, an exporter or an importer name. type - Type of item, one of application, exporter or importer. path - If the item is an exporter or importer, the corresponding platform path is required to determine possible context-dependent parameters. 1 2 3 4 5 6 { \"do\" : \"itemParameters\" , \"name\" : \"name of item for which to get parameters\" , \"type\" : \"type of item for which to get parameters: application, exporter, importer\" , \"path\" : \"if exporter or importer, path for which to get parameters in context with ex-/importer\" }","title":"itemParameters"},{"location":"api_overview.html#jobstatus","text":"Returns the status of a running analysis job. jobId - Id of the job whose status is requested. toFile - Path of file to which to write output. toStdout - Set true to get output printed on standard output. 1 2 3 4 5 6 { \"do\" : \"jobStatus\" , \"jobId\" : \"id of platform job to request status\" , \"toFile\" : \"path of local file\" , \"toStdout\" : \"to print output to standard output\" }","title":"jobStatus"},{"location":"api_overview.html#listitems","text":"Gets listings of available applications, importers or exporters. type - Type of items to list, one of application, exporter or importer. toFile - Path of file to which to write output. toStdout - Set true to get output printed on standard output. 1 2 3 4 5 6 { \"do\" : \"listItems\" , \"type\" : \"type of items to list: applications, importers, or exporters\" \"toFile\" : \"path of local file\" , \"toStdout\" : \"to print output to standard output\" }","title":"listItems"},{"location":"api_overview.html#list","text":"Gets the listing of specified folder. folder - Platform folder to get listing for. toFile - Path of file to which to write output. toStdout - Set true to get output printed on standard output. 1 2 3 4 5 6 { \"do\" : \"list\" , \"folder\" : \"platform folder to get listing for\" \"toFile\" : \"path of local file\" , \"toStdout\" : \"to print output to standard output\" }","title":"list"},{"location":"api_overview.html#put","text":"Uploads a table from specified local file into the platform workspace. file - Local file with data table to upload. skip - Number of lines to skip in the beginning of the file. delimiter - Column delimiter string. table - JSON array of arrays with data columns. Note that the table has no title row, but columns are specified separately. columns - Column definition by an array of two-element arrays giving column name and type, where type is one of Integer, Float, Boolean, or Text . path - Platform path to put table which includes the name of the table item in the platform workspace. 1 2 3 4 5 6 7 8 9 { \"do\" : \"put\" , \"file\" : \"file with data table to put into platform\" , \"skip\" : \"number of lines to skip in the beginning of input file\" , \"delimiter\" : \"delimiter of table columns in input file\" , \"table\" : \"array of arrays with data to put into platform\" , \"columns\" : \"array of two-element arrays specifying column names and type. The latter can be Integer, Float, Boolean, Text\" , \"path\" : \"destination path of table in platform\" }","title":"put"},{"location":"api_overview.html#setparameters","text":"Sets/adds/removes string replacements in the parameter object that will modify parameters of subsequent tasks. set - a JSON object whose keys can be found in the replaceStrings array of the parameter object and whose value will replace the current one. remove - a JSON object whose keys will be removed from the replaceStrings array of the parameter object. before - an array of two-element arrays that are inserted in the beginning of the replaceStrings array. after - an array of two-element arrays that are appended to the replaceStrings array. 1 2 3 4 5 6 7 { \"do\" : \"setParameters\" , \"set\" : \"sets existing parameter to specified value\" , \"remove\" : \"removes existing parameter\" , \"before\" : \"add parameter before others in the parameter array\" , \"after\" : \"add parameter at the end of the parameter array\" }","title":"setParameters"},{"location":"basics.html","text":"Platform tools and parameters There are three main types of platform applications Analysis tools that cover functionality like data preparation, conversion, or data analysis Importers that import certain data types into the platform workspace Exporters that export data from the platform workspace The programming and commandline interfaces provide functions to list available analysis tools, importers and exporters for a given platform server and user account and furthermore to retrieve information about their input options/parameters. In the following, we focus on geneXplainR and commandline utilities provided by the genexplain-api package. Corresponding methods of the Java API are listed here . We recommend to use genexplain-api commandline tools for tool listings and parameters also when working mainly with geneXplainR. Listing tools and parameters using geneXplainR The example code below shows the geneXplainR functions to list available applications and to get information about parameters for a platform tool, gx.analysis.list and gx.analysis.parameters . The output of gx.analysis.list is a table containing tool names in the Name column and a column with the program group which corresponds to the name of the analysis tool folder in which a tool can be found in the graphical web interface. The gx.analysis.parameters output, shown below for Annotate table , is a table with parameter names as row ids and a column with short descriptions. For importers and exporters, corresponding functionality is implemented by gx.importers and gx.exporters which list available import and export functions, respectively, and by gx.import.parameters as well as gx.export.parameters which extract parameter information for specified importers and exporters, respectively. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 > library ( geneXplainR ) # Server, username and password need to be replaced with valid input values. # > gx.login ( \"https://platform.genexplain.com\" , \"someuser@email.io\" , \"12345\" ) > gx.analysis.list () Group Name 1 Data manipulation Annotate diagram 2 Data manipulation Annotate table 3 Data manipulation Annotate track with genes 4 Data manipulation CR cluster selector 5 Data manipulation Calculate weighted mutation score 6 Data manipulation Check quotas ... > gx.analysis.parameters ( \"Annotate table\" ) description inputTablePath Table with experimental ( test ) data species Species to be used during matching ( if applicable ) annotationCollectionPath Data collection with annotations annotationColumns Names for annotation columns replaceDuplicates If input table was already annotated by this source , old annotation columns will be removed from the result outputTablePath Output table Listing tools and parameters using the commandline program apps The commandline program apps can retrieve the list of available platform tools as well as an extended table that additionally contains information about tool parameters. For a simple listing of tools the input JSON file may look as follows, where server , user and password properties need to be replaced with valid input values. 1 2 3 4 5 6 7 { \"server\" : \"https://platform.genexplain.com\" , \"user\" : \"someuser@email.io\" , \"password\" : \"12345\" , \"withParameters\" : false , \"withGalaxy\" : false } The corresponding shell command is as follows, assuming the JSON object above is stored in a file named simple_tool_listing.json . 1 java -jar genexplain-api.jar apps simple_tool_listing.json The output consists of a list of analysis tools preceded by the program group to which a tool is assigned, e.g. Statistical analysis . The group name corresponds to the analysis tool folder in the graphical web interface where a tool can be found. Please note that in function calls only the tool name without the program group name is required. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 Data manipulation/Annotate diagram Data manipulation/Annotate table Data manipulation/Annotate track with genes Data manipulation/CR cluster selector Data manipulation/Calculate weighted mutation score Data manipulation/Check quotas Data manipulation/Composite module to proteins Data manipulation/Convert table Data manipulation/Convert table to VCF track ... Statistical analysis/Train random forest Statistical analysis/Up and Down Identification Statistical analysis/Variance filter Statistical analysis/t-SNE miRNA analysis/Analyze miRNA target enrichment miRNA analysis/Create miRNA promoters miRNA analysis/Get miRNA targets miRNA analysis/miRNA feed forward loops The output can be extended to Galaxy tools integrated in the specified platform instance by setting the withGalaxy property to true . Furthermore, the output can include information about tool parameters by setting the withParameters property to true . An example output with parameters is shown below . The output is a table with the following columns. Column name Description Tool folder/name String consisting of program group and tool name separated by / . The program group corresponds to the graphical interface folder where the tool can be found. API name The tool name that needs to be specified in API calls, e.g. gx.analysis of geneXplainR Parameter name The parameter name that needs to be specified in API calls, e.g. in a parameter list for gx.analysis Short description Short description of the parameter Type Data type of the input, e.g. data-element-path expects a string which is a platform path of data element Class Java class of a data element, e.g. ru.biosoft.table.TableDataCollection expects a path to refer to a tabular data Required Indicates if a value must be specified Description Possibly longer description of the parameter Output from apps including parameters Tool folder/name API name Parameter name Short description Type Class Required Description Data manipulation/Annotate diagram Annotate diagram inputDiagram Input diagram data-element-path biouml.model.Diagram true Diagram to annotate Data manipulation/Annotate diagram Annotate diagram table Annotation table data-element-path ru.biosoft.table.TableDataCollection true Table with diagram ids and annotations Data manipulation/Annotate diagram Annotate diagram column Annotation column code-string false Column with annotations Data manipulation/Annotate diagram Annotate diagram outputDiagram Output diagram data-element-path biouml.model.Diagram false Path to store annotated diagram Data manipulation/Annotate table Annotate table inputTablePath Experiment data-element-path ru.biosoft.table.TableDataCollection true Table with experimental(test) data ... ... ... ... ... ... ... ... miRNA analysis/miRNA feed forward loops miRNA feed forward loops miRNAs miRNAs data-element-path ru.biosoft.table.TableDataCollection true miRNAs miRNA analysis/miRNA feed forward loops miRNA feed forward loops targetGenes targetGenes data-element-path ru.biosoft.table.TableDataCollection true targetGenes miRNA analysis/miRNA feed forward loops miRNA feed forward loops siteModelCollection siteModelCollection data-element-path ru.biosoft.bsa.SiteModelCollection true siteModelCollection miRNA analysis/miRNA feed forward loops miRNA feed forward loops ensembl ensembl code-string false ensembl miRNA analysis/miRNA feed forward loops miRNA feed forward loops scoreType scoreType code-string false scoreType miRNA analysis/miRNA feed forward loops miRNA feed forward loops backgroundGenes backgroundGenes data-element-path ru.biosoft.table.TableDataCollection true backgroundGenes miRNA analysis/miRNA feed forward loops miRNA feed forward loops from from code-string false from miRNA analysis/miRNA feed forward loops miRNA feed forward loops to to code-string false to miRNA analysis/miRNA feed forward loops miRNA feed forward loops targetScanDB targetScanDB data-element-path ru.biosoft.access.SqlDataCollection true targetScanDB miRNA analysis/miRNA feed forward loops miRNA feed forward loops miRNAPromoterScoreThreshold miRNAPromoterScoreThreshold code-string false miRNAPromoterScoreThreshold miRNA analysis/miRNA feed forward loops miRNA feed forward loops targetGenePromoterScoreThreshold targetGenePromoterScoreThreshold code-string false targetGenePromoterScoreThreshold miRNA analysis/miRNA feed forward loops miRNA feed forward loops miRNATargetScoreThreshold miRNATargetScoreThreshold code-string false miRNATargetScoreThreshold miRNA analysis/miRNA feed forward loops miRNA feed forward loops scoreThreshold scoreThreshold code-string false scoreThreshold miRNA analysis/miRNA feed forward loops miRNA feed forward loops outTable outTable data-element-path ru.biosoft.table.TableDataCollection false outTable Fetching parameter information for specific tools using the parameters utility The program parameters of the genexplain-api package extracts parameter information for specified platform tools. The following example JSON fetches parameter descriptions for Annotate table and the Galaxy tool variant_effect_predictor . The server , user and password properties need to be set with valid input values. 1 2 3 4 5 6 { \"server\" : \"https://platform.genexplain.com\" , \"user\" : \"someuser@email.io\" , \"password\" : \"12345\" , \"tools\" : [ \"Annotate table\" , \"variant_effect_predictor\" ] } The following shell invokes parameters with the JSON object above stored in a file named specific_tool_parameters.json . 1 java -jar genexplain-api.jar parameters specific_tool_parameters.json The output is printed to standard output (optionally, an additional JSON parameter outfile can be provided to specify a local output file) and is (partially) shown below. It consists of a JSON object with one property for each platform tool that was specified in the tools list. The input options of a platform tool are contained in a JSON array, each represented by an object describing the input option. The order of input parameters in this array is the same as in the graphical web interface. The displayName property shows the parameter title that appears in the graphical web interface. However , the parameter name that needs to be specified in an API call is the name property. E.g. the first parameter of Annotate table with displayName Experiment has the name inputTablePath . The latter needs to be used in function calls. An input option object provides further valuable information such as the type of data that is expected. E.g. the Experiment needs to be provided as a type data-element-path , which means a path for a data element in the platform workspace and data element on that path must be a table ( elementClass ...TableDataCollection ). If an input option expects a value from a predefined list, the available values to select are also listed, see e.g. output and description for Functional classification . The geneXplainR method to fetch parameter information for platform tools is implemented in the function gx.analysis.parameters . However, the parameters commandline tool provides more details about each input option. Therefore, we recommend its use also for geneXplainR projects. Output produced by parameters for platform tools 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 { \"Annotate table\" : [ { \"canBeNull\" : false , \"promptOverwrite\" : false , \"displayName\" : \"Experiment\" , \"name\" : \"inputTablePath\" , \"icon\" : \"ru.biosoft.table:ru/biosoft/table/resources/table.gif\" , \"description\" : \"Table with experimental(test) data\" , \"readOnly\" : false , \"elementClass\" : \"ru.biosoft.table.TableDataCollection\" , \"type\" : \"data-element-path\" , \"value\" : \"(select element)\" , \"elementMustExist\" : true , \"multiSelect\" : false }, \"...\" , { \"displayName\" : \"Remove duplicate annotations\" , \"name\" : \"replaceDuplicates\" , \"description\" : \"If input table was already annotated by this source, old annotation columns will be removed from the result\" , \"readOnly\" : false , \"type\" : \"bool\" , \"value\" : \"true\" }, { \"auto\" : \"on\" , \"displayName\" : \"Output table\" , \"icon\" : \"ru.biosoft.table:ru/biosoft/table/resources/table.gif\" , \"description\" : \"Output table\" , \"readOnly\" : false , \"type\" : \"data-element-path\" , \"canBeNull\" : false , \"promptOverwrite\" : false , \"name\" : \"outputTablePath\" , \"elementClass\" : \"ru.biosoft.table.TableDataCollection\" , \"value\" : \"(select element)\" , \"elementMustExist\" : false , \"multiSelect\" : false } ], \"variant_effect_predictor\" : [ { \"canBeNull\" : false , \"promptOverwrite\" : false , \"displayName\" : \"Input vcf file\" , \"name\" : \"input\" , \"icon\" : \"ru.biosoft.bsa:ru/biosoft/bsa/resources/track.gif\" , \"description\" : \"\" , \"readOnly\" : false , \"elementClass\" : \"ru.biosoft.bsa.Track\" , \"type\" : \"data-element-path\" , \"value\" : \"(select element)\" , \"elementMustExist\" : true , \"multiSelect\" : false }, \"...\" ] }","title":"Platform tools and parameters"},{"location":"basics.html#platform-tools-and-parameters","text":"There are three main types of platform applications Analysis tools that cover functionality like data preparation, conversion, or data analysis Importers that import certain data types into the platform workspace Exporters that export data from the platform workspace The programming and commandline interfaces provide functions to list available analysis tools, importers and exporters for a given platform server and user account and furthermore to retrieve information about their input options/parameters. In the following, we focus on geneXplainR and commandline utilities provided by the genexplain-api package. Corresponding methods of the Java API are listed here . We recommend to use genexplain-api commandline tools for tool listings and parameters also when working mainly with geneXplainR.","title":"Platform tools and parameters"},{"location":"basics.html#listing-tools-and-parameters-using-genexplainr","text":"The example code below shows the geneXplainR functions to list available applications and to get information about parameters for a platform tool, gx.analysis.list and gx.analysis.parameters . The output of gx.analysis.list is a table containing tool names in the Name column and a column with the program group which corresponds to the name of the analysis tool folder in which a tool can be found in the graphical web interface. The gx.analysis.parameters output, shown below for Annotate table , is a table with parameter names as row ids and a column with short descriptions. For importers and exporters, corresponding functionality is implemented by gx.importers and gx.exporters which list available import and export functions, respectively, and by gx.import.parameters as well as gx.export.parameters which extract parameter information for specified importers and exporters, respectively. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 > library ( geneXplainR ) # Server, username and password need to be replaced with valid input values. # > gx.login ( \"https://platform.genexplain.com\" , \"someuser@email.io\" , \"12345\" ) > gx.analysis.list () Group Name 1 Data manipulation Annotate diagram 2 Data manipulation Annotate table 3 Data manipulation Annotate track with genes 4 Data manipulation CR cluster selector 5 Data manipulation Calculate weighted mutation score 6 Data manipulation Check quotas ... > gx.analysis.parameters ( \"Annotate table\" ) description inputTablePath Table with experimental ( test ) data species Species to be used during matching ( if applicable ) annotationCollectionPath Data collection with annotations annotationColumns Names for annotation columns replaceDuplicates If input table was already annotated by this source , old annotation columns will be removed from the result outputTablePath Output table","title":"Listing tools and parameters using geneXplainR"},{"location":"basics.html#listing-tools-and-parameters-using-the-commandline-program-apps","text":"The commandline program apps can retrieve the list of available platform tools as well as an extended table that additionally contains information about tool parameters. For a simple listing of tools the input JSON file may look as follows, where server , user and password properties need to be replaced with valid input values. 1 2 3 4 5 6 7 { \"server\" : \"https://platform.genexplain.com\" , \"user\" : \"someuser@email.io\" , \"password\" : \"12345\" , \"withParameters\" : false , \"withGalaxy\" : false } The corresponding shell command is as follows, assuming the JSON object above is stored in a file named simple_tool_listing.json . 1 java -jar genexplain-api.jar apps simple_tool_listing.json The output consists of a list of analysis tools preceded by the program group to which a tool is assigned, e.g. Statistical analysis . The group name corresponds to the analysis tool folder in the graphical web interface where a tool can be found. Please note that in function calls only the tool name without the program group name is required. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 Data manipulation/Annotate diagram Data manipulation/Annotate table Data manipulation/Annotate track with genes Data manipulation/CR cluster selector Data manipulation/Calculate weighted mutation score Data manipulation/Check quotas Data manipulation/Composite module to proteins Data manipulation/Convert table Data manipulation/Convert table to VCF track ... Statistical analysis/Train random forest Statistical analysis/Up and Down Identification Statistical analysis/Variance filter Statistical analysis/t-SNE miRNA analysis/Analyze miRNA target enrichment miRNA analysis/Create miRNA promoters miRNA analysis/Get miRNA targets miRNA analysis/miRNA feed forward loops The output can be extended to Galaxy tools integrated in the specified platform instance by setting the withGalaxy property to true . Furthermore, the output can include information about tool parameters by setting the withParameters property to true . An example output with parameters is shown below . The output is a table with the following columns. Column name Description Tool folder/name String consisting of program group and tool name separated by / . The program group corresponds to the graphical interface folder where the tool can be found. API name The tool name that needs to be specified in API calls, e.g. gx.analysis of geneXplainR Parameter name The parameter name that needs to be specified in API calls, e.g. in a parameter list for gx.analysis Short description Short description of the parameter Type Data type of the input, e.g. data-element-path expects a string which is a platform path of data element Class Java class of a data element, e.g. ru.biosoft.table.TableDataCollection expects a path to refer to a tabular data Required Indicates if a value must be specified Description Possibly longer description of the parameter","title":"Listing tools and parameters using the commandline program apps"},{"location":"basics.html#output-from-apps-including-parameters","text":"Tool folder/name API name Parameter name Short description Type Class Required Description Data manipulation/Annotate diagram Annotate diagram inputDiagram Input diagram data-element-path biouml.model.Diagram true Diagram to annotate Data manipulation/Annotate diagram Annotate diagram table Annotation table data-element-path ru.biosoft.table.TableDataCollection true Table with diagram ids and annotations Data manipulation/Annotate diagram Annotate diagram column Annotation column code-string false Column with annotations Data manipulation/Annotate diagram Annotate diagram outputDiagram Output diagram data-element-path biouml.model.Diagram false Path to store annotated diagram Data manipulation/Annotate table Annotate table inputTablePath Experiment data-element-path ru.biosoft.table.TableDataCollection true Table with experimental(test) data ... ... ... ... ... ... ... ... miRNA analysis/miRNA feed forward loops miRNA feed forward loops miRNAs miRNAs data-element-path ru.biosoft.table.TableDataCollection true miRNAs miRNA analysis/miRNA feed forward loops miRNA feed forward loops targetGenes targetGenes data-element-path ru.biosoft.table.TableDataCollection true targetGenes miRNA analysis/miRNA feed forward loops miRNA feed forward loops siteModelCollection siteModelCollection data-element-path ru.biosoft.bsa.SiteModelCollection true siteModelCollection miRNA analysis/miRNA feed forward loops miRNA feed forward loops ensembl ensembl code-string false ensembl miRNA analysis/miRNA feed forward loops miRNA feed forward loops scoreType scoreType code-string false scoreType miRNA analysis/miRNA feed forward loops miRNA feed forward loops backgroundGenes backgroundGenes data-element-path ru.biosoft.table.TableDataCollection true backgroundGenes miRNA analysis/miRNA feed forward loops miRNA feed forward loops from from code-string false from miRNA analysis/miRNA feed forward loops miRNA feed forward loops to to code-string false to miRNA analysis/miRNA feed forward loops miRNA feed forward loops targetScanDB targetScanDB data-element-path ru.biosoft.access.SqlDataCollection true targetScanDB miRNA analysis/miRNA feed forward loops miRNA feed forward loops miRNAPromoterScoreThreshold miRNAPromoterScoreThreshold code-string false miRNAPromoterScoreThreshold miRNA analysis/miRNA feed forward loops miRNA feed forward loops targetGenePromoterScoreThreshold targetGenePromoterScoreThreshold code-string false targetGenePromoterScoreThreshold miRNA analysis/miRNA feed forward loops miRNA feed forward loops miRNATargetScoreThreshold miRNATargetScoreThreshold code-string false miRNATargetScoreThreshold miRNA analysis/miRNA feed forward loops miRNA feed forward loops scoreThreshold scoreThreshold code-string false scoreThreshold miRNA analysis/miRNA feed forward loops miRNA feed forward loops outTable outTable data-element-path ru.biosoft.table.TableDataCollection false outTable","title":"Output from apps including parameters"},{"location":"basics.html#fetching-parameter-information-for-specific-tools-using-the-parameters-utility","text":"The program parameters of the genexplain-api package extracts parameter information for specified platform tools. The following example JSON fetches parameter descriptions for Annotate table and the Galaxy tool variant_effect_predictor . The server , user and password properties need to be set with valid input values. 1 2 3 4 5 6 { \"server\" : \"https://platform.genexplain.com\" , \"user\" : \"someuser@email.io\" , \"password\" : \"12345\" , \"tools\" : [ \"Annotate table\" , \"variant_effect_predictor\" ] } The following shell invokes parameters with the JSON object above stored in a file named specific_tool_parameters.json . 1 java -jar genexplain-api.jar parameters specific_tool_parameters.json The output is printed to standard output (optionally, an additional JSON parameter outfile can be provided to specify a local output file) and is (partially) shown below. It consists of a JSON object with one property for each platform tool that was specified in the tools list. The input options of a platform tool are contained in a JSON array, each represented by an object describing the input option. The order of input parameters in this array is the same as in the graphical web interface. The displayName property shows the parameter title that appears in the graphical web interface. However , the parameter name that needs to be specified in an API call is the name property. E.g. the first parameter of Annotate table with displayName Experiment has the name inputTablePath . The latter needs to be used in function calls. An input option object provides further valuable information such as the type of data that is expected. E.g. the Experiment needs to be provided as a type data-element-path , which means a path for a data element in the platform workspace and data element on that path must be a table ( elementClass ...TableDataCollection ). If an input option expects a value from a predefined list, the available values to select are also listed, see e.g. output and description for Functional classification . The geneXplainR method to fetch parameter information for platform tools is implemented in the function gx.analysis.parameters . However, the parameters commandline tool provides more details about each input option. Therefore, we recommend its use also for geneXplainR projects.","title":"Fetching parameter information for specific tools using the parameters utility"},{"location":"basics.html#output-produced-by-parameters-for-platform-tools","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 { \"Annotate table\" : [ { \"canBeNull\" : false , \"promptOverwrite\" : false , \"displayName\" : \"Experiment\" , \"name\" : \"inputTablePath\" , \"icon\" : \"ru.biosoft.table:ru/biosoft/table/resources/table.gif\" , \"description\" : \"Table with experimental(test) data\" , \"readOnly\" : false , \"elementClass\" : \"ru.biosoft.table.TableDataCollection\" , \"type\" : \"data-element-path\" , \"value\" : \"(select element)\" , \"elementMustExist\" : true , \"multiSelect\" : false }, \"...\" , { \"displayName\" : \"Remove duplicate annotations\" , \"name\" : \"replaceDuplicates\" , \"description\" : \"If input table was already annotated by this source, old annotation columns will be removed from the result\" , \"readOnly\" : false , \"type\" : \"bool\" , \"value\" : \"true\" }, { \"auto\" : \"on\" , \"displayName\" : \"Output table\" , \"icon\" : \"ru.biosoft.table:ru/biosoft/table/resources/table.gif\" , \"description\" : \"Output table\" , \"readOnly\" : false , \"type\" : \"data-element-path\" , \"canBeNull\" : false , \"promptOverwrite\" : false , \"name\" : \"outputTablePath\" , \"elementClass\" : \"ru.biosoft.table.TableDataCollection\" , \"value\" : \"(select element)\" , \"elementMustExist\" : false , \"multiSelect\" : false } ], \"variant_effect_predictor\" : [ { \"canBeNull\" : false , \"promptOverwrite\" : false , \"displayName\" : \"Input vcf file\" , \"name\" : \"input\" , \"icon\" : \"ru.biosoft.bsa:ru/biosoft/bsa/resources/track.gif\" , \"description\" : \"\" , \"readOnly\" : false , \"elementClass\" : \"ru.biosoft.bsa.Track\" , \"type\" : \"data-element-path\" , \"value\" : \"(select element)\" , \"elementMustExist\" : true , \"multiSelect\" : false }, \"...\" ] }","title":"Output produced by parameters for platform tools"},{"location":"chipseq_analysis_intro.html","text":"Overview of the analysis workflow The main tutorial example is a workflow to infer possible components of a gene regulatory network on the basis of ChIP-seq data. The workflow is depicted in Figure 2 . Starting point of the analysis is the BED file containing genomic locations of TAL1-bound regions in Jurkat cells discovered and published by Palii et al. . The GEO repository hosts the ChIP-seq data of the study under series accession GSE25000 . The tutorial focuses on the TAL1-bound genomic locations reported by the study authors which can be downloaded here . Source code that implements the workflow is provided for geneXplainR and the Java API . The corresponding JSON configuration file for the exec commandline interface can be found here . Workflow steps Step A. Sampling TAL1 binding sites In a preparatory step we extracted a sample of 1000 TAL1 bound regions for subsequent MEALR analysis. The sample was drawn using the shuf and head programs from GNU coreutils . The file GSM614003_jurkat.tal1_1000.bed containing the sampled sites is part of the material for this tutorial. Step 1. Import and mapping of TAL1-bound genomic regions Step 1 imports the BED file with TAL1-bound genomic regions into the platform workspace. Since the genomic regions reported in the original study referred to human genome sequence version hg18 , we then use the Galaxy tool Lift over to convert the hg18 coordinates to hg38. Step 2. Mapping TAL1-bound genomic regions to nearby genes Step 2 assigns the hg38 coordinates of TAL1-bound regions with nearby genes using the platform tool Track to gene set . Step 3. Functional enrichment analysis of genes near TAL1-bound regions Genes located in the vicinity of TAL1 binding sites are analyzed for enrichment of certain functions on the basis of Gene Ontology annotation, Reactome pathways, as well as for enrichment of known human disease biomarkers annotated in the HumanPSD . This is done using the Functional classification platform tool. Please note that the HumanPSD biomarker resource requires a license. Step 4. Sampling genomic regions not bound by TAL1 MEALR requires a background set of genomic regions to find a discriminating pattern of PWM scores. The platform tool Create random track samples regions around transcription start sites of genes that do not overlap with an input set of genomic regions, in this case the study set of TAL1 binding sites, and with the same length distribution. Step 5. Import and mapping of TAL1 binding site subset The set of TAL1 binding sites sampled in Step A represents the target set of genomic regions which we import and convert to hg38 coordinates as in Step 1 . Step 6. Selection of important PWM models using MEALR The target and background set of genomic coordinates prepared in the previous two steps are analyzed with MEALR (tracks) using TRANSFAC\u00ae PWMs from the profile vertebrate_human_p0.05_non3d . This profile contains PWM models defined for vertebrate transcription factors omitting those that have been derived theoretically on the basis of molecular structures of protein-DNA complexes using 3DTF . Step 7. Extraction of binding transcription factors Possible co-binding factors are obtained by firstly selecting the top 50 PWMs with positive model coefficients using the Select top rows tool followed by extracting corresponding transcription factor genes using the Matrices to molecules tool. Step 8. Intersection of potentially TAL1-regulated genes and MEALR TFs The gene regulatory network workflow is completed by intersecting the transcription factors identified by MEALR with potentially TAL1-regulated genes ( Step 2 ) using the Venn diagrams tool. The resulting set of transcription factors are inferred to be both regulatory targets of TAL1 as well as co-regulators. Step 9. Prediction of binding sites of identified TFs in TAL1-bound genomic regions In order to conduct the last two steps of the tutorial workflow we prepare a list of PWMs representing TFs identified in Step 8 and, after its import into the platform workspace, create a corresponding PWM profile using the Create profile from site model table tool. The score cutoffs are taken from the vertebrate_human_p0.001_non3d profile which adjusts scores to a p -value of 0.001 estimated for a sequences with the same dinucleotide composition as human promoter regions. The profile for GRN transcription factors is then used to predict precise binding locations of these transcription factors within TAL1 ChIP-seq regions using the TRANSFAC(R) Match(TM) for tracks tool. Step 10. Prediction of binding sites of identified TFs around TAL1 transcription start site Binding sites for inferred TFs are furthermore predicted in the genomic region around the TAL1 transcription start site. As the study ChIP-seq regions did not contain a TAL1-bound region near the TAL1 gene, we import a simple table containing the TAL1 Ensembl id and extract the region around the TSS using the Gene set to track tool, followed by Match analysis of the sequence as in Step 9. Figure 2. Workflow overview Scientific results of the tutorial workflow According to the output table named MEALR_positive_coefficients MEALR assigned highest coefficients to TAL1 PWM models (V$TAL1_05 and V$TAL1GATA1_02). and binding factors of important PWMs, such as Runt and GATA motifs, coincide with those reported in the original publication . The TAL1-regulatory network inferred by the workflow includes the transcription factors ERG, GATA2, LEF1, MAX, MYB, RUNX1, RUNX2 and TCF7. GATA2, TAL1 and ERG have been reported as components of a regulatory circuit by Thoms et al. . The regulatory link between RUNX1 and MYB in leukemia has been described by Choi et al. and the importance of MYB for leukemic pathology has been elaborated on by Zuber et al. .","title":"Analysis overview"},{"location":"chipseq_analysis_intro.html#overview-of-the-analysis-workflow","text":"The main tutorial example is a workflow to infer possible components of a gene regulatory network on the basis of ChIP-seq data. The workflow is depicted in Figure 2 . Starting point of the analysis is the BED file containing genomic locations of TAL1-bound regions in Jurkat cells discovered and published by Palii et al. . The GEO repository hosts the ChIP-seq data of the study under series accession GSE25000 . The tutorial focuses on the TAL1-bound genomic locations reported by the study authors which can be downloaded here . Source code that implements the workflow is provided for geneXplainR and the Java API . The corresponding JSON configuration file for the exec commandline interface can be found here .","title":"Overview of the analysis workflow"},{"location":"chipseq_analysis_intro.html#workflow-steps","text":"","title":"Workflow steps"},{"location":"chipseq_analysis_intro.html#step-a-sampling-tal1-binding-sites","text":"In a preparatory step we extracted a sample of 1000 TAL1 bound regions for subsequent MEALR analysis. The sample was drawn using the shuf and head programs from GNU coreutils . The file GSM614003_jurkat.tal1_1000.bed containing the sampled sites is part of the material for this tutorial.","title":"Step A. Sampling TAL1 binding sites"},{"location":"chipseq_analysis_intro.html#step-1-import-and-mapping-of-tal1-bound-genomic-regions","text":"Step 1 imports the BED file with TAL1-bound genomic regions into the platform workspace. Since the genomic regions reported in the original study referred to human genome sequence version hg18 , we then use the Galaxy tool Lift over to convert the hg18 coordinates to hg38.","title":"Step 1. Import and mapping of TAL1-bound genomic regions"},{"location":"chipseq_analysis_intro.html#step-2-mapping-tal1-bound-genomic-regions-to-nearby-genes","text":"Step 2 assigns the hg38 coordinates of TAL1-bound regions with nearby genes using the platform tool Track to gene set .","title":"Step 2. Mapping TAL1-bound genomic regions to nearby genes"},{"location":"chipseq_analysis_intro.html#step-3-functional-enrichment-analysis-of-genes-near-tal1-bound-regions","text":"Genes located in the vicinity of TAL1 binding sites are analyzed for enrichment of certain functions on the basis of Gene Ontology annotation, Reactome pathways, as well as for enrichment of known human disease biomarkers annotated in the HumanPSD . This is done using the Functional classification platform tool. Please note that the HumanPSD biomarker resource requires a license.","title":"Step 3. Functional enrichment analysis of genes near TAL1-bound regions"},{"location":"chipseq_analysis_intro.html#step-4-sampling-genomic-regions-not-bound-by-tal1","text":"MEALR requires a background set of genomic regions to find a discriminating pattern of PWM scores. The platform tool Create random track samples regions around transcription start sites of genes that do not overlap with an input set of genomic regions, in this case the study set of TAL1 binding sites, and with the same length distribution.","title":"Step 4. Sampling genomic regions not bound by TAL1"},{"location":"chipseq_analysis_intro.html#step-5-import-and-mapping-of-tal1-binding-site-subset","text":"The set of TAL1 binding sites sampled in Step A represents the target set of genomic regions which we import and convert to hg38 coordinates as in Step 1 .","title":"Step 5. Import and mapping of TAL1 binding site subset"},{"location":"chipseq_analysis_intro.html#step-6-selection-of-important-pwm-models-using-mealr","text":"The target and background set of genomic coordinates prepared in the previous two steps are analyzed with MEALR (tracks) using TRANSFAC\u00ae PWMs from the profile vertebrate_human_p0.05_non3d . This profile contains PWM models defined for vertebrate transcription factors omitting those that have been derived theoretically on the basis of molecular structures of protein-DNA complexes using 3DTF .","title":"Step 6. Selection of important PWM models using MEALR"},{"location":"chipseq_analysis_intro.html#step-7-extraction-of-binding-transcription-factors","text":"Possible co-binding factors are obtained by firstly selecting the top 50 PWMs with positive model coefficients using the Select top rows tool followed by extracting corresponding transcription factor genes using the Matrices to molecules tool.","title":"Step 7. Extraction of binding transcription factors"},{"location":"chipseq_analysis_intro.html#step-8-intersection-of-potentially-tal1-regulated-genes-and-mealr-tfs","text":"The gene regulatory network workflow is completed by intersecting the transcription factors identified by MEALR with potentially TAL1-regulated genes ( Step 2 ) using the Venn diagrams tool. The resulting set of transcription factors are inferred to be both regulatory targets of TAL1 as well as co-regulators.","title":"Step 8. Intersection of potentially TAL1-regulated genes and MEALR TFs"},{"location":"chipseq_analysis_intro.html#step-9-prediction-of-binding-sites-of-identified-tfs-in-tal1-bound-genomic-regions","text":"In order to conduct the last two steps of the tutorial workflow we prepare a list of PWMs representing TFs identified in Step 8 and, after its import into the platform workspace, create a corresponding PWM profile using the Create profile from site model table tool. The score cutoffs are taken from the vertebrate_human_p0.001_non3d profile which adjusts scores to a p -value of 0.001 estimated for a sequences with the same dinucleotide composition as human promoter regions. The profile for GRN transcription factors is then used to predict precise binding locations of these transcription factors within TAL1 ChIP-seq regions using the TRANSFAC(R) Match(TM) for tracks tool.","title":"Step 9. Prediction of binding sites of identified TFs in TAL1-bound genomic regions"},{"location":"chipseq_analysis_intro.html#step-10-prediction-of-binding-sites-of-identified-tfs-around-tal1-transcription-start-site","text":"Binding sites for inferred TFs are furthermore predicted in the genomic region around the TAL1 transcription start site. As the study ChIP-seq regions did not contain a TAL1-bound region near the TAL1 gene, we import a simple table containing the TAL1 Ensembl id and extract the region around the TSS using the Gene set to track tool, followed by Match analysis of the sequence as in Step 9.","title":"Step 10. Prediction of binding sites of identified TFs around TAL1 transcription start site"},{"location":"chipseq_analysis_intro.html#figure-2-workflow-overview","text":"","title":"Figure 2. Workflow overview"},{"location":"chipseq_analysis_intro.html#scientific-results-of-the-tutorial-workflow","text":"According to the output table named MEALR_positive_coefficients MEALR assigned highest coefficients to TAL1 PWM models (V$TAL1_05 and V$TAL1GATA1_02). and binding factors of important PWMs, such as Runt and GATA motifs, coincide with those reported in the original publication . The TAL1-regulatory network inferred by the workflow includes the transcription factors ERG, GATA2, LEF1, MAX, MYB, RUNX1, RUNX2 and TCF7. GATA2, TAL1 and ERG have been reported as components of a regulatory circuit by Thoms et al. . The regulatory link between RUNX1 and MYB in leukemia has been described by Choi et al. and the importance of MYB for leukemic pathology has been elaborated on by Zuber et al. .","title":"Scientific results of the tutorial workflow"},{"location":"chipseq_analysis_java.html","text":"ChIP-seq data analysis with a Java program based on genexplain-api The Java code below implements the tutorial workflow . The described steps are indicated in code comments for reference. Compiling and executing the tutorial The Java code is provided with the tutorial material as GenexplainTutorialChipseqAnalysis.java . Please note that some parts require editing before running the program, including username, password, project name. Assuming the source file is stored as GenexplainTutorialChipseqAnalysis.java and the genexplain-api package is located in the same subfolder, the Java class can be compiled as follows. 1 javac -cp .:genexplain-api.jar GenexplainTutorialChipseqAnalysis.java Similarly, the class file can then be executed as 1 java -cp .:genexplain-api.jar GenexplainTutorialChipseqAnalysis Java code for the tutorial workflow 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 import com.eclipsesource.json.JsonArray ; import com.eclipsesource.json.JsonValue ; import com.eclipsesource.json.JsonObject ; import com.eclipsesource.json.PrettyPrint ; import com.genexplain.api.core.GxHttpClient ; import com.genexplain.api.core.GxHttpClientImpl ; import com.genexplain.api.core.GxHttpConnection ; import com.genexplain.api.core.GxHttpConnectionImpl ; import java.io.FileOutputStream ; import java.io.FileWriter ; import java.io.StringWriter ; import java.io.Writer ; import java.util.HashMap ; import java.util.Map ; public class GenexplainTutorialChipseqAnalysis { public static void main ( String [] args ) throws Exception { // The GxHttpConnectionImpl holds the connection to the specified // platform server. Username and password need to correspond to a // valid account on that server. // GxHttpConnectionImpl con = new GxHttpConnectionImpl (); con . setServer ( \"https://platform.genexplain.com\" ); con . setUsername ( \"someuser@email.io\" ); con . setPassword ( \"12345\" ); con . setVerbose ( true ); con . login (); // The connection is given to a client object. The client is the // main component to interact with the connected platform server. // GxHttpClientImpl client = new GxHttpClientImpl (); client . setConnection ( con ); // The createProject method creates a new project in the user // workspace. The project name must be new and unique on the // platform instance. The platform path of the new project is // \"data/Projects/<project name>\". // Map < String , String > projectParams = new HashMap <> (); projectParams . put ( \"user\" , \"someuser@email.io\" ); projectParams . put ( \"pass\" , \"12345\" ); projectParams . put ( \"project\" , \"api2022_tutorial\" ); projectParams . put ( \"description\" , \"API 2022 tutorial project\" ); client . createProject ( projectParams ) String folderPath = \"data/Projects/api2022_tutorial/Data/chipseq_analysis_workflow_java\" ; String species = \"Human (Homo sapiens)\" ; // The createFolder function creates the folder if it does not // already exist. Within a project, folders for data elements // have to be created within the *Data* folder or its subfolders. // client . createFolder ( \"data/Projects/api2022_tutorial/Data\" , \"chipseq_analysis_workflow_java\" ); // // Step 1. Import and mapping of TAL1-bound genomic regions // JsonObject params = new JsonObject (). add ( \"dbSelector\" , \"Ensembl 52.36n Human (hg18)\" ); // Import the BED file with TAL1-bound regions into the destination folder client . imPort ( \"../data/GSM614003_jurkat.tal1.bed\" , folderPath , \"BED format (*.bed)\" , params ); // Sometimes a short interruption is required to allow processes // on the server complete their work Thread . sleep ( 1000 ); String bedPath = folderPath + \"/GSM614003_jurkat.tal1\" ; String mappedPath = folderPath + \"/jurkat_chipseq_hg38\" ; String unmappedPath = folderPath + \"/jurkat_chipseq_hg38_unmapped\" ; String mapping = \"hg18->hg38\" ; params = new JsonObject () . add ( \"input\" , bedPath ) . add ( \"mapping\" , mapping ) . add ( \"minMatch\" , 0.95 ) . add ( \"out_file1\" , mappedPath ) . add ( \"out_file2\" , unmappedPath ); // Run Liftover to map hg18 coordinates to hg38 client . analyze ( \"liftOver1\" , params , false , true , true ); // // Step 2. Mapping TAL1-bound genomic regions to nearby genes // String mappedGenePath = mappedPath + \" Genes\" ; JsonArray sourcePaths = new JsonArray (). add ( mappedPath ); params = new JsonObject () . add ( \"sourcePaths\" , sourcePaths ) . add ( \"species\" , species ) . add ( \"from\" , - 5000 ) . add ( \"to\" , 2000 ) . add ( \"destPath\" , mappedGenePath ); // Run \"Track to gene set\" tool to map genomic coordinates to genes client . analyze ( \"Track to gene set\" , params , false , true , true ); // // Step 3. Functional enrichment analysis of genes near TAL1-bound // regions // String funclassResultPath = mappedGenePath + \" GO\" ; params = new JsonObject () . add ( \"sourcePath\" , mappedGenePath ) . add ( \"species\" , species ) . add ( \"bioHub\" , \"Full gene ontology classification\" ) . add ( \"minHits\" , 1 ) . add ( \"pvalueThreshold\" , 1 ) . add ( \"outputTable\" , funclassResultPath ); // Enrichment of genes associated with Gene Ontology terms using // \"Functional classification\" client . analyze ( \"Functional classification\" , params , false , true , true ); FileOutputStream fileExport = new FileOutputStream ( \"functional_classification_result_GO.tsv\" ); // Export analysis result to local file client . export ( funclassResultPath , \"Tab-separated text (*.txt)\" , fileExport , new JsonObject ()); // The output stream is not closed by the platform client. fileExport . close (); funclassResultPath = mappedGenePath + \" Reactome\" ; params . add ( \"bioHub\" , \"Reactome pathways (74)\" ). add ( \"outputTable\" , funclassResultPath ); // Enrichment of genes associated with Reactome pathways client . analyze ( \"Functional classification\" , params , false , true , true ); fileExport = new FileOutputStream ( \"functional_classification_result_Reactome.tsv\" ); // Export analysis result to local file client . export ( funclassResultPath , \"Tab-separated text (*.txt)\" , fileExport , new JsonObject ()); fileExport . close (); funclassResultPath = mappedGenePath + \" Human disease biomarkers\" ; params . add ( \"bioHub\" , \"HumanPSD(TM) disease (2022.1)\" ). add ( \"outputTable\" , funclassResultPath ); // Enrichment of genes associated with human diseases based on // HumanPSD disease biomarker annotation client . analyze ( \"Functional classification\" , params , false , true , true ); fileExport = new FileOutputStream ( \"functional_classification_result_HumanPSD.tsv\" ); // Export analysis result to local file client . export ( funclassResultPath , \"Tab-separated text (*.txt)\" , fileExport , new JsonObject ()); fileExport . close (); // // Step 4. Sampling genomic regions not bound by TAL1 // String mealrBackgroundTrack = mappedPath + \" random 1000\" ; params = new JsonObject () . add ( \"inputTrackPath\" , mappedPath ) . add ( \"dbSelector\" , \"Ensembl 104.38 Human (hg38)\" ) . add ( \"species\" , species ) . add ( \"standardChromosomes\" , true ) . add ( \"seqNumber\" , 1000 ) . add ( \"seqLength\" , 0 ) . add ( \"from\" , 0 ) . add ( \"to\" , 0 ) . add ( \"withOverlap\" , false ) . add ( \"randomShift\" , false ) . add ( \"outputTrackPath\" , mealrBackgroundTrack ) . add ( \"randSeed\" , 123 ); // Create random track not overlapping with TAL1-bound regions client . analyze ( \"Create random track\" , params , false , true , true ); // // Step 5. Import and mapping of TAL1 binding site subset // // Data upload and lifting as in Step 1 for 1000 TAL1 sites sampled // from the original BED file params = new JsonObject (). add ( \"dbSelector\" , \"Ensembl 52.36n Human (hg18)\" ); // Import sampled TAL1 ChIP-seq sites client . imPort ( \"../data/GSM614003_jurkat.tal1_1000.bed\" , folderPath , \"BED format (*.bed)\" , params ); // Sometimes a short interruption is required to allow processes // on the server complete their work Thread . sleep ( 1000 ); bedPath = folderPath + \"/GSM614003_jurkat.tal1_1000\" ; mappedPath = folderPath + \"/jurkat_chipseq_hg38_1000\" ; unmappedPath = folderPath + \"/jurkat_chipseq_hg38_1000_unmapped\" ; params = new JsonObject () . add ( \"input\" , bedPath ) . add ( \"mapping\" , mapping ) . add ( \"minMatch\" , 0.95 ) . add ( \"out_file1\" , mappedPath ) . add ( \"out_file2\" , unmappedPath ); // Coordinate mapping to hg38 client . analyze ( \"liftOver1\" , params , false , true , true ); // // Step 6. Selection of important PWM models using MEALR // String mealrOutputPath = mappedPath + \" MEALR\" ; String transfacProfile = \"databases/TRANSFAC(R) 2022.1/Data/profiles/vertebrate_human_p0.05_non3d\" ; params = new JsonObject () . add ( \"yesSetPath\" , mappedPath ) . add ( \"noSetPath\" , mealrBackgroundTrack ) . add ( \"dbSelector\" , \"Ensembl 104.38 Human (hg38)\" ) . add ( \"profilePath\" , transfacProfile ) . add ( \"maxPosCoef\" , 150 ) . add ( \"maxComplexity\" , 0.5 ) . add ( \"complexityInc\" , 0.02 ) . add ( \"maxUnimproved\" , 20 ) . add ( \"scoresWithNoSet\" , false ) . add ( \"output\" , mealrOutputPath ); // Analyze target and background genomic regions using MEALR client . analyze ( \"MEALR (tracks)\" , params , false , true , true ); // // Step 7. Extraction of binding transcription factors // String mealrMotifPath = mealrOutputPath + \"/MEALR_positive_coefficients\" ; String mealrTopPath = mealrMotifPath + \" Top 50\" ; params = new JsonObject () . add ( \"inputTable\" , mealrMotifPath ) . add ( \"column\" , \"Coefficient\" ) . add ( \"types\" , new JsonArray (). add ( \"Top\" )) . add ( \"topPercent\" , 100.0 ) . add ( \"topCount\" , 50 ) . add ( \"topMinCount\" , 50 ) . add ( \"topTable\" , mealrTopPath ); // Extract top 50 PWMs ranked by logistic regression coefficient client . analyze ( \"Select top rows\" , params , false , true , true ); String mealrTopGenePath = mealrTopPath + \" Genes\" ; params = new JsonObject () . add ( \"sitesCollection\" , mealrTopPath ) . add ( \"siteModelsCollection\" , transfacProfile ) . add ( \"species\" , species ) . add ( \"targetType\" , \"Genes: Ensembl\" ) . add ( \"outputTable\" , mealrTopGenePath ); // Convert PWMs to factor genes client . analyze ( \"Matrices to molecules\" , params , false , true , true ); // // Step 8. Intersection of potentially TAL1-regulated genes and // MEALR TFs // String mappedNearbyGenePath = folderPath + \"/jurkat_chipseq_hg38 Genes\" ; String mealrTopVennPath = mealrTopPath + \" Venn\" ; params = new JsonObject () . add ( \"table1Path\" , mappedNearbyGenePath ) . add ( \"table1Name\" , \"Genes near TAL1 sites\" ) . add ( \"table2Path\" , mealrTopGenePath ) . add ( \"table2Name\" , \"MEALR transcription factors\" ) . add ( \"simple\" , true ) . add ( \"output\" , mealrTopVennPath ); // Intersect factors identified by MEALR and genes with nearby // TAL1 ChIP-seq sites client . analyze ( \"Venn diagrams\" , params , false , true , true ); // // Step 9. Prediction of binding sites of identified TFs in // TAL1-bound genomic regions // String grnFactorPath = mealrTopVennPath + \"/Rows present in both tables\" ; // Load table with potential GRN factors JsonObject tableData = client . getTable ( grnFactorPath ); // The JSON object contains the table data under property // \"data\" JsonArray topPwms = tableData . get ( \"data\" ). asArray (). get ( 3 ). asArray (); JsonArray topCoefs = tableData . get ( \"data\" ). asArray (). get ( 4 ). asArray (); String tpwms ; String [] pwmids ; double tcoef ; Map < String , Double > topPwmData = new HashMap <> (); // Extract PWM ids and coefficients for ( int t = 0 ; t < topPwms . size (); ++ t ) { tpwms = topPwms . get ( t ). asString (); tcoef = topCoefs . get ( t ). asDouble (); pwmids = tpwms . split ( \",\" ); for ( String id : pwmids ) { if ( topPwmData . containsKey ( id )) { topPwmData . put ( id , Math . max ( topPwmData . get ( id ), tcoef )); } else { topPwmData . put ( id , tcoef ); } } } // Create PWM table for upload FileWriter fw = new FileWriter ( \"grn_pwms.tsv\" ); fw . write ( \"PWM\\tCoefficient\\n\" ); for ( String id : topPwmData . keySet ()) { fw . write ( id + \"\\t\" + topPwmData . get ( id ) + \"\\n\" ); } fw . close (); // Import PWM table client . importTable ( \"grn_pwms.tsv\" , mealrOutputPath , \"MEALR_positive_coefficients Top 50 GRN PWMs\" , false , GxHttpClient . ColumnDelimiter . Tab , 1 , 2 , \"\" , \"PWM\" , false , \"Matrices: TRANSFAC\" , species ); // Sometimes a short interruption is required to allow processes // on the server complete their work Thread . sleep ( 1000 ); String grnPwmPath = mealrOutputPath + \"/MEALR_positive_coefficients Top 50 GRN PWMs\" ; transfacProfile = \"databases/TRANSFAC(R) 2022.1/Data/profiles/vertebrate_human_p0.001_non3d\" ; String grnPwmProfile = grnPwmPath + \" profile\" ; params = new JsonObject () . add ( \"table\" , grnPwmPath ) . add ( \"profile\" , transfacProfile ) . add ( \"outputProfile\" , grnPwmProfile ); // Create Match(TM) profile for PWMs of potential GRN factors client . analyze ( \"Create profile from site model table\" , params , false , true , true ); String grnMatchPath = grnPwmProfile + \" Match\" ; params = new JsonObject () . add ( \"sequencePath\" , folderPath + \"/jurkat_chipseq_hg38\" ) . add ( \"dbSelector\" , \"Ensembl 104.38 Human (hg38)\" ) . add ( \"profilePath\" , grnPwmProfile ) . add ( \"withoutDuplicates\" , true ) . add ( \"ignoreCore\" , true ) . add ( \"output\" , grnMatchPath ); // Predict binding sites of GRN factors in TAL1-bound regions client . analyze ( \"TRANSFAC(R) Match(TM) for tracks\" , params , false , true , true ); // // Step 10. Prediction of binding sites of identified TFs around // TAL1 transcription start site // // Create TAL1 gene table for import fw = new FileWriter ( \"tal1.tsv\" ); fw . write ( \"ID\\tSymbol\\nENSG00000162367\\tTAL1\\n\" ); fw . close (); // Import TAL1 gene client . importTable ( \"tal1.tsv\" , mealrOutputPath , \"TAL1 gene\" , false , GxHttpClient . ColumnDelimiter . Tab , 1 , 2 , \"\" , \"ID\" , false , \"Genes: Ensembl\" , species ); // Sometimes a short interruption is required to allow processes // on the server complete their work Thread . sleep ( 1000 ); String tal1GenePath = mealrOutputPath + \"/TAL1 gene\" ; String tal1TrackPath = tal1GenePath + \" promoter\" ; params = new JsonObject () . add ( \"sourcePath\" , tal1GenePath ) . add ( \"species\" , species ) . add ( \"from\" , 2000 ) . add ( \"to\" , 1000 ) . add ( \"destPath\" , tal1TrackPath ); // Create track of genomic region around TAL1 TSS (promoter) client . analyze ( \"Gene set to track\" , params , false , true , true ); String tal1MatchPath = grnPwmProfile + \" TAL1 Match\" ; params = new JsonObject () . add ( \"sequencePath\" , tal1TrackPath ) . add ( \"dbSelector\" , \"Ensembl 104.38 Human (hg38)\" ) . add ( \"profilePath\" , grnPwmProfile ) . add ( \"withoutDuplicates\" , true ) . add ( \"ignoreCore\" , true ) . add ( \"output\" , tal1MatchPath ); // Predict binding sites of GRN factors in TAL1 promoter client . analyze ( \"TRANSFAC(R) Match(TM) for tracks\" , params , false , true , true ); fileExport = new FileOutputStream ( \"TAL1_grn_pwm_sites.bed\" ); // Export genomic locations of predicted sites for GRN factors // around TAL1 TSS client . export ( tal1MatchPath , \"BED format (*.bed)\" , fileExport , new JsonObject ()); fileExport . close (); con . logout (); } }","title":"Java program"},{"location":"chipseq_analysis_java.html#chip-seq-data-analysis-with-a-java-program-based-on-genexplain-api","text":"The Java code below implements the tutorial workflow . The described steps are indicated in code comments for reference.","title":"ChIP-seq data analysis with a Java program based on genexplain-api"},{"location":"chipseq_analysis_java.html#compiling-and-executing-the-tutorial","text":"The Java code is provided with the tutorial material as GenexplainTutorialChipseqAnalysis.java . Please note that some parts require editing before running the program, including username, password, project name. Assuming the source file is stored as GenexplainTutorialChipseqAnalysis.java and the genexplain-api package is located in the same subfolder, the Java class can be compiled as follows. 1 javac -cp .:genexplain-api.jar GenexplainTutorialChipseqAnalysis.java Similarly, the class file can then be executed as 1 java -cp .:genexplain-api.jar GenexplainTutorialChipseqAnalysis","title":"Compiling and executing the tutorial"},{"location":"chipseq_analysis_java.html#java-code-for-the-tutorial-workflow","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 import com.eclipsesource.json.JsonArray ; import com.eclipsesource.json.JsonValue ; import com.eclipsesource.json.JsonObject ; import com.eclipsesource.json.PrettyPrint ; import com.genexplain.api.core.GxHttpClient ; import com.genexplain.api.core.GxHttpClientImpl ; import com.genexplain.api.core.GxHttpConnection ; import com.genexplain.api.core.GxHttpConnectionImpl ; import java.io.FileOutputStream ; import java.io.FileWriter ; import java.io.StringWriter ; import java.io.Writer ; import java.util.HashMap ; import java.util.Map ; public class GenexplainTutorialChipseqAnalysis { public static void main ( String [] args ) throws Exception { // The GxHttpConnectionImpl holds the connection to the specified // platform server. Username and password need to correspond to a // valid account on that server. // GxHttpConnectionImpl con = new GxHttpConnectionImpl (); con . setServer ( \"https://platform.genexplain.com\" ); con . setUsername ( \"someuser@email.io\" ); con . setPassword ( \"12345\" ); con . setVerbose ( true ); con . login (); // The connection is given to a client object. The client is the // main component to interact with the connected platform server. // GxHttpClientImpl client = new GxHttpClientImpl (); client . setConnection ( con ); // The createProject method creates a new project in the user // workspace. The project name must be new and unique on the // platform instance. The platform path of the new project is // \"data/Projects/<project name>\". // Map < String , String > projectParams = new HashMap <> (); projectParams . put ( \"user\" , \"someuser@email.io\" ); projectParams . put ( \"pass\" , \"12345\" ); projectParams . put ( \"project\" , \"api2022_tutorial\" ); projectParams . put ( \"description\" , \"API 2022 tutorial project\" ); client . createProject ( projectParams ) String folderPath = \"data/Projects/api2022_tutorial/Data/chipseq_analysis_workflow_java\" ; String species = \"Human (Homo sapiens)\" ; // The createFolder function creates the folder if it does not // already exist. Within a project, folders for data elements // have to be created within the *Data* folder or its subfolders. // client . createFolder ( \"data/Projects/api2022_tutorial/Data\" , \"chipseq_analysis_workflow_java\" ); // // Step 1. Import and mapping of TAL1-bound genomic regions // JsonObject params = new JsonObject (). add ( \"dbSelector\" , \"Ensembl 52.36n Human (hg18)\" ); // Import the BED file with TAL1-bound regions into the destination folder client . imPort ( \"../data/GSM614003_jurkat.tal1.bed\" , folderPath , \"BED format (*.bed)\" , params ); // Sometimes a short interruption is required to allow processes // on the server complete their work Thread . sleep ( 1000 ); String bedPath = folderPath + \"/GSM614003_jurkat.tal1\" ; String mappedPath = folderPath + \"/jurkat_chipseq_hg38\" ; String unmappedPath = folderPath + \"/jurkat_chipseq_hg38_unmapped\" ; String mapping = \"hg18->hg38\" ; params = new JsonObject () . add ( \"input\" , bedPath ) . add ( \"mapping\" , mapping ) . add ( \"minMatch\" , 0.95 ) . add ( \"out_file1\" , mappedPath ) . add ( \"out_file2\" , unmappedPath ); // Run Liftover to map hg18 coordinates to hg38 client . analyze ( \"liftOver1\" , params , false , true , true ); // // Step 2. Mapping TAL1-bound genomic regions to nearby genes // String mappedGenePath = mappedPath + \" Genes\" ; JsonArray sourcePaths = new JsonArray (). add ( mappedPath ); params = new JsonObject () . add ( \"sourcePaths\" , sourcePaths ) . add ( \"species\" , species ) . add ( \"from\" , - 5000 ) . add ( \"to\" , 2000 ) . add ( \"destPath\" , mappedGenePath ); // Run \"Track to gene set\" tool to map genomic coordinates to genes client . analyze ( \"Track to gene set\" , params , false , true , true ); // // Step 3. Functional enrichment analysis of genes near TAL1-bound // regions // String funclassResultPath = mappedGenePath + \" GO\" ; params = new JsonObject () . add ( \"sourcePath\" , mappedGenePath ) . add ( \"species\" , species ) . add ( \"bioHub\" , \"Full gene ontology classification\" ) . add ( \"minHits\" , 1 ) . add ( \"pvalueThreshold\" , 1 ) . add ( \"outputTable\" , funclassResultPath ); // Enrichment of genes associated with Gene Ontology terms using // \"Functional classification\" client . analyze ( \"Functional classification\" , params , false , true , true ); FileOutputStream fileExport = new FileOutputStream ( \"functional_classification_result_GO.tsv\" ); // Export analysis result to local file client . export ( funclassResultPath , \"Tab-separated text (*.txt)\" , fileExport , new JsonObject ()); // The output stream is not closed by the platform client. fileExport . close (); funclassResultPath = mappedGenePath + \" Reactome\" ; params . add ( \"bioHub\" , \"Reactome pathways (74)\" ). add ( \"outputTable\" , funclassResultPath ); // Enrichment of genes associated with Reactome pathways client . analyze ( \"Functional classification\" , params , false , true , true ); fileExport = new FileOutputStream ( \"functional_classification_result_Reactome.tsv\" ); // Export analysis result to local file client . export ( funclassResultPath , \"Tab-separated text (*.txt)\" , fileExport , new JsonObject ()); fileExport . close (); funclassResultPath = mappedGenePath + \" Human disease biomarkers\" ; params . add ( \"bioHub\" , \"HumanPSD(TM) disease (2022.1)\" ). add ( \"outputTable\" , funclassResultPath ); // Enrichment of genes associated with human diseases based on // HumanPSD disease biomarker annotation client . analyze ( \"Functional classification\" , params , false , true , true ); fileExport = new FileOutputStream ( \"functional_classification_result_HumanPSD.tsv\" ); // Export analysis result to local file client . export ( funclassResultPath , \"Tab-separated text (*.txt)\" , fileExport , new JsonObject ()); fileExport . close (); // // Step 4. Sampling genomic regions not bound by TAL1 // String mealrBackgroundTrack = mappedPath + \" random 1000\" ; params = new JsonObject () . add ( \"inputTrackPath\" , mappedPath ) . add ( \"dbSelector\" , \"Ensembl 104.38 Human (hg38)\" ) . add ( \"species\" , species ) . add ( \"standardChromosomes\" , true ) . add ( \"seqNumber\" , 1000 ) . add ( \"seqLength\" , 0 ) . add ( \"from\" , 0 ) . add ( \"to\" , 0 ) . add ( \"withOverlap\" , false ) . add ( \"randomShift\" , false ) . add ( \"outputTrackPath\" , mealrBackgroundTrack ) . add ( \"randSeed\" , 123 ); // Create random track not overlapping with TAL1-bound regions client . analyze ( \"Create random track\" , params , false , true , true ); // // Step 5. Import and mapping of TAL1 binding site subset // // Data upload and lifting as in Step 1 for 1000 TAL1 sites sampled // from the original BED file params = new JsonObject (). add ( \"dbSelector\" , \"Ensembl 52.36n Human (hg18)\" ); // Import sampled TAL1 ChIP-seq sites client . imPort ( \"../data/GSM614003_jurkat.tal1_1000.bed\" , folderPath , \"BED format (*.bed)\" , params ); // Sometimes a short interruption is required to allow processes // on the server complete their work Thread . sleep ( 1000 ); bedPath = folderPath + \"/GSM614003_jurkat.tal1_1000\" ; mappedPath = folderPath + \"/jurkat_chipseq_hg38_1000\" ; unmappedPath = folderPath + \"/jurkat_chipseq_hg38_1000_unmapped\" ; params = new JsonObject () . add ( \"input\" , bedPath ) . add ( \"mapping\" , mapping ) . add ( \"minMatch\" , 0.95 ) . add ( \"out_file1\" , mappedPath ) . add ( \"out_file2\" , unmappedPath ); // Coordinate mapping to hg38 client . analyze ( \"liftOver1\" , params , false , true , true ); // // Step 6. Selection of important PWM models using MEALR // String mealrOutputPath = mappedPath + \" MEALR\" ; String transfacProfile = \"databases/TRANSFAC(R) 2022.1/Data/profiles/vertebrate_human_p0.05_non3d\" ; params = new JsonObject () . add ( \"yesSetPath\" , mappedPath ) . add ( \"noSetPath\" , mealrBackgroundTrack ) . add ( \"dbSelector\" , \"Ensembl 104.38 Human (hg38)\" ) . add ( \"profilePath\" , transfacProfile ) . add ( \"maxPosCoef\" , 150 ) . add ( \"maxComplexity\" , 0.5 ) . add ( \"complexityInc\" , 0.02 ) . add ( \"maxUnimproved\" , 20 ) . add ( \"scoresWithNoSet\" , false ) . add ( \"output\" , mealrOutputPath ); // Analyze target and background genomic regions using MEALR client . analyze ( \"MEALR (tracks)\" , params , false , true , true ); // // Step 7. Extraction of binding transcription factors // String mealrMotifPath = mealrOutputPath + \"/MEALR_positive_coefficients\" ; String mealrTopPath = mealrMotifPath + \" Top 50\" ; params = new JsonObject () . add ( \"inputTable\" , mealrMotifPath ) . add ( \"column\" , \"Coefficient\" ) . add ( \"types\" , new JsonArray (). add ( \"Top\" )) . add ( \"topPercent\" , 100.0 ) . add ( \"topCount\" , 50 ) . add ( \"topMinCount\" , 50 ) . add ( \"topTable\" , mealrTopPath ); // Extract top 50 PWMs ranked by logistic regression coefficient client . analyze ( \"Select top rows\" , params , false , true , true ); String mealrTopGenePath = mealrTopPath + \" Genes\" ; params = new JsonObject () . add ( \"sitesCollection\" , mealrTopPath ) . add ( \"siteModelsCollection\" , transfacProfile ) . add ( \"species\" , species ) . add ( \"targetType\" , \"Genes: Ensembl\" ) . add ( \"outputTable\" , mealrTopGenePath ); // Convert PWMs to factor genes client . analyze ( \"Matrices to molecules\" , params , false , true , true ); // // Step 8. Intersection of potentially TAL1-regulated genes and // MEALR TFs // String mappedNearbyGenePath = folderPath + \"/jurkat_chipseq_hg38 Genes\" ; String mealrTopVennPath = mealrTopPath + \" Venn\" ; params = new JsonObject () . add ( \"table1Path\" , mappedNearbyGenePath ) . add ( \"table1Name\" , \"Genes near TAL1 sites\" ) . add ( \"table2Path\" , mealrTopGenePath ) . add ( \"table2Name\" , \"MEALR transcription factors\" ) . add ( \"simple\" , true ) . add ( \"output\" , mealrTopVennPath ); // Intersect factors identified by MEALR and genes with nearby // TAL1 ChIP-seq sites client . analyze ( \"Venn diagrams\" , params , false , true , true ); // // Step 9. Prediction of binding sites of identified TFs in // TAL1-bound genomic regions // String grnFactorPath = mealrTopVennPath + \"/Rows present in both tables\" ; // Load table with potential GRN factors JsonObject tableData = client . getTable ( grnFactorPath ); // The JSON object contains the table data under property // \"data\" JsonArray topPwms = tableData . get ( \"data\" ). asArray (). get ( 3 ). asArray (); JsonArray topCoefs = tableData . get ( \"data\" ). asArray (). get ( 4 ). asArray (); String tpwms ; String [] pwmids ; double tcoef ; Map < String , Double > topPwmData = new HashMap <> (); // Extract PWM ids and coefficients for ( int t = 0 ; t < topPwms . size (); ++ t ) { tpwms = topPwms . get ( t ). asString (); tcoef = topCoefs . get ( t ). asDouble (); pwmids = tpwms . split ( \",\" ); for ( String id : pwmids ) { if ( topPwmData . containsKey ( id )) { topPwmData . put ( id , Math . max ( topPwmData . get ( id ), tcoef )); } else { topPwmData . put ( id , tcoef ); } } } // Create PWM table for upload FileWriter fw = new FileWriter ( \"grn_pwms.tsv\" ); fw . write ( \"PWM\\tCoefficient\\n\" ); for ( String id : topPwmData . keySet ()) { fw . write ( id + \"\\t\" + topPwmData . get ( id ) + \"\\n\" ); } fw . close (); // Import PWM table client . importTable ( \"grn_pwms.tsv\" , mealrOutputPath , \"MEALR_positive_coefficients Top 50 GRN PWMs\" , false , GxHttpClient . ColumnDelimiter . Tab , 1 , 2 , \"\" , \"PWM\" , false , \"Matrices: TRANSFAC\" , species ); // Sometimes a short interruption is required to allow processes // on the server complete their work Thread . sleep ( 1000 ); String grnPwmPath = mealrOutputPath + \"/MEALR_positive_coefficients Top 50 GRN PWMs\" ; transfacProfile = \"databases/TRANSFAC(R) 2022.1/Data/profiles/vertebrate_human_p0.001_non3d\" ; String grnPwmProfile = grnPwmPath + \" profile\" ; params = new JsonObject () . add ( \"table\" , grnPwmPath ) . add ( \"profile\" , transfacProfile ) . add ( \"outputProfile\" , grnPwmProfile ); // Create Match(TM) profile for PWMs of potential GRN factors client . analyze ( \"Create profile from site model table\" , params , false , true , true ); String grnMatchPath = grnPwmProfile + \" Match\" ; params = new JsonObject () . add ( \"sequencePath\" , folderPath + \"/jurkat_chipseq_hg38\" ) . add ( \"dbSelector\" , \"Ensembl 104.38 Human (hg38)\" ) . add ( \"profilePath\" , grnPwmProfile ) . add ( \"withoutDuplicates\" , true ) . add ( \"ignoreCore\" , true ) . add ( \"output\" , grnMatchPath ); // Predict binding sites of GRN factors in TAL1-bound regions client . analyze ( \"TRANSFAC(R) Match(TM) for tracks\" , params , false , true , true ); // // Step 10. Prediction of binding sites of identified TFs around // TAL1 transcription start site // // Create TAL1 gene table for import fw = new FileWriter ( \"tal1.tsv\" ); fw . write ( \"ID\\tSymbol\\nENSG00000162367\\tTAL1\\n\" ); fw . close (); // Import TAL1 gene client . importTable ( \"tal1.tsv\" , mealrOutputPath , \"TAL1 gene\" , false , GxHttpClient . ColumnDelimiter . Tab , 1 , 2 , \"\" , \"ID\" , false , \"Genes: Ensembl\" , species ); // Sometimes a short interruption is required to allow processes // on the server complete their work Thread . sleep ( 1000 ); String tal1GenePath = mealrOutputPath + \"/TAL1 gene\" ; String tal1TrackPath = tal1GenePath + \" promoter\" ; params = new JsonObject () . add ( \"sourcePath\" , tal1GenePath ) . add ( \"species\" , species ) . add ( \"from\" , 2000 ) . add ( \"to\" , 1000 ) . add ( \"destPath\" , tal1TrackPath ); // Create track of genomic region around TAL1 TSS (promoter) client . analyze ( \"Gene set to track\" , params , false , true , true ); String tal1MatchPath = grnPwmProfile + \" TAL1 Match\" ; params = new JsonObject () . add ( \"sequencePath\" , tal1TrackPath ) . add ( \"dbSelector\" , \"Ensembl 104.38 Human (hg38)\" ) . add ( \"profilePath\" , grnPwmProfile ) . add ( \"withoutDuplicates\" , true ) . add ( \"ignoreCore\" , true ) . add ( \"output\" , tal1MatchPath ); // Predict binding sites of GRN factors in TAL1 promoter client . analyze ( \"TRANSFAC(R) Match(TM) for tracks\" , params , false , true , true ); fileExport = new FileOutputStream ( \"TAL1_grn_pwm_sites.bed\" ); // Export genomic locations of predicted sites for GRN factors // around TAL1 TSS client . export ( tal1MatchPath , \"BED format (*.bed)\" , fileExport , new JsonObject ()); fileExport . close (); con . logout (); } }","title":"Java code for the tutorial workflow"},{"location":"chipseq_analysis_json.html","text":"ChIP-seq data analysis using the genexplain-api JSON interface The JSON document below executes the tutorial workflow using the exec program of the Java package with a command like the following. The JSON file is provided with the tutorial material as genexplain_tutorial_chipseq_analysis.json . 1 java -jar genexplain-api.jar exec genexplain_tutorial_chipseq_analysis.json The described workflow steps are indicated in comments for reference. Please note that the JSON properties user and password , possibly also server , need to be altered to valid parameters. The external scripts waitns.sh , chipseq_analysis_grn_pwms.py , chipseq_analysis_tal1.py are provided with the tutorial material. The script paths ( $WAIT_SCRIPT , $PWM_ID_SCRIPT , $TAL1_GENE_SCRIPT ) in the JSON configuration may require adjustment. The JSON document assumes an existing platform project. It was named api2022_tutorial as example. To run execute the workflow a new project needs to be created and the value assigned to $PARENT_FOLDER (currently data/Projects/api2022_tutorial/Data ) needs to be adjusted. Similarly, the tutorial paths assigned to $CHIPSEQ_BED_ALL and $CHIPSEQ_BED_SAMPLE may require adjustment. JSON configuration for the tutorial workflow 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 { \"server\" : \"https://platform.genexplain.com\" , \"user\" : \"someuser@email.io\" , \"password\" : \"12345\" , \"reconnect\" : true , \"replaceStrings\" : [ [ \"$SPECIES\" , \"Human (Homo sapiens)\" ], [ \"$GENOME_MAPPING\" , \"hg18->hg38\" ], [ \"$ENSEMBL_104_SELECTOR\" , \"Ensembl 104.38 Human (hg38)\" ], [ \"$MEALR_TRANSFAC_PROFILE\" , \"databases/TRANSFAC(R) 2022.1/Data/profiles/vertebrate_human_p0.05_non3d\" ], [ \"$GRN_TRANSFAC_PROFILE\" , \"databases/TRANSFAC(R) 2022.1/Data/profiles/vertebrate_human_p0.001_non3d\" ], [ \"$BED_PATH_ALL\" , \"$FOLDER_PATH/GSM614003_jurkat.tal1\" ], [ \"$MAPPED_GENES_GO_PATH\" , \"$MAPPED_GENE_PATH_ALL GO\" ], [ \"$MAPPED_GENES_REACTOME_PATH\" , \"$MAPPED_GENE_PATH_ALL Reactome\" ], [ \"$MAPPED_GENES_HUMANPSD_PATH\" , \"$MAPPED_GENE_PATH_ALL Human disease biomarkers\" ], [ \"$MAPPED_GENE_PATH_ALL\" , \"$MAPPED_PATH_ALL Genes\" ], [ \"$MEALR_BACKGROUND_PATH\" , \"$MAPPED_PATH_ALL random 1000\" ], [ \"$MAPPED_PATH_ALL\" , \"$FOLDER_PATH/jurkat_chipseq_hg38\" ], [ \"$UNMAPPED_PATH_ALL\" , \"$FOLDER_PATH/jurkat_chipseq_hg38_unmapped\" ], [ \"$BED_PATH_SAMPLE\" , \"$FOLDER_PATH/GSM614003_jurkat.tal1_1000\" ], [ \"$MEALR_TOP_GENE_PATH\" , \"$MEALR_TOP_PATH Genes\" ], [ \"$GRN_FACTOR_PATH\" , \"$MEALR_VENN_PATH/Rows present in both tables\" ], [ \"$GRN_MATCH_PATH\" , \"$GRN_PWM_PROFILE Match\" ], [ \"$TAL1_MATCH_PATH\" , \"$GRN_PWM_PROFILE TAL1 Match\" ], [ \"$GRN_PWM_PROFILE\" , \"$GRN_PWM_PATH profile\" ], [ \"$GRN_PWM_PATH\" , \"$MEALR_OUTPUT_PATH/grn_pwms\" ], [ \"$TAL1_TRACK_PATH\" , \"$TAL1_GENE_PATH promoter\" ], [ \"$TAL1_GENE_PATH\" , \"$MEALR_OUTPUT_PATH/tal1\" ], [ \"$MEALR_VENN_PATH\" , \"$MEALR_TOP_PATH Venn\" ], [ \"$MEALR_TOP_PATH\" , \"$MEALR_MOTIF_PATH Top 50\" ], [ \"$MEALR_MOTIF_PATH\" , \"$MEALR_OUTPUT_PATH/MEALR_positive_coefficients\" ], [ \"$MEALR_OUTPUT_PATH\" , \"$MAPPED_PATH_SAMPLE MEALR\" ], [ \"$MAPPED_PATH_SAMPLE\" , \"$FOLDER_PATH/jurkat_chipseq_hg38_1000\" ], [ \"$UNMAPPED_PATH_SAMPLE\" , \"$FOLDER_PATH/jurkat_chipseq_hg38_1000_unmapped\" ], [ \"$FOLDER_PATH\" , \"$PARENT_FOLDER$/$FOLDER_NAME$\" ], [ \"$PARENT_FOLDER$\" , \"data/Projects/api2022_tutorial/Data\" ], [ \"$FOLDER_NAME$\" , \"chipseq_analysis_workflow_json\" ], [ \"$CHIPSEQ_BED_ALL\" , \"../data/GSM614003_jurkat.tal1.bed\" ], [ \"$CHIPSEQ_BED_SAMPLE\" , \"../data/GSM614003_jurkat.tal1_1000.bed\" ], [ \"$WAIT_SCRIPT\" , \"waitns.sh\" ], [ \"$PWM_ID_SCRIPT\" , \"chipseq_analysis_grn_pwms.py\" ], [ \"$TAL1_GENE_SCRIPT\" , \"chipseq_analysis_tal1.py\" ] ], \"tasks\" : [ { \"do\" : \"createFolder\" , \"showOutput\" : true , \"path\" : \"$PARENT_FOLDER$\" , \"name\" : \"$FOLDER_NAME$\" , \"comment\" : \"Prepare folder for analysis data and results\" }, { \"do\" : \"imPort\" , \"file\" : \"$CHIPSEQ_BED_ALL\" , \"path\" : \"$FOLDER_PATH\" , \"importer\" : \"BED format (*.bed)\" , \"verbose\" : true , \"parameters\" : { \"dbSelector\" : \"Ensembl 52.36n Human (hg18)\" }, \"comment\" : \"Step 1.1 Import the BED file with TAL1-bound regions into the destination folder\" }, { \"do\" : \"external\" , \"showOutput\" : true , \"bin\" : \"sh\" , \"params\" : [ \"$WAIT_SCRIPT\" ], \"comment\" : \"Run external script to allow server process to finish before using imported data\" }, { \"do\" : \"analyze\" , \"method\" : \"liftOver1\" , \"workflow\" : false , \"wait\" : true , \"progress\" : true , \"parameters\" : { \"input\" : \"$BED_PATH_ALL\" , \"mapping\" : \"$GENOME_MAPPING\" , \"minMatch\" : 0.95 , \"out_file1\" : \"$MAPPED_PATH_ALL\" , \"out_file2\" : \"$UNMAPPED_PATH_ALL\" }, \"comment\" : \"Step 1.2 Run Liftover to map hg18 coordinates to hg38\" }, { \"do\" : \"analyze\" , \"method\" : \"Track to gene set\" , \"workflow\" : false , \"wait\" : true , \"progress\" : true , \"parameters\" : { \"sourcePaths\" : [ \"$MAPPED_PATH_ALL\" ], \"species\" : \"$SPECIES\" , \"from\" : -5000 , \"to\" : 2000 , \"destPath\" : \"$MAPPED_GENE_PATH_ALL\" }, \"comment\" : \"Step 2. Run 'Track to gene set' tool to map genomic coordinates to genes\" }, { \"do\" : \"analyze\" , \"method\" : \"Functional classification\" , \"workflow\" : false , \"wait\" : true , \"progress\" : true , \"parameters\" : { \"sourcePath\" : \"$MAPPED_GENE_PATH_ALL\" , \"species\" : \"$SPECIES\" , \"bioHub\" : \"Full gene ontology classification\" , \"minHits\" : 1 , \"pvalueThreshold\" : 1 , \"outputTable\" : \"$MAPPED_GENES_GO_PATH\" }, \"comment\" : \"Step 3.1 Enrichment of genes associated with Gene Ontology terms using 'Functional classification'\" }, { \"do\" : \"export\" , \"file\" : \"functional_classification_result_GO.tsv\" , \"path\" : \"$MAPPED_GENES_GO_PATH\" , \"exporter\" : \"Tab-separated text (*.txt)\" , \"parameters\" : {}, \"comment\" : \"Step 3.2 Export analysis results to local file\" }, { \"do\" : \"analyze\" , \"method\" : \"Functional classification\" , \"workflow\" : false , \"wait\" : true , \"progress\" : true , \"parameters\" : { \"sourcePath\" : \"$MAPPED_GENE_PATH_ALL\" , \"species\" : \"$SPECIES\" , \"bioHub\" : \"Reactome pathways (74)\" , \"minHits\" : 1 , \"pvalueThreshold\" : 1 , \"outputTable\" : \"$MAPPED_GENES_REACTOME_PATH\" }, \"comment\" : \"Step 3.3 Enrichment of genes associated with Reactome pathways using 'Functional classification'\" }, { \"do\" : \"export\" , \"file\" : \"functional_classification_result_Reactome.tsv\" , \"path\" : \"$MAPPED_GENES_REACTOME_PATH\" , \"exporter\" : \"Tab-separated text (*.txt)\" , \"parameters\" : {}, \"comment\" : \"Step 3.4 Export analysis results to local file\" }, { \"do\" : \"analyze\" , \"method\" : \"Functional classification\" , \"workflow\" : false , \"wait\" : true , \"progress\" : true , \"parameters\" : { \"sourcePath\" : \"$MAPPED_GENE_PATH_ALL\" , \"species\" : \"$SPECIES\" , \"bioHub\" : \"HumanPSD(TM) disease (2022.1)\" , \"minHits\" : 1 , \"pvalueThreshold\" : 1 , \"outputTable\" : \"$MAPPED_GENES_HUMANPSD_PATH\" }, \"comment\" : \"Step 3.5 Enrichment of biomarkers of human diseases annotated in the HumanPSD knowledgebase\" }, { \"do\" : \"export\" , \"file\" : \"functional_classification_result_HumanPSD.tsv\" , \"path\" : \"$MAPPED_GENES_HUMANPSD_PATH\" , \"exporter\" : \"Tab-separated text (*.txt)\" , \"parameters\" : {}, \"comment\" : \"Step 3.6 Export analysis results to local file\" }, { \"do\" : \"analyze\" , \"method\" : \"Create random track\" , \"workflow\" : false , \"wait\" : true , \"progress\" : true , \"parameters\" : { \"inputTrackPath\" : \"$MAPPED_PATH_ALL\" , \"dbSelector\" : \"$ENSEMBL_104_SELECTOR\" , \"species\" : \"$SPECIES\" , \"standardChromosomes\" : true , \"seqNumber\" : 1000 , \"seqLength\" : 0 , \"from\" : 0 , \"to\" : 0 , \"withOverlap\" : false , \"randomShift\" : false , \"outputTrackPath\" : \"$MEALR_BACKGROUND_PATH\" , \"randSeed\" : 123 }, \"comment\" : \"Step 4. Create random track not overlapping with TAL1-bound regions\" }, { \"do\" : \"imPort\" , \"file\" : \"$CHIPSEQ_BED_SAMPLE\" , \"path\" : \"$FOLDER_PATH\" , \"importer\" : \"BED format (*.bed)\" , \"verbose\" : true , \"parameters\" : { \"dbSelector\" : \"Ensembl 52.36n Human (hg18)\" }, \"comment\" : \"Step 5.1 Import sampled TAL1 ChIP-seq sites\" }, { \"do\" : \"external\" , \"showOutput\" : true , \"bin\" : \"sh\" , \"params\" : [ \"$WAIT_SCRIPT\" ], \"comment\" : \"Run external script to allow server process to finish before using imported data\" }, { \"do\" : \"analyze\" , \"method\" : \"liftOver1\" , \"workflow\" : false , \"wait\" : true , \"progress\" : true , \"parameters\" : { \"input\" : \"$BED_PATH_SAMPLE\" , \"mapping\" : \"$GENOME_MAPPING\" , \"minMatch\" : 0.95 , \"out_file1\" : \"$MAPPED_PATH_SAMPLE\" , \"out_file2\" : \"$UNMAPPED_PATH_SAMPLE\" }, \"comment\" : \"Step 5.2 Map coordinates from hg18 to hg38\" }, { \"do\" : \"analyze\" , \"method\" : \"MEALR (tracks)\" , \"workflow\" : false , \"wait\" : true , \"progress\" : true , \"parameters\" : { \"yesSetPath\" : \"$MAPPED_PATH_SAMPLE\" , \"noSetPath\" : \"$MEALR_BACKGROUND_PATH\" , \"dbSelector\" : \"$ENSEMBL_104_SELECTOR\" , \"profilePath\" : \"$MEALR_TRANSFAC_PROFILE\" , \"maxPosCoef\" : 150 , \"maxComplexity\" : 0.5 , \"complexityInc\" : 0.02 , \"maxUnimproved\" : 20 , \"scoresWithNoSet\" : false , \"output\" : \"$MEALR_OUTPUT_PATH\" }, \"comment\" : \"Step 6. Analyze target and background genomic regions using MEALR to find important PWMs\" }, { \"do\" : \"analyze\" , \"method\" : \"Select top rows\" , \"workflow\" : false , \"wait\" : true , \"progress\" : true , \"parameters\" : { \"inputTable\" : \"$MEALR_MOTIF_PATH\" , \"column\" : \"Coefficient\" , \"types\" : [ \"Top\" ], \"topPercent\" : 100.0 , \"topCount\" : 50 , \"topMinCount\" : 50 , \"topTable\" : \"$MEALR_TOP_PATH\" }, \"comment\" : \"Step 7.1 Extract top 50 PWMs ranked by logistic regression coefficient\" }, { \"do\" : \"analyze\" , \"method\" : \"Matrices to molecules\" , \"workflow\" : false , \"wait\" : true , \"progress\" : true , \"parameters\" : { \"sitesCollection\" : \"$MEALR_TOP_PATH\" , \"siteModelsCollection\" : \"$MEALR_TRANSFAC_PROFILE\" , \"species\" : \"$SPECIES\" , \"targetType\" : \"Genes: Ensembl\" , \"outputTable\" : \"$MEALR_TOP_GENE_PATH\" }, \"comment\" : \"Step 7.2 Convert PWMs to factor genes\" }, { \"do\" : \"analyze\" , \"method\" : \"Venn diagrams\" , \"workflow\" : false , \"wait\" : true , \"progress\" : true , \"parameters\" : { \"table1Path\" : \"$MAPPED_GENE_PATH_ALL\" , \"table1Name\" : \"Genes near TAL1 sites\" , \"table2Path\" : \"$MEALR_TOP_GENE_PATH\" , \"table2Name\" : \"MEALR transcription factors\" , \"simple\" : true , \"output\" : \"$MEALR_VENN_PATH\" }, \"comment\" : \"Step 8 Intersect factors identified by MEALR and genes with nearby TAL1 ChIP-seq sites\" }, { \"do\" : \"get\" , \"table\" : \"$GRN_FACTOR_PATH\" , \"toFile\" : \"grn_factors.json\" , \"comment\" : \"Step 9.1 Download table with potential GRN factors to local file\" }, { \"do\" : \"external\" , \"bin\" : \"python3\" , \"params\" : [ \"$PWM_ID_SCRIPT\" ], \"comment\" : \"Step 9.2 Run external script to create PWM table\" }, { \"do\" : \"imPort\" , \"file\" : \"grn_pwms.tsv\" , \"path\" : \"$MEALR_OUTPUT_PATH\" , \"importer\" : \"Tabular (*.txt, *.xls, *.tab, etc.)\" , \"parameters\" : { \"columnForID\" : \"PWM\" , \"tableType\" : \"Matrices: TRANSFAC\" , \"species\" : \"Human (Homo sapiens)\" }, \"comment\" : \"Step 9.3 Import PWM table created by external script\" }, { \"do\" : \"external\" , \"showOutput\" : true , \"bin\" : \"sh\" , \"params\" : [ \"$WAIT_SCRIPT\" ], \"comment\" : \"Run external script to allow server process to finish before using imported data\" }, { \"do\" : \"analyze\" , \"method\" : \"Create profile from site model table\" , \"workflow\" : false , \"wait\" : true , \"progress\" : true , \"parameters\" : { \"table\" : \"$GRN_PWM_PATH\" , \"profile\" : \"$GRN_TRANSFAC_PROFILE\" , \"outputProfile\" : \"$GRN_PWM_PROFILE\" }, \"comment\" : \"Step 9.4 Create Match(TM) profile for PWMs of potential GRN factors\" }, { \"do\" : \"analyze\" , \"method\" : \"TRANSFAC(R) Match(TM) for tracks\" , \"workflow\" : false , \"wait\" : true , \"progress\" : true , \"parameters\" : { \"sequencePath\" : \"$MAPPED_PATH_ALL\" , \"dbSelector\" : \"$ENSEMBL_104_SELECTOR\" , \"profilePath\" : \"$GRN_PWM_PROFILE\" , \"withoutDuplicates\" : true , \"ignoreCore\" : true , \"output\" : \"$GRN_MATCH_PATH\" }, \"comment\" : \"Step 9.5 Predict binding sites of GRN factors in TAL1-bound regions\" }, { \"do\" : \"external\" , \"bin\" : \"python3\" , \"params\" : [ \"$TAL1_GENE_SCRIPT\" ], \"comment\" : \"Step 10.1 Run external script to prepare TAL1 gene table\" }, { \"do\" : \"imPort\" , \"file\" : \"tal1.tsv\" , \"path\" : \"$MEALR_OUTPUT_PATH\" , \"importer\" : \"Tabular (*.txt, *.xls, *.tab, etc.)\" , \"parameters\" : { \"columnForID\" : \"ID\" , \"tableType\" : \"Genes: Ensembl\" , \"species\" : \"Human (Homo sapiens)\" }, \"comment\" : \"Step 10.2 Import TAL1 gene table\" }, { \"do\" : \"external\" , \"showOutput\" : true , \"bin\" : \"sh\" , \"params\" : [ \"$WAIT_SCRIPT\" ], \"comment\" : \"Run external script to allow server process to finish before using imported data\" }, { \"do\" : \"analyze\" , \"method\" : \"Gene set to track\" , \"workflow\" : false , \"wait\" : true , \"progress\" : true , \"parameters\" : { \"sourcePath\" : \"$TAL1_GENE_PATH\" , \"species\" : \"$SPECIES\" , \"from\" : 2000 , \"to\" : 1000 , \"destPath\" : \"$TAL1_TRACK_PATH\" }, \"comment\" : \"Step 10.3 Create track of genomic region around TAL1 TSS (promoter)\" }, { \"do\" : \"analyze\" , \"method\" : \"TRANSFAC(R) Match(TM) for tracks\" , \"workflow\" : false , \"wait\" : true , \"progress\" : true , \"parameters\" : { \"sequencePath\" : \"$TAL1_TRACK_PATH\" , \"dbSelector\" : \"$ENSEMBL_104_SELECTOR\" , \"profilePath\" : \"$GRN_PWM_PROFILE\" , \"withoutDuplicates\" : true , \"ignoreCore\" : true , \"output\" : \"$TAL1_MATCH_PATH\" }, \"comment\" : \"Step 10.4 Predict binding sites of GRN factors in TAL1 promoter\" }, { \"do\" : \"export\" , \"file\" : \"TAL1_grn_pwm_sites.bed\" , \"path\" : \"$TAL1_MATCH_PATH\" , \"exporter\" : \"BED format (*.bed)\" , \"parameters\" : {}, \"comment\" : \"Step 10.5 Export genomic locations of predicted sites for GRN factors around TAL1 TSS\" } ] }","title":"JSON interface"},{"location":"chipseq_analysis_json.html#chip-seq-data-analysis-using-the-genexplain-api-json-interface","text":"The JSON document below executes the tutorial workflow using the exec program of the Java package with a command like the following. The JSON file is provided with the tutorial material as genexplain_tutorial_chipseq_analysis.json . 1 java -jar genexplain-api.jar exec genexplain_tutorial_chipseq_analysis.json The described workflow steps are indicated in comments for reference. Please note that the JSON properties user and password , possibly also server , need to be altered to valid parameters. The external scripts waitns.sh , chipseq_analysis_grn_pwms.py , chipseq_analysis_tal1.py are provided with the tutorial material. The script paths ( $WAIT_SCRIPT , $PWM_ID_SCRIPT , $TAL1_GENE_SCRIPT ) in the JSON configuration may require adjustment. The JSON document assumes an existing platform project. It was named api2022_tutorial as example. To run execute the workflow a new project needs to be created and the value assigned to $PARENT_FOLDER (currently data/Projects/api2022_tutorial/Data ) needs to be adjusted. Similarly, the tutorial paths assigned to $CHIPSEQ_BED_ALL and $CHIPSEQ_BED_SAMPLE may require adjustment.","title":"ChIP-seq data analysis using the genexplain-api JSON interface"},{"location":"chipseq_analysis_json.html#json-configuration-for-the-tutorial-workflow","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 { \"server\" : \"https://platform.genexplain.com\" , \"user\" : \"someuser@email.io\" , \"password\" : \"12345\" , \"reconnect\" : true , \"replaceStrings\" : [ [ \"$SPECIES\" , \"Human (Homo sapiens)\" ], [ \"$GENOME_MAPPING\" , \"hg18->hg38\" ], [ \"$ENSEMBL_104_SELECTOR\" , \"Ensembl 104.38 Human (hg38)\" ], [ \"$MEALR_TRANSFAC_PROFILE\" , \"databases/TRANSFAC(R) 2022.1/Data/profiles/vertebrate_human_p0.05_non3d\" ], [ \"$GRN_TRANSFAC_PROFILE\" , \"databases/TRANSFAC(R) 2022.1/Data/profiles/vertebrate_human_p0.001_non3d\" ], [ \"$BED_PATH_ALL\" , \"$FOLDER_PATH/GSM614003_jurkat.tal1\" ], [ \"$MAPPED_GENES_GO_PATH\" , \"$MAPPED_GENE_PATH_ALL GO\" ], [ \"$MAPPED_GENES_REACTOME_PATH\" , \"$MAPPED_GENE_PATH_ALL Reactome\" ], [ \"$MAPPED_GENES_HUMANPSD_PATH\" , \"$MAPPED_GENE_PATH_ALL Human disease biomarkers\" ], [ \"$MAPPED_GENE_PATH_ALL\" , \"$MAPPED_PATH_ALL Genes\" ], [ \"$MEALR_BACKGROUND_PATH\" , \"$MAPPED_PATH_ALL random 1000\" ], [ \"$MAPPED_PATH_ALL\" , \"$FOLDER_PATH/jurkat_chipseq_hg38\" ], [ \"$UNMAPPED_PATH_ALL\" , \"$FOLDER_PATH/jurkat_chipseq_hg38_unmapped\" ], [ \"$BED_PATH_SAMPLE\" , \"$FOLDER_PATH/GSM614003_jurkat.tal1_1000\" ], [ \"$MEALR_TOP_GENE_PATH\" , \"$MEALR_TOP_PATH Genes\" ], [ \"$GRN_FACTOR_PATH\" , \"$MEALR_VENN_PATH/Rows present in both tables\" ], [ \"$GRN_MATCH_PATH\" , \"$GRN_PWM_PROFILE Match\" ], [ \"$TAL1_MATCH_PATH\" , \"$GRN_PWM_PROFILE TAL1 Match\" ], [ \"$GRN_PWM_PROFILE\" , \"$GRN_PWM_PATH profile\" ], [ \"$GRN_PWM_PATH\" , \"$MEALR_OUTPUT_PATH/grn_pwms\" ], [ \"$TAL1_TRACK_PATH\" , \"$TAL1_GENE_PATH promoter\" ], [ \"$TAL1_GENE_PATH\" , \"$MEALR_OUTPUT_PATH/tal1\" ], [ \"$MEALR_VENN_PATH\" , \"$MEALR_TOP_PATH Venn\" ], [ \"$MEALR_TOP_PATH\" , \"$MEALR_MOTIF_PATH Top 50\" ], [ \"$MEALR_MOTIF_PATH\" , \"$MEALR_OUTPUT_PATH/MEALR_positive_coefficients\" ], [ \"$MEALR_OUTPUT_PATH\" , \"$MAPPED_PATH_SAMPLE MEALR\" ], [ \"$MAPPED_PATH_SAMPLE\" , \"$FOLDER_PATH/jurkat_chipseq_hg38_1000\" ], [ \"$UNMAPPED_PATH_SAMPLE\" , \"$FOLDER_PATH/jurkat_chipseq_hg38_1000_unmapped\" ], [ \"$FOLDER_PATH\" , \"$PARENT_FOLDER$/$FOLDER_NAME$\" ], [ \"$PARENT_FOLDER$\" , \"data/Projects/api2022_tutorial/Data\" ], [ \"$FOLDER_NAME$\" , \"chipseq_analysis_workflow_json\" ], [ \"$CHIPSEQ_BED_ALL\" , \"../data/GSM614003_jurkat.tal1.bed\" ], [ \"$CHIPSEQ_BED_SAMPLE\" , \"../data/GSM614003_jurkat.tal1_1000.bed\" ], [ \"$WAIT_SCRIPT\" , \"waitns.sh\" ], [ \"$PWM_ID_SCRIPT\" , \"chipseq_analysis_grn_pwms.py\" ], [ \"$TAL1_GENE_SCRIPT\" , \"chipseq_analysis_tal1.py\" ] ], \"tasks\" : [ { \"do\" : \"createFolder\" , \"showOutput\" : true , \"path\" : \"$PARENT_FOLDER$\" , \"name\" : \"$FOLDER_NAME$\" , \"comment\" : \"Prepare folder for analysis data and results\" }, { \"do\" : \"imPort\" , \"file\" : \"$CHIPSEQ_BED_ALL\" , \"path\" : \"$FOLDER_PATH\" , \"importer\" : \"BED format (*.bed)\" , \"verbose\" : true , \"parameters\" : { \"dbSelector\" : \"Ensembl 52.36n Human (hg18)\" }, \"comment\" : \"Step 1.1 Import the BED file with TAL1-bound regions into the destination folder\" }, { \"do\" : \"external\" , \"showOutput\" : true , \"bin\" : \"sh\" , \"params\" : [ \"$WAIT_SCRIPT\" ], \"comment\" : \"Run external script to allow server process to finish before using imported data\" }, { \"do\" : \"analyze\" , \"method\" : \"liftOver1\" , \"workflow\" : false , \"wait\" : true , \"progress\" : true , \"parameters\" : { \"input\" : \"$BED_PATH_ALL\" , \"mapping\" : \"$GENOME_MAPPING\" , \"minMatch\" : 0.95 , \"out_file1\" : \"$MAPPED_PATH_ALL\" , \"out_file2\" : \"$UNMAPPED_PATH_ALL\" }, \"comment\" : \"Step 1.2 Run Liftover to map hg18 coordinates to hg38\" }, { \"do\" : \"analyze\" , \"method\" : \"Track to gene set\" , \"workflow\" : false , \"wait\" : true , \"progress\" : true , \"parameters\" : { \"sourcePaths\" : [ \"$MAPPED_PATH_ALL\" ], \"species\" : \"$SPECIES\" , \"from\" : -5000 , \"to\" : 2000 , \"destPath\" : \"$MAPPED_GENE_PATH_ALL\" }, \"comment\" : \"Step 2. Run 'Track to gene set' tool to map genomic coordinates to genes\" }, { \"do\" : \"analyze\" , \"method\" : \"Functional classification\" , \"workflow\" : false , \"wait\" : true , \"progress\" : true , \"parameters\" : { \"sourcePath\" : \"$MAPPED_GENE_PATH_ALL\" , \"species\" : \"$SPECIES\" , \"bioHub\" : \"Full gene ontology classification\" , \"minHits\" : 1 , \"pvalueThreshold\" : 1 , \"outputTable\" : \"$MAPPED_GENES_GO_PATH\" }, \"comment\" : \"Step 3.1 Enrichment of genes associated with Gene Ontology terms using 'Functional classification'\" }, { \"do\" : \"export\" , \"file\" : \"functional_classification_result_GO.tsv\" , \"path\" : \"$MAPPED_GENES_GO_PATH\" , \"exporter\" : \"Tab-separated text (*.txt)\" , \"parameters\" : {}, \"comment\" : \"Step 3.2 Export analysis results to local file\" }, { \"do\" : \"analyze\" , \"method\" : \"Functional classification\" , \"workflow\" : false , \"wait\" : true , \"progress\" : true , \"parameters\" : { \"sourcePath\" : \"$MAPPED_GENE_PATH_ALL\" , \"species\" : \"$SPECIES\" , \"bioHub\" : \"Reactome pathways (74)\" , \"minHits\" : 1 , \"pvalueThreshold\" : 1 , \"outputTable\" : \"$MAPPED_GENES_REACTOME_PATH\" }, \"comment\" : \"Step 3.3 Enrichment of genes associated with Reactome pathways using 'Functional classification'\" }, { \"do\" : \"export\" , \"file\" : \"functional_classification_result_Reactome.tsv\" , \"path\" : \"$MAPPED_GENES_REACTOME_PATH\" , \"exporter\" : \"Tab-separated text (*.txt)\" , \"parameters\" : {}, \"comment\" : \"Step 3.4 Export analysis results to local file\" }, { \"do\" : \"analyze\" , \"method\" : \"Functional classification\" , \"workflow\" : false , \"wait\" : true , \"progress\" : true , \"parameters\" : { \"sourcePath\" : \"$MAPPED_GENE_PATH_ALL\" , \"species\" : \"$SPECIES\" , \"bioHub\" : \"HumanPSD(TM) disease (2022.1)\" , \"minHits\" : 1 , \"pvalueThreshold\" : 1 , \"outputTable\" : \"$MAPPED_GENES_HUMANPSD_PATH\" }, \"comment\" : \"Step 3.5 Enrichment of biomarkers of human diseases annotated in the HumanPSD knowledgebase\" }, { \"do\" : \"export\" , \"file\" : \"functional_classification_result_HumanPSD.tsv\" , \"path\" : \"$MAPPED_GENES_HUMANPSD_PATH\" , \"exporter\" : \"Tab-separated text (*.txt)\" , \"parameters\" : {}, \"comment\" : \"Step 3.6 Export analysis results to local file\" }, { \"do\" : \"analyze\" , \"method\" : \"Create random track\" , \"workflow\" : false , \"wait\" : true , \"progress\" : true , \"parameters\" : { \"inputTrackPath\" : \"$MAPPED_PATH_ALL\" , \"dbSelector\" : \"$ENSEMBL_104_SELECTOR\" , \"species\" : \"$SPECIES\" , \"standardChromosomes\" : true , \"seqNumber\" : 1000 , \"seqLength\" : 0 , \"from\" : 0 , \"to\" : 0 , \"withOverlap\" : false , \"randomShift\" : false , \"outputTrackPath\" : \"$MEALR_BACKGROUND_PATH\" , \"randSeed\" : 123 }, \"comment\" : \"Step 4. Create random track not overlapping with TAL1-bound regions\" }, { \"do\" : \"imPort\" , \"file\" : \"$CHIPSEQ_BED_SAMPLE\" , \"path\" : \"$FOLDER_PATH\" , \"importer\" : \"BED format (*.bed)\" , \"verbose\" : true , \"parameters\" : { \"dbSelector\" : \"Ensembl 52.36n Human (hg18)\" }, \"comment\" : \"Step 5.1 Import sampled TAL1 ChIP-seq sites\" }, { \"do\" : \"external\" , \"showOutput\" : true , \"bin\" : \"sh\" , \"params\" : [ \"$WAIT_SCRIPT\" ], \"comment\" : \"Run external script to allow server process to finish before using imported data\" }, { \"do\" : \"analyze\" , \"method\" : \"liftOver1\" , \"workflow\" : false , \"wait\" : true , \"progress\" : true , \"parameters\" : { \"input\" : \"$BED_PATH_SAMPLE\" , \"mapping\" : \"$GENOME_MAPPING\" , \"minMatch\" : 0.95 , \"out_file1\" : \"$MAPPED_PATH_SAMPLE\" , \"out_file2\" : \"$UNMAPPED_PATH_SAMPLE\" }, \"comment\" : \"Step 5.2 Map coordinates from hg18 to hg38\" }, { \"do\" : \"analyze\" , \"method\" : \"MEALR (tracks)\" , \"workflow\" : false , \"wait\" : true , \"progress\" : true , \"parameters\" : { \"yesSetPath\" : \"$MAPPED_PATH_SAMPLE\" , \"noSetPath\" : \"$MEALR_BACKGROUND_PATH\" , \"dbSelector\" : \"$ENSEMBL_104_SELECTOR\" , \"profilePath\" : \"$MEALR_TRANSFAC_PROFILE\" , \"maxPosCoef\" : 150 , \"maxComplexity\" : 0.5 , \"complexityInc\" : 0.02 , \"maxUnimproved\" : 20 , \"scoresWithNoSet\" : false , \"output\" : \"$MEALR_OUTPUT_PATH\" }, \"comment\" : \"Step 6. Analyze target and background genomic regions using MEALR to find important PWMs\" }, { \"do\" : \"analyze\" , \"method\" : \"Select top rows\" , \"workflow\" : false , \"wait\" : true , \"progress\" : true , \"parameters\" : { \"inputTable\" : \"$MEALR_MOTIF_PATH\" , \"column\" : \"Coefficient\" , \"types\" : [ \"Top\" ], \"topPercent\" : 100.0 , \"topCount\" : 50 , \"topMinCount\" : 50 , \"topTable\" : \"$MEALR_TOP_PATH\" }, \"comment\" : \"Step 7.1 Extract top 50 PWMs ranked by logistic regression coefficient\" }, { \"do\" : \"analyze\" , \"method\" : \"Matrices to molecules\" , \"workflow\" : false , \"wait\" : true , \"progress\" : true , \"parameters\" : { \"sitesCollection\" : \"$MEALR_TOP_PATH\" , \"siteModelsCollection\" : \"$MEALR_TRANSFAC_PROFILE\" , \"species\" : \"$SPECIES\" , \"targetType\" : \"Genes: Ensembl\" , \"outputTable\" : \"$MEALR_TOP_GENE_PATH\" }, \"comment\" : \"Step 7.2 Convert PWMs to factor genes\" }, { \"do\" : \"analyze\" , \"method\" : \"Venn diagrams\" , \"workflow\" : false , \"wait\" : true , \"progress\" : true , \"parameters\" : { \"table1Path\" : \"$MAPPED_GENE_PATH_ALL\" , \"table1Name\" : \"Genes near TAL1 sites\" , \"table2Path\" : \"$MEALR_TOP_GENE_PATH\" , \"table2Name\" : \"MEALR transcription factors\" , \"simple\" : true , \"output\" : \"$MEALR_VENN_PATH\" }, \"comment\" : \"Step 8 Intersect factors identified by MEALR and genes with nearby TAL1 ChIP-seq sites\" }, { \"do\" : \"get\" , \"table\" : \"$GRN_FACTOR_PATH\" , \"toFile\" : \"grn_factors.json\" , \"comment\" : \"Step 9.1 Download table with potential GRN factors to local file\" }, { \"do\" : \"external\" , \"bin\" : \"python3\" , \"params\" : [ \"$PWM_ID_SCRIPT\" ], \"comment\" : \"Step 9.2 Run external script to create PWM table\" }, { \"do\" : \"imPort\" , \"file\" : \"grn_pwms.tsv\" , \"path\" : \"$MEALR_OUTPUT_PATH\" , \"importer\" : \"Tabular (*.txt, *.xls, *.tab, etc.)\" , \"parameters\" : { \"columnForID\" : \"PWM\" , \"tableType\" : \"Matrices: TRANSFAC\" , \"species\" : \"Human (Homo sapiens)\" }, \"comment\" : \"Step 9.3 Import PWM table created by external script\" }, { \"do\" : \"external\" , \"showOutput\" : true , \"bin\" : \"sh\" , \"params\" : [ \"$WAIT_SCRIPT\" ], \"comment\" : \"Run external script to allow server process to finish before using imported data\" }, { \"do\" : \"analyze\" , \"method\" : \"Create profile from site model table\" , \"workflow\" : false , \"wait\" : true , \"progress\" : true , \"parameters\" : { \"table\" : \"$GRN_PWM_PATH\" , \"profile\" : \"$GRN_TRANSFAC_PROFILE\" , \"outputProfile\" : \"$GRN_PWM_PROFILE\" }, \"comment\" : \"Step 9.4 Create Match(TM) profile for PWMs of potential GRN factors\" }, { \"do\" : \"analyze\" , \"method\" : \"TRANSFAC(R) Match(TM) for tracks\" , \"workflow\" : false , \"wait\" : true , \"progress\" : true , \"parameters\" : { \"sequencePath\" : \"$MAPPED_PATH_ALL\" , \"dbSelector\" : \"$ENSEMBL_104_SELECTOR\" , \"profilePath\" : \"$GRN_PWM_PROFILE\" , \"withoutDuplicates\" : true , \"ignoreCore\" : true , \"output\" : \"$GRN_MATCH_PATH\" }, \"comment\" : \"Step 9.5 Predict binding sites of GRN factors in TAL1-bound regions\" }, { \"do\" : \"external\" , \"bin\" : \"python3\" , \"params\" : [ \"$TAL1_GENE_SCRIPT\" ], \"comment\" : \"Step 10.1 Run external script to prepare TAL1 gene table\" }, { \"do\" : \"imPort\" , \"file\" : \"tal1.tsv\" , \"path\" : \"$MEALR_OUTPUT_PATH\" , \"importer\" : \"Tabular (*.txt, *.xls, *.tab, etc.)\" , \"parameters\" : { \"columnForID\" : \"ID\" , \"tableType\" : \"Genes: Ensembl\" , \"species\" : \"Human (Homo sapiens)\" }, \"comment\" : \"Step 10.2 Import TAL1 gene table\" }, { \"do\" : \"external\" , \"showOutput\" : true , \"bin\" : \"sh\" , \"params\" : [ \"$WAIT_SCRIPT\" ], \"comment\" : \"Run external script to allow server process to finish before using imported data\" }, { \"do\" : \"analyze\" , \"method\" : \"Gene set to track\" , \"workflow\" : false , \"wait\" : true , \"progress\" : true , \"parameters\" : { \"sourcePath\" : \"$TAL1_GENE_PATH\" , \"species\" : \"$SPECIES\" , \"from\" : 2000 , \"to\" : 1000 , \"destPath\" : \"$TAL1_TRACK_PATH\" }, \"comment\" : \"Step 10.3 Create track of genomic region around TAL1 TSS (promoter)\" }, { \"do\" : \"analyze\" , \"method\" : \"TRANSFAC(R) Match(TM) for tracks\" , \"workflow\" : false , \"wait\" : true , \"progress\" : true , \"parameters\" : { \"sequencePath\" : \"$TAL1_TRACK_PATH\" , \"dbSelector\" : \"$ENSEMBL_104_SELECTOR\" , \"profilePath\" : \"$GRN_PWM_PROFILE\" , \"withoutDuplicates\" : true , \"ignoreCore\" : true , \"output\" : \"$TAL1_MATCH_PATH\" }, \"comment\" : \"Step 10.4 Predict binding sites of GRN factors in TAL1 promoter\" }, { \"do\" : \"export\" , \"file\" : \"TAL1_grn_pwm_sites.bed\" , \"path\" : \"$TAL1_MATCH_PATH\" , \"exporter\" : \"BED format (*.bed)\" , \"parameters\" : {}, \"comment\" : \"Step 10.5 Export genomic locations of predicted sites for GRN factors around TAL1 TSS\" } ] }","title":"JSON configuration for the tutorial workflow"},{"location":"chipseq_analysis_r.html","text":"ChIP-seq data analysis using geneXplainR The R script below implements the tutorial workflow . The described steps are indicated in code comments for reference. The R code is provided with the tutorial material as genexplain_tutorial_chipseq_analysis.R . Please note that some parts require editing before running the script, including username, password, project name. R code for the tutorial 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 library ( geneXplainR ) # Please note that for successful login, username and password have to # belong to a valid account on that server. server <- \"https://platform.genexplain.com\" user <- \"someuser@email.io\" password <- \"12345\" gx.login ( server , user , password ) apiProjectName <- \"api2022_tutorial\" apiProjectPath <- paste0 ( \"data/Projects/\" , apiProjectName ) # Create a new platform project # This step should be conducted only once for a new project. # The gx.createProject function returns an error if the project # already exists. gx.createProject ( apiProjectName , description = \"API 2022 tutorial project\" ) folderPath <- paste0 ( apiProjectPath , \"/Data/chipseq_analysis_workflow\" ) # Within a project, folders for data elements need to be created within the # \"Data\" folder or its subfolders. gx.createFolder ( \"data/Projects/api2022_tutorial/Data\" , \"chipseq_analysis_workflow\" ) # # Step 1. Import and mapping of TAL1-bound genomic regions # # Import the BED file with TAL1-bound regions into the destination folder gx.import ( \"../data/GSM614003_jurkat.tal1.bed\" , folderPath , \"BED format (*.bed)\" , list ( dbSelector = \"Ensembl 52.36n Human (hg18)\" )) # After data imports it is recommendable to shortly pause in order to # allow server processes to finish before using the data Sys.sleep ( 1 ) gx.analysis.parameters ( \"liftOver1\" ) # # Output # description # input # mapping # minMatch Recommended values: same species = 0.95, different species = 0.10 # multiple|choice Recommended values: same species = No, different species = Yes # out_file1 # out_file2 # bedPath <- paste0 ( folderPath , \"/GSM614003_jurkat.tal1\" ) mappedPath <- paste0 ( folderPath , \"/jurkat_chipseq_hg38\" ) unmappedPath <- paste0 ( folderPath , \"/jurkat_chipseq_hg38_unmapped\" ) mapping <- \"hg18->hg38\" # Run Liftover to map hg18 coordinates to hg38 gx.analysis ( \"liftOver1\" , list ( input = bedPath , mapping = mapping , minMatch = 0.95 , out_file1 = mappedPath , out_file2 = unmappedPath ), TRUE , TRUE ) # # Step 2. Mapping TAL1-bound genomic regions to nearby genes # species <- \"Human (Homo sapiens)\" mappedGenePath <- paste0 ( mappedPath , \" Genes\" ) # Use gx.trackToGeneSet function to map genomic coordinates to genes gx.trackToGeneSet ( mappedPath , species , -5000 , 2000 , destPath = mappedGenePath ) # # Step 3. Functional enrichment analysis of genes near TAL1-bound regions # # Enrichment of genes associated with Gene Ontology terms using # \"Functional classification\" funclassResultPath <- paste0 ( mappedGenePath , \" GO\" ) gx.analysis ( \"Functional classification\" , list ( sourcePath = mappedGenePath , species = species , bioHub = \"Full gene ontology classification\" , minHits = 1 , pvalueThreshold = 1 , outputTable = funclassResultPath ), TRUE , TRUE ) # Export analysis result to local file # The default exporter is for data tables, so that it is sufficient # to specify the data element path and the local output file gx.export ( funclassResultPath , target.file = \"functional_classification_result_GO.tsv\" ) # Enrichment of genes associated with Reactome pathways funclassResultPath <- paste0 ( mappedGenePath , \" Reactome\" ) gx.analysis ( \"Functional classification\" , list ( sourcePath = mappedGenePath , species = species , bioHub = \"Reactome pathways (74)\" , minHits = 1 , pvalueThreshold = 1 , outputTable = funclassResultPath ), TRUE , TRUE ) # Export analysis result to local file gx.export ( funclassResultPath , target.file = \"functional_classification_result_Reactome.tsv\" ) # Enrichment of genes associated with human diseases based on # HumanPSD disease biomarker annotation funclassResultPath <- paste0 ( mappedGenePath , \" Human disease biomarkers\" ) gx.analysis ( \"Functional classification\" , list ( sourcePath = mappedGenePath , species = species , bioHub = \"HumanPSD(TM) disease (2022.1)\" , minHits = 1 , pvalueThreshold = 1 , outputTable = funclassResultPath ), TRUE , TRUE ) # Export analysis result to local file gx.export ( funclassResultPath , target.file = \"functional_classification_result_HumanPSD.tsv\" ) # # Step 4. Sampling genomic regions not bound by TAL1 # mealrBackgroundTrack <- paste0 ( mappedPath , \" random 1000\" ) # Create random track not overlapping with TAL1-bound regions gx.analysis ( \"Create random track\" , list ( inputTrackPath = mappedPath , dbSelector = \"Ensembl 104.38 Human (hg38)\" , species = species , standardChromosomes = TRUE , seqNumber = 1000 , seqLength = 0 , from = 0 , to = 0 , withOverlap = FALSE , randomShift = FALSE , outputTrackPath = mealrBackgroundTrack , randSeed = 123 ), TRUE , TRUE ) # # Step 5. Import and mapping of TAL1 binding site subset # # # Data upload and lifting as in Step 1 for 1000 TAL1 sites sampled # from the original BED file gx.import ( \"../data/GSM614003_jurkat.tal1_1000.bed\" , folderPath , \"BED format (*.bed)\" , list ( dbSelector = \"Ensembl 52.36n Human (hg18)\" )) # After data imports it is recommendable to shortly pause in order to # allow server processes to finish before using the data Sys.sleep ( 1 ) bedPath <- paste0 ( folderPath , \"/GSM614003_jurkat.tal1_1000\" ) mappedPath <- paste0 ( folderPath , \"/jurkat_chipseq_hg38_1000\" ) unmappedPath <- paste0 ( folderPath , \"/jurkat_chipseq_hg38_1000_unmapped\" ) # Map hg18 coordinates to hg38 gx.analysis ( \"liftOver1\" , list ( input = bedPath , mapping = mapping , minMatch = 0.95 , out_file1 = mappedPath , out_file2 = unmappedPath ), TRUE , TRUE ) # # Step 6. Selection of important PWM models using MEALR # gx.analysis.parameters ( \"MEALR (tracks)\" ) # # Output # description # yesSetPath Study track / Track with intervals of interest # noSetPath Background track / Track of non-bound intervals # dbSelector Select a deployed or custom sequence source # profilePath Profile of weight matrices # maxPosCoef Maximum number of positive coefficients (motifs of factors with positive binding effect) # maxComplexity Maximal complexity paramater to explore # complexityInc Step-size of incrementing the complexity parameter # maxUnimproved Maximal number of iterations without improved accuracy # scoresWithNoSet Include scores for No sequences in score table outputs # output Output folder path # mealrOutputPath <- paste0 ( mappedPath , \" MEALR\" ) transfacProfile <- \"databases/TRANSFAC(R) 2022.1/Data/profiles/vertebrate_human_p0.05_non3d\" # Analyze target and background genomic regions using MEALR gx.analysis ( \"MEALR (tracks)\" , list ( yesSetPath = mappedPath , noSetPath = mealrBackgroundTrack , dbSelector = \"Ensembl 104.38 Human (hg38)\" , profilePath = transfacProfile , maxPosCoef = 150 , maxComplexity = 0.5 , complexityInc = 0.02 , maxUnimproved = 20 , scoresWithNoSet = FALSE , output = mealrOutputPath ), TRUE , TRUE ) # # Step 7. Extraction of binding transcription factors # gx.analysis.parameters ( \"Select top rows\" ) # # Output # description # inputTable Input table # column Column # types Type # topPercent Top percent # topCount Top max count # topMinCount Top min count # topTable Top table output # middlePercent Middle percent # middleCount Middle max count # middleMinCount Middle min count # middleTable Middle table output # bottomPercent Bottom percent # bottomCount Bottom max count # bottomMinCount Bottom min count # bottomTable Bottom table output # mealrMotifPath <- paste0 ( mealrOutputPath , \"/MEALR_positive_coefficients\" ) mealrTopPath <- paste0 ( mealrMotifPath , \" Top 50\" ) # Extract top 50 PWMs ranked by logistic regression coefficient gx.analysis ( \"Select top rows\" , list ( inputTable = mealrMotifPath , column = \"Coefficient\" , topPercent = 100.0 , topCount = 50 , topMinCount = 50 , topTable = mealrTopPath ), TRUE , TRUE ) gx.analysis.parameters ( \"Matrices to molecules\" ) # # Output # description # sitesCollection Select table with the results of \"Site search on gene set\". Such table contains site model ID in each row. # siteModelsCollection Select the profile that was used for site search. In most of the cases, profile is selected automatically. # species Select arabidopsis, nematoda, zebrafish, fruit fly, human, mouse, rat, baker s yeast or fission yeast species # targetType Select type of identifiers for the resulting table # ignoreNaNInAggregator Ignore empty values during aggregator work # aggregator Select one of the rules to treat values in the numerical columns of the table when several rows are merged into a single one. # columnName Select the column with numerical values to apply one of the rules described above # outputTable Path to store the resulting table in the tree # mealrTopGenePath <- paste0 ( mealrTopPath , \" Genes\" ) # Convert PWMs to factor genes gx.analysis ( \"Matrices to molecules\" , list ( sitesCollection = mealrTopPath , siteModelsCollection = transfacProfile , species = species , targetType = \"Genes: Ensembl\" , outputTable = mealrTopGenePath ), TRUE , TRUE ) # # Step 8. Intersection of potentially TAL1-regulated genes and MEALR TFs # gx.analysis.parameters ( \"Venn diagrams\" ) # # Output # description # table1Path Table which will be represented as left-top circle # table1Name Name for the left table on the diagram (leave empty to use table name) # circle1Color Color for the left-top circle on the diagram # table2Path Table which will be represented as right-top circle # table2Name Name for the right table on the diagram (leave empty to use table name) # circle2Color Color for the right-top circle on the diagram # table3Path Table which will be represented as center-bottom circle # table3Name Name for the center table on the diagram (leave empty to use table name) # circle3Color Color for the center-bottom circle on the diagram # simple All circles has equal radius # output Folder name to store the results # mappedNearbyGenePath <- paste0 ( folderPath , \"/jurkat_chipseq_hg38 Genes\" ) mealrTopVennPath <- paste0 ( mealrTopPath , \" Venn\" ) # Intersect factors identified by MEALR and genes with nearby TAL1 ChIP-seq # sites gx.analysis ( \"Venn diagrams\" , list ( table1Path = mappedNearbyGenePath , table1Name = \"Genes near TAL1 sites\" , table2Path = mealrTopGenePath , table2Name = \"MEALR transcription factors\" , simple = TRUE , output = mealrTopVennPath ), TRUE , TRUE ) # # Step 9. Prediction of binding sites of identified TFs in TAL1-bound genomic regions # grnFactorPath <- paste0 ( mealrTopVennPath , \"/Rows present in both tables\" ) # Load potential GRN factors into R data frame tfs <- gx.get ( grnFactorPath ) # tfs # Gene symbol jurkat_chipseq_hg38: Count # ENSG00000081059 TCF7 1 # ENSG00000118513 MYB 1 # ENSG00000124813 RUNX2 4 # ENSG00000125952 MAX 2 # ENSG00000138795 LEF1 2 # ENSG00000157554 ERG 1 # ENSG00000159216 RUNX1 4 # ENSG00000179348 GATA2 1 # Site model ID Coefficient # ENSG00000081059 V$TCF1_09 0.05875131 # ENSG00000118513 V$CMYB_01 0.02749087 # ENSG00000124813 V$AML_Q6,V$OSF2_Q6,V$RUNX2_03,V$RUNX2_04 0.08663064 # ENSG00000125952 V$MYCMAX_01 0.02998472 # ENSG00000138795 V$LEF1_10,V$LEF1_17 0.03285110 # ENSG00000157554 V$ERG_07 0.04488260 # ENSG00000159216 V$AML1_02,V$AML_Q6 0.08663064 # ENSG00000179348 V$GATA2_09 0.04911769 # # Extract PWM ids grnPwms <- unlist ( strsplit ( tfs [, 3 ], \",\" , fixed = TRUE )) # Create PWM table for import write.table ( cbind ( PWM = grnPwms , Num = 1 : length ( grnPwms )), file = \"grn_pwms.tsv\" , quote = FALSE , sep = \"\\t\" , row.names = FALSE ) # Import PWM table gx.importTable ( \"grn_pwms.tsv\" , mealrOutputPath , \"MEALR_positive_coefficients Top 50 GRN PWMs\" , columnForID = \"PWM\" , tableType = \"Matrices: TRANSFAC\" , species = species ) # After data imports it is recommendable to shortly pause in order to # allow server processes to finish before using the data Sys.sleep ( 1 ) grnPwmPath <- paste0 ( mealrOutputPath , \"/MEALR_positive_coefficients Top 50 GRN PWMs\" ) gx.analysis.parameters ( \"Create profile from site model table\" ) # # Output # description # table Table containing site models as row names # profile Profile to copy the values from # thresholdsColumn Column containing cutoff values (use 'none' to copy cutoffs from the profile) # outputProfile Specify the path whether to store output profile # transfacProfile <- \"databases/TRANSFAC(R) 2022.1/Data/profiles/vertebrate_human_p0.001_non3d\" grnPwmProfile <- paste0 ( grnPwmPath , \" profile\" ) # Create Match(TM) profile for PWMs of potential GRN factors gx.analysis ( \"Create profile from site model table\" , list ( table = grnPwmPath , profile = transfacProfile , outputProfile = grnPwmProfile ), TRUE , TRUE ) gx.analysis.parameters ( \"TRANSFAC(R) Match(TM) for tracks\" ) # # Output # description # sequencePath Sequence track to search # dbSelector Select a deployed or custom sequence source # profilePath Profile # withoutDuplicates Ensure to report sites in overlapping genomic intervals only once # ignoreCore Core scores are not calculated and not used for filtering. # output Output track path # grnMatchPath <- paste0 ( grnPwmProfile , \" Match\" ) # Predict binding sites of GRN factors in TAL1-bound regions gx.analysis ( \"TRANSFAC(R) Match(TM) for tracks\" , list ( sequencePath = paste0 ( folderPath , \"/jurkat_chipseq_hg38\" ), dbSelector = \"Ensembl 104.38 Human (hg38)\" , profilePath = grnPwmProfile , withoutDuplicates = TRUE , ignoreCore = TRUE , output = grnMatchPath ), TRUE , TRUE ) # # Step 10. Prediction of binding sites of identified TFs around TAL1 transcription start site # # Create TAL1 gene table for import write.table ( cbind ( ID = c ( \"ENSG00000162367\" ), Symbol = c ( \"TAL1\" )), file = \"tal1.tsv\" , quote = FALSE , sep = \"\\t\" , row.names = FALSE ) # Import TAL1 gene gx.importTable ( \"tal1.tsv\" , mealrOutputPath , \"TAL1 gene\" , columnForID = \"ID\" , tableType = \"Genes: Ensembl\" , species = species ) # After data imports it is recommendable to shortly pause in order to # allow server processes to finish before using the data Sys.sleep ( 1 ) tal1GenePath <- paste0 ( mealrOutputPath , \"/TAL1 gene\" ) gx.analysis.parameters ( \"Gene set to track\" ) # # Output # description # sourcePath Table of source genes # species Taxonomical species # from From position (relative to gene start) # to To position (relative to gene start) # overlapMergingMode How to handle TSS located close to each other # destPath Output name # tal1TrackPath <- paste0 ( tal1GenePath , \" promoter\" ) # Create track of genomic region around TAL1 TSS (promoter) gx.analysis ( \"Gene set to track\" , list ( sourcePath = tal1GenePath , species = species , from = 2000 , to = 1000 , destPath = tal1TrackPath ), TRUE , TRUE ) tal1MatchPath <- paste0 ( grnPwmProfile , \" TAL1 Match\" ) # Predict binding sites of GRN factors in TAL1 promoter gx.analysis ( \"TRANSFAC(R) Match(TM) for tracks\" , list ( sequencePath = tal1TrackPath , dbSelector = \"Ensembl 104.38 Human (hg38)\" , profilePath = grnPwmProfile , withoutDuplicates = TRUE , ignoreCore = TRUE , output = tal1MatchPath ), TRUE , TRUE ) # Export genomic locations of predicted sites for GRN factors around TAL1 TSS gx.export ( tal1MatchPath , exporter = \"BED format (*.bed)\" , target.file = \"TAL1_grn_pwm_sites.bed\" ) gx.logout ()","title":"geneXplainR"},{"location":"chipseq_analysis_r.html#chip-seq-data-analysis-using-genexplainr","text":"The R script below implements the tutorial workflow . The described steps are indicated in code comments for reference. The R code is provided with the tutorial material as genexplain_tutorial_chipseq_analysis.R . Please note that some parts require editing before running the script, including username, password, project name.","title":"ChIP-seq data analysis using geneXplainR"},{"location":"chipseq_analysis_r.html#r-code-for-the-tutorial","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 library ( geneXplainR ) # Please note that for successful login, username and password have to # belong to a valid account on that server. server <- \"https://platform.genexplain.com\" user <- \"someuser@email.io\" password <- \"12345\" gx.login ( server , user , password ) apiProjectName <- \"api2022_tutorial\" apiProjectPath <- paste0 ( \"data/Projects/\" , apiProjectName ) # Create a new platform project # This step should be conducted only once for a new project. # The gx.createProject function returns an error if the project # already exists. gx.createProject ( apiProjectName , description = \"API 2022 tutorial project\" ) folderPath <- paste0 ( apiProjectPath , \"/Data/chipseq_analysis_workflow\" ) # Within a project, folders for data elements need to be created within the # \"Data\" folder or its subfolders. gx.createFolder ( \"data/Projects/api2022_tutorial/Data\" , \"chipseq_analysis_workflow\" ) # # Step 1. Import and mapping of TAL1-bound genomic regions # # Import the BED file with TAL1-bound regions into the destination folder gx.import ( \"../data/GSM614003_jurkat.tal1.bed\" , folderPath , \"BED format (*.bed)\" , list ( dbSelector = \"Ensembl 52.36n Human (hg18)\" )) # After data imports it is recommendable to shortly pause in order to # allow server processes to finish before using the data Sys.sleep ( 1 ) gx.analysis.parameters ( \"liftOver1\" ) # # Output # description # input # mapping # minMatch Recommended values: same species = 0.95, different species = 0.10 # multiple|choice Recommended values: same species = No, different species = Yes # out_file1 # out_file2 # bedPath <- paste0 ( folderPath , \"/GSM614003_jurkat.tal1\" ) mappedPath <- paste0 ( folderPath , \"/jurkat_chipseq_hg38\" ) unmappedPath <- paste0 ( folderPath , \"/jurkat_chipseq_hg38_unmapped\" ) mapping <- \"hg18->hg38\" # Run Liftover to map hg18 coordinates to hg38 gx.analysis ( \"liftOver1\" , list ( input = bedPath , mapping = mapping , minMatch = 0.95 , out_file1 = mappedPath , out_file2 = unmappedPath ), TRUE , TRUE ) # # Step 2. Mapping TAL1-bound genomic regions to nearby genes # species <- \"Human (Homo sapiens)\" mappedGenePath <- paste0 ( mappedPath , \" Genes\" ) # Use gx.trackToGeneSet function to map genomic coordinates to genes gx.trackToGeneSet ( mappedPath , species , -5000 , 2000 , destPath = mappedGenePath ) # # Step 3. Functional enrichment analysis of genes near TAL1-bound regions # # Enrichment of genes associated with Gene Ontology terms using # \"Functional classification\" funclassResultPath <- paste0 ( mappedGenePath , \" GO\" ) gx.analysis ( \"Functional classification\" , list ( sourcePath = mappedGenePath , species = species , bioHub = \"Full gene ontology classification\" , minHits = 1 , pvalueThreshold = 1 , outputTable = funclassResultPath ), TRUE , TRUE ) # Export analysis result to local file # The default exporter is for data tables, so that it is sufficient # to specify the data element path and the local output file gx.export ( funclassResultPath , target.file = \"functional_classification_result_GO.tsv\" ) # Enrichment of genes associated with Reactome pathways funclassResultPath <- paste0 ( mappedGenePath , \" Reactome\" ) gx.analysis ( \"Functional classification\" , list ( sourcePath = mappedGenePath , species = species , bioHub = \"Reactome pathways (74)\" , minHits = 1 , pvalueThreshold = 1 , outputTable = funclassResultPath ), TRUE , TRUE ) # Export analysis result to local file gx.export ( funclassResultPath , target.file = \"functional_classification_result_Reactome.tsv\" ) # Enrichment of genes associated with human diseases based on # HumanPSD disease biomarker annotation funclassResultPath <- paste0 ( mappedGenePath , \" Human disease biomarkers\" ) gx.analysis ( \"Functional classification\" , list ( sourcePath = mappedGenePath , species = species , bioHub = \"HumanPSD(TM) disease (2022.1)\" , minHits = 1 , pvalueThreshold = 1 , outputTable = funclassResultPath ), TRUE , TRUE ) # Export analysis result to local file gx.export ( funclassResultPath , target.file = \"functional_classification_result_HumanPSD.tsv\" ) # # Step 4. Sampling genomic regions not bound by TAL1 # mealrBackgroundTrack <- paste0 ( mappedPath , \" random 1000\" ) # Create random track not overlapping with TAL1-bound regions gx.analysis ( \"Create random track\" , list ( inputTrackPath = mappedPath , dbSelector = \"Ensembl 104.38 Human (hg38)\" , species = species , standardChromosomes = TRUE , seqNumber = 1000 , seqLength = 0 , from = 0 , to = 0 , withOverlap = FALSE , randomShift = FALSE , outputTrackPath = mealrBackgroundTrack , randSeed = 123 ), TRUE , TRUE ) # # Step 5. Import and mapping of TAL1 binding site subset # # # Data upload and lifting as in Step 1 for 1000 TAL1 sites sampled # from the original BED file gx.import ( \"../data/GSM614003_jurkat.tal1_1000.bed\" , folderPath , \"BED format (*.bed)\" , list ( dbSelector = \"Ensembl 52.36n Human (hg18)\" )) # After data imports it is recommendable to shortly pause in order to # allow server processes to finish before using the data Sys.sleep ( 1 ) bedPath <- paste0 ( folderPath , \"/GSM614003_jurkat.tal1_1000\" ) mappedPath <- paste0 ( folderPath , \"/jurkat_chipseq_hg38_1000\" ) unmappedPath <- paste0 ( folderPath , \"/jurkat_chipseq_hg38_1000_unmapped\" ) # Map hg18 coordinates to hg38 gx.analysis ( \"liftOver1\" , list ( input = bedPath , mapping = mapping , minMatch = 0.95 , out_file1 = mappedPath , out_file2 = unmappedPath ), TRUE , TRUE ) # # Step 6. Selection of important PWM models using MEALR # gx.analysis.parameters ( \"MEALR (tracks)\" ) # # Output # description # yesSetPath Study track / Track with intervals of interest # noSetPath Background track / Track of non-bound intervals # dbSelector Select a deployed or custom sequence source # profilePath Profile of weight matrices # maxPosCoef Maximum number of positive coefficients (motifs of factors with positive binding effect) # maxComplexity Maximal complexity paramater to explore # complexityInc Step-size of incrementing the complexity parameter # maxUnimproved Maximal number of iterations without improved accuracy # scoresWithNoSet Include scores for No sequences in score table outputs # output Output folder path # mealrOutputPath <- paste0 ( mappedPath , \" MEALR\" ) transfacProfile <- \"databases/TRANSFAC(R) 2022.1/Data/profiles/vertebrate_human_p0.05_non3d\" # Analyze target and background genomic regions using MEALR gx.analysis ( \"MEALR (tracks)\" , list ( yesSetPath = mappedPath , noSetPath = mealrBackgroundTrack , dbSelector = \"Ensembl 104.38 Human (hg38)\" , profilePath = transfacProfile , maxPosCoef = 150 , maxComplexity = 0.5 , complexityInc = 0.02 , maxUnimproved = 20 , scoresWithNoSet = FALSE , output = mealrOutputPath ), TRUE , TRUE ) # # Step 7. Extraction of binding transcription factors # gx.analysis.parameters ( \"Select top rows\" ) # # Output # description # inputTable Input table # column Column # types Type # topPercent Top percent # topCount Top max count # topMinCount Top min count # topTable Top table output # middlePercent Middle percent # middleCount Middle max count # middleMinCount Middle min count # middleTable Middle table output # bottomPercent Bottom percent # bottomCount Bottom max count # bottomMinCount Bottom min count # bottomTable Bottom table output # mealrMotifPath <- paste0 ( mealrOutputPath , \"/MEALR_positive_coefficients\" ) mealrTopPath <- paste0 ( mealrMotifPath , \" Top 50\" ) # Extract top 50 PWMs ranked by logistic regression coefficient gx.analysis ( \"Select top rows\" , list ( inputTable = mealrMotifPath , column = \"Coefficient\" , topPercent = 100.0 , topCount = 50 , topMinCount = 50 , topTable = mealrTopPath ), TRUE , TRUE ) gx.analysis.parameters ( \"Matrices to molecules\" ) # # Output # description # sitesCollection Select table with the results of \"Site search on gene set\". Such table contains site model ID in each row. # siteModelsCollection Select the profile that was used for site search. In most of the cases, profile is selected automatically. # species Select arabidopsis, nematoda, zebrafish, fruit fly, human, mouse, rat, baker s yeast or fission yeast species # targetType Select type of identifiers for the resulting table # ignoreNaNInAggregator Ignore empty values during aggregator work # aggregator Select one of the rules to treat values in the numerical columns of the table when several rows are merged into a single one. # columnName Select the column with numerical values to apply one of the rules described above # outputTable Path to store the resulting table in the tree # mealrTopGenePath <- paste0 ( mealrTopPath , \" Genes\" ) # Convert PWMs to factor genes gx.analysis ( \"Matrices to molecules\" , list ( sitesCollection = mealrTopPath , siteModelsCollection = transfacProfile , species = species , targetType = \"Genes: Ensembl\" , outputTable = mealrTopGenePath ), TRUE , TRUE ) # # Step 8. Intersection of potentially TAL1-regulated genes and MEALR TFs # gx.analysis.parameters ( \"Venn diagrams\" ) # # Output # description # table1Path Table which will be represented as left-top circle # table1Name Name for the left table on the diagram (leave empty to use table name) # circle1Color Color for the left-top circle on the diagram # table2Path Table which will be represented as right-top circle # table2Name Name for the right table on the diagram (leave empty to use table name) # circle2Color Color for the right-top circle on the diagram # table3Path Table which will be represented as center-bottom circle # table3Name Name for the center table on the diagram (leave empty to use table name) # circle3Color Color for the center-bottom circle on the diagram # simple All circles has equal radius # output Folder name to store the results # mappedNearbyGenePath <- paste0 ( folderPath , \"/jurkat_chipseq_hg38 Genes\" ) mealrTopVennPath <- paste0 ( mealrTopPath , \" Venn\" ) # Intersect factors identified by MEALR and genes with nearby TAL1 ChIP-seq # sites gx.analysis ( \"Venn diagrams\" , list ( table1Path = mappedNearbyGenePath , table1Name = \"Genes near TAL1 sites\" , table2Path = mealrTopGenePath , table2Name = \"MEALR transcription factors\" , simple = TRUE , output = mealrTopVennPath ), TRUE , TRUE ) # # Step 9. Prediction of binding sites of identified TFs in TAL1-bound genomic regions # grnFactorPath <- paste0 ( mealrTopVennPath , \"/Rows present in both tables\" ) # Load potential GRN factors into R data frame tfs <- gx.get ( grnFactorPath ) # tfs # Gene symbol jurkat_chipseq_hg38: Count # ENSG00000081059 TCF7 1 # ENSG00000118513 MYB 1 # ENSG00000124813 RUNX2 4 # ENSG00000125952 MAX 2 # ENSG00000138795 LEF1 2 # ENSG00000157554 ERG 1 # ENSG00000159216 RUNX1 4 # ENSG00000179348 GATA2 1 # Site model ID Coefficient # ENSG00000081059 V$TCF1_09 0.05875131 # ENSG00000118513 V$CMYB_01 0.02749087 # ENSG00000124813 V$AML_Q6,V$OSF2_Q6,V$RUNX2_03,V$RUNX2_04 0.08663064 # ENSG00000125952 V$MYCMAX_01 0.02998472 # ENSG00000138795 V$LEF1_10,V$LEF1_17 0.03285110 # ENSG00000157554 V$ERG_07 0.04488260 # ENSG00000159216 V$AML1_02,V$AML_Q6 0.08663064 # ENSG00000179348 V$GATA2_09 0.04911769 # # Extract PWM ids grnPwms <- unlist ( strsplit ( tfs [, 3 ], \",\" , fixed = TRUE )) # Create PWM table for import write.table ( cbind ( PWM = grnPwms , Num = 1 : length ( grnPwms )), file = \"grn_pwms.tsv\" , quote = FALSE , sep = \"\\t\" , row.names = FALSE ) # Import PWM table gx.importTable ( \"grn_pwms.tsv\" , mealrOutputPath , \"MEALR_positive_coefficients Top 50 GRN PWMs\" , columnForID = \"PWM\" , tableType = \"Matrices: TRANSFAC\" , species = species ) # After data imports it is recommendable to shortly pause in order to # allow server processes to finish before using the data Sys.sleep ( 1 ) grnPwmPath <- paste0 ( mealrOutputPath , \"/MEALR_positive_coefficients Top 50 GRN PWMs\" ) gx.analysis.parameters ( \"Create profile from site model table\" ) # # Output # description # table Table containing site models as row names # profile Profile to copy the values from # thresholdsColumn Column containing cutoff values (use 'none' to copy cutoffs from the profile) # outputProfile Specify the path whether to store output profile # transfacProfile <- \"databases/TRANSFAC(R) 2022.1/Data/profiles/vertebrate_human_p0.001_non3d\" grnPwmProfile <- paste0 ( grnPwmPath , \" profile\" ) # Create Match(TM) profile for PWMs of potential GRN factors gx.analysis ( \"Create profile from site model table\" , list ( table = grnPwmPath , profile = transfacProfile , outputProfile = grnPwmProfile ), TRUE , TRUE ) gx.analysis.parameters ( \"TRANSFAC(R) Match(TM) for tracks\" ) # # Output # description # sequencePath Sequence track to search # dbSelector Select a deployed or custom sequence source # profilePath Profile # withoutDuplicates Ensure to report sites in overlapping genomic intervals only once # ignoreCore Core scores are not calculated and not used for filtering. # output Output track path # grnMatchPath <- paste0 ( grnPwmProfile , \" Match\" ) # Predict binding sites of GRN factors in TAL1-bound regions gx.analysis ( \"TRANSFAC(R) Match(TM) for tracks\" , list ( sequencePath = paste0 ( folderPath , \"/jurkat_chipseq_hg38\" ), dbSelector = \"Ensembl 104.38 Human (hg38)\" , profilePath = grnPwmProfile , withoutDuplicates = TRUE , ignoreCore = TRUE , output = grnMatchPath ), TRUE , TRUE ) # # Step 10. Prediction of binding sites of identified TFs around TAL1 transcription start site # # Create TAL1 gene table for import write.table ( cbind ( ID = c ( \"ENSG00000162367\" ), Symbol = c ( \"TAL1\" )), file = \"tal1.tsv\" , quote = FALSE , sep = \"\\t\" , row.names = FALSE ) # Import TAL1 gene gx.importTable ( \"tal1.tsv\" , mealrOutputPath , \"TAL1 gene\" , columnForID = \"ID\" , tableType = \"Genes: Ensembl\" , species = species ) # After data imports it is recommendable to shortly pause in order to # allow server processes to finish before using the data Sys.sleep ( 1 ) tal1GenePath <- paste0 ( mealrOutputPath , \"/TAL1 gene\" ) gx.analysis.parameters ( \"Gene set to track\" ) # # Output # description # sourcePath Table of source genes # species Taxonomical species # from From position (relative to gene start) # to To position (relative to gene start) # overlapMergingMode How to handle TSS located close to each other # destPath Output name # tal1TrackPath <- paste0 ( tal1GenePath , \" promoter\" ) # Create track of genomic region around TAL1 TSS (promoter) gx.analysis ( \"Gene set to track\" , list ( sourcePath = tal1GenePath , species = species , from = 2000 , to = 1000 , destPath = tal1TrackPath ), TRUE , TRUE ) tal1MatchPath <- paste0 ( grnPwmProfile , \" TAL1 Match\" ) # Predict binding sites of GRN factors in TAL1 promoter gx.analysis ( \"TRANSFAC(R) Match(TM) for tracks\" , list ( sequencePath = tal1TrackPath , dbSelector = \"Ensembl 104.38 Human (hg38)\" , profilePath = grnPwmProfile , withoutDuplicates = TRUE , ignoreCore = TRUE , output = tal1MatchPath ), TRUE , TRUE ) # Export genomic locations of predicted sites for GRN factors around TAL1 TSS gx.export ( tal1MatchPath , exporter = \"BED format (*.bed)\" , target.file = \"TAL1_grn_pwm_sites.bed\" ) gx.logout ()","title":"R code for the tutorial"},{"location":"first_example.html","text":"A first example analysis - Enrichment of gene functions in a gene set Example overview The analysis consists of the following steps. Prepare a project and a data folder in the platform workspace as a container for analysis data and results Upload a gene set Analyze enrichment of gene function using the Functional classification tool Platform tool parameters Platform tools typically require a set of input parameters, e.g. path of input data, a path for result output, species selection. The APIs provide functions to gather information about available input options for analysis tools as well as for import and export functions. Here we show how to use the genexplain-api commandline tool parameters to obtain information about the Functional classification platform tool that is going to be applied to calculate gene functional enrichment in this example analysis. The console command to run the tool looks as follows. The command invokes the jar package of genexplain-api with the name of the parameters tool followed by the path of a JSON file. 1 java -jar genexplain-api.jar parameters funclass_parameter_listing.json The JSON file contains a single JSON object with four properties server , user , password and tools . The first three properties configure the platform server to connect with as well as username and password which need to be replaced with valid account credentials on that server. The tools list contains the name(s) of platform tools for which the program shall fetch parameter information. 1 2 3 4 5 6 { \"server\" : \"https://platform.genexplain.com\" , \"user\" : \"someuser@email.io\" , \"password\" : \"12345\" , \"tools\" : [ \"Functional classification\" ] } The output is printed to standard output (optionally, an additional JSON parameter outfile can be provided to specify a local output file) and is (partially) shown below. It consists of a JSON object with one property for each platform tool that was specified in the tools list. The input options of a platform tool are contained in a JSON array, each represented by an object describing the input option. The order of input parameters in this array is the same as in the graphical web interface. The displayName property shows the parameter title that appears in the graphical web interface. However, the parameter name that needs to be specified in an API call is the name property. E.g. the first parameter with displayName Source data set has the name sourcePath . The latter needs to be used in function calls. An input option object provides further valuable information such as the type of data that is expected. E.g. the Source data set needs to be provided as a type data-element-path , which means a path for a data element in the platform workspace, the data element on that path must be a table ( elementClass ...TableDataCollection ), and the table row names must be Ensembl ids. If an input option expects a value from a predefined list, the available values to select are also listed. E.g. the second option Species expects one of the species strings listed in dictionary and the default value is given in value ( Human (Homo sapiens) ). The geneXplainR method to fetch parameter information for platform tools is implemented in the function gx.analysis.parameters . However, the parameters commandline tool provides more details about each input option. Therefore, we recommend its use also for geneXplainR projects. Output for the Functional classification tool 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 { \"Functional classification\" : [ { \"displayName\" : \"Source data set\" , \"icon\" : \"biouml.plugins.ensembl:biouml/plugins/ensembl/tabletype/resources/genes-ensembl.gif\" , \"description\" : \"Input table having Ensembl genes as rows.\" , \"referenceType\" : \"Genes: Ensembl\" , \"readOnly\" : false , \"type\" : \"data-element-path\" , \"canBeNull\" : false , \"promptOverwrite\" : false , \"name\" : \"sourcePath\" , \"elementClass\" : \"ru.biosoft.table.TableDataCollection\" , \"value\" : \"(select element)\" , \"elementMustExist\" : true , \"multiSelect\" : false }, { \"dictionary\" : [ [ \"Human (Homo sapiens)\" , \"Human (Homo sapiens)\" ], [ \"Mouse (Mus musculus)\" , \"Mouse (Mus musculus)\" ], [ \"Rat (Rattus norvegicus)\" , \"Rat (Rattus norvegicus)\" ], [ \"Baker's yeast (Saccharomyces cerevisiae)\" , \"Baker's yeast (Saccharomyces cerevisiae)\" ], [ \"Fission yeast (Schizosaccharomyces pombe)\" , \"Fission yeast (Schizosaccharomyces pombe)\" ] ], \"displayName\" : \"Species\" , \"name\" : \"species\" , \"description\" : \"Species corresponding to the input table.\" , \"readOnly\" : false , \"type\" : \"code-string\" , \"value\" : \"Human (Homo sapiens)\" }, { \"dictionary\" : [ [ \"Full gene ontology classification\" , \"Full gene ontology classification\" ], [ \"GO (biological process)\" , \"GO (biological process)\" ], [ \"GO (cellular component)\" , \"GO (cellular component)\" ], [ \"GO (molecular function)\" , \"GO (molecular function)\" ], [ \"HumanCyc pathways\" , \"HumanCyc pathways\" ], [ \"HumanPSD(TM) GO (biological process) (2022.1)\" , \"HumanPSD(TM) GO (biological process) (2022.1)\" ], [ \"HumanPSD(TM) disease (2022.1)\" , \"HumanPSD(TM) disease (2022.1)\" ], [ \"Reactome pathways (74)\" , \"Reactome pathways (74)\" ], [ \"TF classification\" , \"TF classification\" ], [ \"TRANSPATH Pathways (2022.1)\" , \"TRANSPATH Pathways (2022.1)\" ], [ \"Repository folder\" , \"Repository folder\" ] ], \"displayName\" : \"Classification\" , \"name\" : \"bioHub\" , \"description\" : \"Classification you want to use. List of classifications may differ depending on software version and your subscription. Use 'Repository folder' for custom classification.\" , \"readOnly\" : false , \"type\" : \"code-string\" , \"value\" : \"Full gene ontology classification\" }, { \"displayName\" : \"Minimal hits to group\" , \"name\" : \"minHits\" , \"description\" : \"Groups with lower number of hits will be filtered out (nmin)\" , \"readOnly\" : false , \"type\" : \"code-string\" , \"value\" : \"2\" }, { \"displayName\" : \"Only over-represented\" , \"name\" : \"onlyOverrepresented\" , \"description\" : \"If checked, under-represented groups will be excluded from the result\" , \"readOnly\" : false , \"type\" : \"bool\" , \"value\" : \"true\" }, { \"displayName\" : \"P-value threshold\" , \"name\" : \"pvalueThreshold\" , \"description\" : \"P-value threshold (Pmax)\" , \"readOnly\" : false , \"type\" : \"code-string\" , \"value\" : \"0.05\" }, { \"auto\" : \"on\" , \"displayName\" : \"Result name\" , \"icon\" : \"biouml.plugins.enrichment:biouml/plugins/enrichment/resources/classify.gif\" , \"description\" : \"Name and path for the resulting table\" , \"readOnly\" : false , \"type\" : \"data-element-path\" , \"canBeNull\" : false , \"promptOverwrite\" : false , \"name\" : \"outputTable\" , \"elementClass\" : \"ru.biosoft.table.TableDataCollection\" , \"value\" : \"(select element)\" , \"elementMustExist\" : false , \"multiSelect\" : false } ] } Functional classification using geneXplainR The R code of this section is provided with the tutorial material as first_example.R . Please note that some parts require editing before running the script, including username, password, project name. Folder preparation In the R script we firstly load the geneXplainR library and log into a geneXplain platform account. Then we prepare a project as well as a data folder for the analysis files. The following source code also shows the function gx.ls that lists the data elements of a specified folder. The data/Projects path contains all projects and associated data folders. The path of a data folder within a project follows the pattern data/Projects/<project name>/Data/<folder name> . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 library ( geneXplainR ) # Username (email) and password need to be replaced with valid credentials. # gx.login ( \"https://platform.genexplain.com\" , \"someuser@email.io\" , \"12345\" ) # The gx.ls function returns a listing of the specified workspace folder. # gx.ls ( \"data/Projects\" ) # The project name has to be unique on the connected platform server. # apiProjectName <- \"api2022_tutorial\" apiProjectPath <- paste0 ( \"data/Projects/\" , apiProjectName ) # The gx.createProject function returns an error if the project already # exists. # gx.createProject ( apiProjectName , description = \"API 2022 tutorial project\" ) funclassFolder <- \"first_example_functional_class\" folderPath <- paste0 ( apiProjectPath , \"Data/\" , funclassFolder ) # The gx.createFolder function creates the folder if it does not # already exist. # gx.createFolder ( paste0 ( apiProjectPath , \"Data\" ), funclassFolder ) Data upload We import the gene list file using the gx.importTable function. This is a specialized function for tabular data. The gx.import function can be used to import many different data types and formats. The gx.importers function shows available importers and the gx.import.parameters function provides information about importer parameters. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 species <- \"Human (Homo sapiens)\" dataName <- \"funclass_genes_covid-19\" # The gx.importers function returns a list of available importers # for different data types. # gx.importers () # The available parameters for a specific importer and a destination # folder can be interrogated using the gx.import.parameters function. # gx.import.parameters ( folderPath , \"Tabular (*.txt, *.xls, *.tab, etc.)\" ) # The geneXplainR library provides a specialized function to import tabular # data files. # gx.importTable ( \"../data/functional_classification_genes_GSE156063.tsv\" , folderPath , dataName , columnForID = \"ID\" , tableType = \"Genes: Ensembl\" , species = species ) # This is the platform workspace path of the imported data. # funclassGenePath <- paste0 ( folderPath , \"/\" , dataName ) Functional classification The Functional classification analysis is invoked by the gx.analysis function. Information about the elements of the parameter list can be obtained by the parameters command line tool described above or the gx.analyis.parameters . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 funclassResultPath <- paste0 ( funclassGenePath , \" GO\" ) # The gx.analysis.parameters function shows input option names and # descriptions for a specified platform tool. # gx.analyis.parameters ( \"Functional classification\" ) # The gx.analysis function submits analysis tasks to the connected # platform server. # gx.analysis ( \"Functional classification\" , list ( sourcePath = funclassGenePath , species = species , bioHub = \"Full gene ontology classification\" , minHits = 1 , pvalueThreshold = 1 , outputTable = funclassResultPath )) # The gx.get function loads data tables from the platform workspace into # a data frame. # funclassResult <- gx.get ( funclassResultPath ) head ( funclassResult ) Functional classification using genexplain-api Getting importer types and platform tool parameters The workflow of this example analysis requires uploading a gene list into a platform workspace. The gene list is then analyzed using a platform analysis tool. Therefore, we need to know how to import our gene list and which parameters are needed for the import process as well as for the subsequent analysis. While in the case of this specific analysis we can make use of a dedicated method to import of tabular data, here we demonstrate how to find out about importers and their parameters as well as the input parameters for the Functional classification tool using genexplain-api library methods. Importers are platform functions that import specific data types and formats, e.g. tabular data stored in a text file, into a platform workspace. The list of available importers is extracted using the listImporters method of the client object, whereas its getImporterParameters method returns information about parameters of a specific importer, in this the importer for tabular data. Finally, the getAnalysisParameters method retrieves input option specifications for the analysis tool from the connected platform server. The code of this section is provided with the tutorial material as ToolParameters.java . Please note that some parts require editing before running the program, including username, password, project name. The Java class can be compiled and executed with commands like the following. 1 2 javac -cp .:genexplain-api.jar ToolParameters.java java -cp .:genexplain-api.jar ToolParameters 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 import com.eclipsesource.json.JsonValue ; import com.eclipsesource.json.JsonObject ; import com.eclipsesource.json.PrettyPrint ; import com.genexplain.api.core.GxHttpClient ; import com.genexplain.api.core.GxHttpClientImpl ; import com.genexplain.api.core.GxHttpConnection ; import com.genexplain.api.core.GxHttpConnectionImpl ; import java.io.StringWriter ; import java.io.Writer ; public class ToolParameters { public static void main ( String [] args ) throws Exception { // The GxHttpConnectionImpl holds the connection to the specified // platform server. Username and password need to correspond to a // valid account on that server. // GxHttpConnectionImpl con = new GxHttpConnectionImpl (); con . setServer ( \"https://platform.genexplain.com\" ); con . setUsername ( \"someuser@email.io\" ); con . setPassword ( \"12345\" ); con . setVerbose ( true ); con . login (); // The connection is given to a client object. The client is the // main component to interact with the connected platform server. // GxHttpClientImpl client = new GxHttpClientImpl (); client . setConnection ( con ); System . out . println ( \"--- Available importers ---\" ); // The listImporters method returns a JSON object with the list // of importers contained in the \"values\" array. // JsonObject importers = client . listImporters (); for ( JsonValue imp : importers . get ( \"values\" ). asArray ()) { System . out . println ( imp . asString ()); } System . out . println ( \"--- Importer parameters ---\" ); // The getImporterParameters method returns a JSON object // containing a description of importer parameters. The // importer parameters are requested for a target folder. // JsonObject importParams = client . getImporterParameters ( \"data/Projects/api2022_tutorial/Data/first_example_functional_class\" , \"Tabular (*.txt, *.xls, *.tab, etc.)\" ); Writer writer = new StringWriter (); importParams . writeTo ( writer , PrettyPrint . indentWithSpaces ( 4 )); System . out . println ( writer . toString ()); System . out . println ( \"--- Functional classification parameters ---\" ); // The getAnalysisParameters method returns a JSON object // containing a description of analysis tool parameters. // JsonObject funClassParams = client . getAnalysisParameters ( \"Functional classification\" ); Writer writer = new StringWriter (); funClassParams . writeTo ( writer , PrettyPrint . indentWithSpaces ( 4 )); System . out . println ( writer . toString ()); con . logout (); } } Java program for functional classification The code of this section is provided with the tutorial material as FirstExample.java . Please note that some parts require editing before running the program, including username, password, project name. The Java class can be compiled and executed with commands like the following. 1 2 javac -cp .:genexplain-api.jar FirstExample.java java -cp .:genexplain-api.jar FirstExample In the Java program we import the core classes and interfaces from com.genexplain.api.core and log into a geneXplain platform account. Then we prepare a project as well as a data folder for the analysis files. The data/Projects path contains all projects and associated data folders. The path of a data folder within a project follows the pattern data/Projects/<project name>/Data/<folder name> . We import the gene list file using the importTable function. This is a specialized function for tabular data. The Functional classification analysis is invoked by the analyze method of the client. Information about the elements of the parameter object can be obtained by the parameters command line tool described above or as shown here . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 import com.eclipsesource.json.JsonValue ; import com.eclipsesource.json.JsonObject ; import com.eclipsesource.json.PrettyPrint ; import com.genexplain.api.core.GxHttpClient ; import com.genexplain.api.core.GxHttpClientImpl ; import com.genexplain.api.core.GxHttpConnection ; import com.genexplain.api.core.GxHttpConnectionImpl ; import java.io.StringWriter ; import java.io.Writer ; public class FirstExample { public static void main ( String [] args ) throws Exception { // The GxHttpConnectionImpl holds the connection to the specified // platform server. Username and password need to correspond to a // valid account on that server. // GxHttpConnectionImpl con = new GxHttpConnectionImpl (); con . setServer ( \"https://platform.genexplain.com\" ); con . setUsername ( \"someuser@email.io\" ); con . setPassword ( \"12345\" ); con . setVerbose ( true ); con . login (); // The connection is given to a client object. The client is the // main component to interact with the connected platform server. // GxHttpClientImpl client = new GxHttpClientImpl (); client . setConnection ( con ); // The createProject method creates a new project in the user // workspace. The project name must be new and unique on the // platform instance. The platform path of the new project is // \"data/Projects/<project name>\". // Map < String , String > projectParams = new HashMap <> (); projectParams . put ( \"user\" , \"someuser@email.io\" ); projectParams . put ( \"pass\" , \"12345\" ); projectParams . put ( \"project\" , \"api2022_tutorial\" ); projectParams . put ( \"description\" , \"API 2022 tutorial project\" ); client . createProject ( projectParams ) // The createFolder function creates the folder if it does not // already exist. // client . createFolder ( \"data/Projects/api2022_tutorial/Data\" , \"first_example_functional_class\" ); // The API provides for a specialized method to import tabular // data. // client . importTable ( \"../data/functional_classification_genes_GSE156063.tsv\" , \"data/Projects/api2022_tutorial/Data/first_example_functional_class\" , \"funclass_genes_covid-19\" , false , GxHttpClient . ColumnDelimiter . Tab , 1 , 2 , \"\" , \"ID\" , false , \"Genes: Ensembl\" , \"Human (Homo sapiens)\" ); // After data import it is often advisable to let background // processes on the server finish their work, before proceeding // with analyzing the uploaded data. // Thread . sleep ( 1000 ); // The analyze function submits analysis tasks to the connected // platform server. // JsonObject params = new JsonObject () . add ( \"sourcePath\" , \"data/Projects/api2022_tutorial/Data/first_example_functional_class/funclass_genes_covid-19\" ) . add ( \"species\" , \"Human (Homo sapiens)\" ) . add ( \"bioHub\" , \"Full gene ontology classification\" ) . add ( \"minHits\" , 1 ) . add ( \"pvalueThreshold\" , 1 ) . add ( \"outputTable\" , \"data/Projects/api2022_tutorial/Data/first_example_functional_class/funclass_genes_covid-19 GO\" ); client . analyze ( \"Functional classification\" , params , false , true , true ); con . logout (); } } Functional classification using the commandline Commandline and JSON The exec application, provided by the genexplain-api JAR package, is invoked with a configuration file in JSON format. 1 java -jar genexplain-api.jar exec first_example.json The content of the JSON file to run the example analysis workflow (named first_example.json in the example above) is shown below . It contains a JSON object with server, username and password parameters as well as a task list. Please note that server , user , password as well as the project name ( api2022_tutorial used as example) need to be replaced with proper values. The reconnect property instructs the program to try to reconnect in case of interruption. The JSON configuration is provided with the tutorial material as first_example.json . Please note that some parts require editing before running the program, including username, password, project name. The tasks property is a JSON array with the sequence of tasks that exec shall perform. Each task is described by an object that firstly defines an executor using the do property. The exec application has a set of executors for different kinds of tasks which typically resemble functions and methods of the R and Java APIs. The executors are described in detail here . The example functional classification analysis uses four executors. The createFolder executor creates a folder named first_example_functional_class within the api2022_tutorial project. The imPort executor imports the gene list file into the analysis folder. After the import, external executes an external script to wait for one second, in order to allow background processes on the platform server to finish their work before proceeding with the analysis. The analyze executor invokes the platform tool Functional classification . The script invoked by external is a simple shell script: 1 2 3 #/bin/sh sleep 1 Information about the parameters required for importers and analysis tools can be obtained using the import and parameters applications, respectively, Another options is to use the itemParameters executor with exec . The list of available platform tools is provided by apps or by the listItems executor of exec . 1 2 3 java -jar genexplain-api.jar import ( ... ) java -jar genexplain-api.jar parameters ( ... ) java -jar genexplain-api.jar apps ( ... ) JSON configuration file for functional classification 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 { \"server\" : \"https://platform.genexplain.com\" , \"user\" : \"someuser@email.io\" , \"password\" : \"12345\" , \"reconnect\" : true , \"tasks\" : [ { \"do\" : \"createFolder\" , \"showOutput\" : true , \"path\" : \"data/Projects/api2022_tutorial/Data\" , \"name\" : \"first_example_functional_class\" }, { \"do\" : \"imPort\" , \"file\" : \"../data/functional_classification_genes_GSE156063.tsv\" , \"path\" : \"data/Projects/api2022_tutorial/Data/first_example_functional_class\" , \"importer\" : \"Tabular (*.txt, *.xls, *.tab, etc.)\" , \"parameters\" : { \"columnForID\" : \"ID\" , \"tableType\" : \"Genes: Ensembl\" , \"species\" : \"Human (Homo sapiens)\" } }, { \"do\" : \"external\" , \"showOutput\" : true , \"bin\" : \"sh\" , \"params\" : [ \"waitns.sh\" ] }, { \"do\" : \"analyze\" , \"method\" : \"Functional classification\" , \"verbose\" : true , \"parameters\" : { \"sourcePath\" : \"data/Projects/api2022_tutorial/Data/first_example_functional_class/functional_classification_genes_GSE156063\" , \"species\" : \"Human (Homo sapiens)\" , \"bioHub\" : \"Full gene ontology classification\" , \"minHits\" : 1 , \"pvalueThreshold\" : 1 , \"outputTable\" : \"data/Projects/api2022_tutorial/Data/first_example_functional_class/functional_classification_genes_GSE156063 GO\" } } ] }","title":"A first example&#58; Enrichment of gene functions in a gene set"},{"location":"first_example.html#a-first-example-analysis-enrichment-of-gene-functions-in-a-gene-set","text":"","title":"A first example analysis - Enrichment of gene functions in a gene set"},{"location":"first_example.html#example-overview","text":"The analysis consists of the following steps. Prepare a project and a data folder in the platform workspace as a container for analysis data and results Upload a gene set Analyze enrichment of gene function using the Functional classification tool","title":"Example overview"},{"location":"first_example.html#platform-tool-parameters","text":"Platform tools typically require a set of input parameters, e.g. path of input data, a path for result output, species selection. The APIs provide functions to gather information about available input options for analysis tools as well as for import and export functions. Here we show how to use the genexplain-api commandline tool parameters to obtain information about the Functional classification platform tool that is going to be applied to calculate gene functional enrichment in this example analysis. The console command to run the tool looks as follows. The command invokes the jar package of genexplain-api with the name of the parameters tool followed by the path of a JSON file. 1 java -jar genexplain-api.jar parameters funclass_parameter_listing.json The JSON file contains a single JSON object with four properties server , user , password and tools . The first three properties configure the platform server to connect with as well as username and password which need to be replaced with valid account credentials on that server. The tools list contains the name(s) of platform tools for which the program shall fetch parameter information. 1 2 3 4 5 6 { \"server\" : \"https://platform.genexplain.com\" , \"user\" : \"someuser@email.io\" , \"password\" : \"12345\" , \"tools\" : [ \"Functional classification\" ] } The output is printed to standard output (optionally, an additional JSON parameter outfile can be provided to specify a local output file) and is (partially) shown below. It consists of a JSON object with one property for each platform tool that was specified in the tools list. The input options of a platform tool are contained in a JSON array, each represented by an object describing the input option. The order of input parameters in this array is the same as in the graphical web interface. The displayName property shows the parameter title that appears in the graphical web interface. However, the parameter name that needs to be specified in an API call is the name property. E.g. the first parameter with displayName Source data set has the name sourcePath . The latter needs to be used in function calls. An input option object provides further valuable information such as the type of data that is expected. E.g. the Source data set needs to be provided as a type data-element-path , which means a path for a data element in the platform workspace, the data element on that path must be a table ( elementClass ...TableDataCollection ), and the table row names must be Ensembl ids. If an input option expects a value from a predefined list, the available values to select are also listed. E.g. the second option Species expects one of the species strings listed in dictionary and the default value is given in value ( Human (Homo sapiens) ). The geneXplainR method to fetch parameter information for platform tools is implemented in the function gx.analysis.parameters . However, the parameters commandline tool provides more details about each input option. Therefore, we recommend its use also for geneXplainR projects.","title":"Platform tool parameters"},{"location":"first_example.html#output-for-the-functional-classification-tool","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 { \"Functional classification\" : [ { \"displayName\" : \"Source data set\" , \"icon\" : \"biouml.plugins.ensembl:biouml/plugins/ensembl/tabletype/resources/genes-ensembl.gif\" , \"description\" : \"Input table having Ensembl genes as rows.\" , \"referenceType\" : \"Genes: Ensembl\" , \"readOnly\" : false , \"type\" : \"data-element-path\" , \"canBeNull\" : false , \"promptOverwrite\" : false , \"name\" : \"sourcePath\" , \"elementClass\" : \"ru.biosoft.table.TableDataCollection\" , \"value\" : \"(select element)\" , \"elementMustExist\" : true , \"multiSelect\" : false }, { \"dictionary\" : [ [ \"Human (Homo sapiens)\" , \"Human (Homo sapiens)\" ], [ \"Mouse (Mus musculus)\" , \"Mouse (Mus musculus)\" ], [ \"Rat (Rattus norvegicus)\" , \"Rat (Rattus norvegicus)\" ], [ \"Baker's yeast (Saccharomyces cerevisiae)\" , \"Baker's yeast (Saccharomyces cerevisiae)\" ], [ \"Fission yeast (Schizosaccharomyces pombe)\" , \"Fission yeast (Schizosaccharomyces pombe)\" ] ], \"displayName\" : \"Species\" , \"name\" : \"species\" , \"description\" : \"Species corresponding to the input table.\" , \"readOnly\" : false , \"type\" : \"code-string\" , \"value\" : \"Human (Homo sapiens)\" }, { \"dictionary\" : [ [ \"Full gene ontology classification\" , \"Full gene ontology classification\" ], [ \"GO (biological process)\" , \"GO (biological process)\" ], [ \"GO (cellular component)\" , \"GO (cellular component)\" ], [ \"GO (molecular function)\" , \"GO (molecular function)\" ], [ \"HumanCyc pathways\" , \"HumanCyc pathways\" ], [ \"HumanPSD(TM) GO (biological process) (2022.1)\" , \"HumanPSD(TM) GO (biological process) (2022.1)\" ], [ \"HumanPSD(TM) disease (2022.1)\" , \"HumanPSD(TM) disease (2022.1)\" ], [ \"Reactome pathways (74)\" , \"Reactome pathways (74)\" ], [ \"TF classification\" , \"TF classification\" ], [ \"TRANSPATH Pathways (2022.1)\" , \"TRANSPATH Pathways (2022.1)\" ], [ \"Repository folder\" , \"Repository folder\" ] ], \"displayName\" : \"Classification\" , \"name\" : \"bioHub\" , \"description\" : \"Classification you want to use. List of classifications may differ depending on software version and your subscription. Use 'Repository folder' for custom classification.\" , \"readOnly\" : false , \"type\" : \"code-string\" , \"value\" : \"Full gene ontology classification\" }, { \"displayName\" : \"Minimal hits to group\" , \"name\" : \"minHits\" , \"description\" : \"Groups with lower number of hits will be filtered out (nmin)\" , \"readOnly\" : false , \"type\" : \"code-string\" , \"value\" : \"2\" }, { \"displayName\" : \"Only over-represented\" , \"name\" : \"onlyOverrepresented\" , \"description\" : \"If checked, under-represented groups will be excluded from the result\" , \"readOnly\" : false , \"type\" : \"bool\" , \"value\" : \"true\" }, { \"displayName\" : \"P-value threshold\" , \"name\" : \"pvalueThreshold\" , \"description\" : \"P-value threshold (Pmax)\" , \"readOnly\" : false , \"type\" : \"code-string\" , \"value\" : \"0.05\" }, { \"auto\" : \"on\" , \"displayName\" : \"Result name\" , \"icon\" : \"biouml.plugins.enrichment:biouml/plugins/enrichment/resources/classify.gif\" , \"description\" : \"Name and path for the resulting table\" , \"readOnly\" : false , \"type\" : \"data-element-path\" , \"canBeNull\" : false , \"promptOverwrite\" : false , \"name\" : \"outputTable\" , \"elementClass\" : \"ru.biosoft.table.TableDataCollection\" , \"value\" : \"(select element)\" , \"elementMustExist\" : false , \"multiSelect\" : false } ] }","title":"Output for the Functional classification tool"},{"location":"first_example.html#functional-classification-using-genexplainr","text":"The R code of this section is provided with the tutorial material as first_example.R . Please note that some parts require editing before running the script, including username, password, project name.","title":"Functional classification using geneXplainR"},{"location":"first_example.html#folder-preparation","text":"In the R script we firstly load the geneXplainR library and log into a geneXplain platform account. Then we prepare a project as well as a data folder for the analysis files. The following source code also shows the function gx.ls that lists the data elements of a specified folder. The data/Projects path contains all projects and associated data folders. The path of a data folder within a project follows the pattern data/Projects/<project name>/Data/<folder name> . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 library ( geneXplainR ) # Username (email) and password need to be replaced with valid credentials. # gx.login ( \"https://platform.genexplain.com\" , \"someuser@email.io\" , \"12345\" ) # The gx.ls function returns a listing of the specified workspace folder. # gx.ls ( \"data/Projects\" ) # The project name has to be unique on the connected platform server. # apiProjectName <- \"api2022_tutorial\" apiProjectPath <- paste0 ( \"data/Projects/\" , apiProjectName ) # The gx.createProject function returns an error if the project already # exists. # gx.createProject ( apiProjectName , description = \"API 2022 tutorial project\" ) funclassFolder <- \"first_example_functional_class\" folderPath <- paste0 ( apiProjectPath , \"Data/\" , funclassFolder ) # The gx.createFolder function creates the folder if it does not # already exist. # gx.createFolder ( paste0 ( apiProjectPath , \"Data\" ), funclassFolder )","title":"Folder preparation"},{"location":"first_example.html#data-upload","text":"We import the gene list file using the gx.importTable function. This is a specialized function for tabular data. The gx.import function can be used to import many different data types and formats. The gx.importers function shows available importers and the gx.import.parameters function provides information about importer parameters. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 species <- \"Human (Homo sapiens)\" dataName <- \"funclass_genes_covid-19\" # The gx.importers function returns a list of available importers # for different data types. # gx.importers () # The available parameters for a specific importer and a destination # folder can be interrogated using the gx.import.parameters function. # gx.import.parameters ( folderPath , \"Tabular (*.txt, *.xls, *.tab, etc.)\" ) # The geneXplainR library provides a specialized function to import tabular # data files. # gx.importTable ( \"../data/functional_classification_genes_GSE156063.tsv\" , folderPath , dataName , columnForID = \"ID\" , tableType = \"Genes: Ensembl\" , species = species ) # This is the platform workspace path of the imported data. # funclassGenePath <- paste0 ( folderPath , \"/\" , dataName )","title":"Data upload"},{"location":"first_example.html#functional-classification","text":"The Functional classification analysis is invoked by the gx.analysis function. Information about the elements of the parameter list can be obtained by the parameters command line tool described above or the gx.analyis.parameters . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 funclassResultPath <- paste0 ( funclassGenePath , \" GO\" ) # The gx.analysis.parameters function shows input option names and # descriptions for a specified platform tool. # gx.analyis.parameters ( \"Functional classification\" ) # The gx.analysis function submits analysis tasks to the connected # platform server. # gx.analysis ( \"Functional classification\" , list ( sourcePath = funclassGenePath , species = species , bioHub = \"Full gene ontology classification\" , minHits = 1 , pvalueThreshold = 1 , outputTable = funclassResultPath )) # The gx.get function loads data tables from the platform workspace into # a data frame. # funclassResult <- gx.get ( funclassResultPath ) head ( funclassResult )","title":"Functional classification"},{"location":"first_example.html#functional-classification-using-genexplain-api","text":"","title":"Functional classification using genexplain-api"},{"location":"first_example.html#getting-importer-types-and-platform-tool-parameters","text":"The workflow of this example analysis requires uploading a gene list into a platform workspace. The gene list is then analyzed using a platform analysis tool. Therefore, we need to know how to import our gene list and which parameters are needed for the import process as well as for the subsequent analysis. While in the case of this specific analysis we can make use of a dedicated method to import of tabular data, here we demonstrate how to find out about importers and their parameters as well as the input parameters for the Functional classification tool using genexplain-api library methods. Importers are platform functions that import specific data types and formats, e.g. tabular data stored in a text file, into a platform workspace. The list of available importers is extracted using the listImporters method of the client object, whereas its getImporterParameters method returns information about parameters of a specific importer, in this the importer for tabular data. Finally, the getAnalysisParameters method retrieves input option specifications for the analysis tool from the connected platform server. The code of this section is provided with the tutorial material as ToolParameters.java . Please note that some parts require editing before running the program, including username, password, project name. The Java class can be compiled and executed with commands like the following. 1 2 javac -cp .:genexplain-api.jar ToolParameters.java java -cp .:genexplain-api.jar ToolParameters 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 import com.eclipsesource.json.JsonValue ; import com.eclipsesource.json.JsonObject ; import com.eclipsesource.json.PrettyPrint ; import com.genexplain.api.core.GxHttpClient ; import com.genexplain.api.core.GxHttpClientImpl ; import com.genexplain.api.core.GxHttpConnection ; import com.genexplain.api.core.GxHttpConnectionImpl ; import java.io.StringWriter ; import java.io.Writer ; public class ToolParameters { public static void main ( String [] args ) throws Exception { // The GxHttpConnectionImpl holds the connection to the specified // platform server. Username and password need to correspond to a // valid account on that server. // GxHttpConnectionImpl con = new GxHttpConnectionImpl (); con . setServer ( \"https://platform.genexplain.com\" ); con . setUsername ( \"someuser@email.io\" ); con . setPassword ( \"12345\" ); con . setVerbose ( true ); con . login (); // The connection is given to a client object. The client is the // main component to interact with the connected platform server. // GxHttpClientImpl client = new GxHttpClientImpl (); client . setConnection ( con ); System . out . println ( \"--- Available importers ---\" ); // The listImporters method returns a JSON object with the list // of importers contained in the \"values\" array. // JsonObject importers = client . listImporters (); for ( JsonValue imp : importers . get ( \"values\" ). asArray ()) { System . out . println ( imp . asString ()); } System . out . println ( \"--- Importer parameters ---\" ); // The getImporterParameters method returns a JSON object // containing a description of importer parameters. The // importer parameters are requested for a target folder. // JsonObject importParams = client . getImporterParameters ( \"data/Projects/api2022_tutorial/Data/first_example_functional_class\" , \"Tabular (*.txt, *.xls, *.tab, etc.)\" ); Writer writer = new StringWriter (); importParams . writeTo ( writer , PrettyPrint . indentWithSpaces ( 4 )); System . out . println ( writer . toString ()); System . out . println ( \"--- Functional classification parameters ---\" ); // The getAnalysisParameters method returns a JSON object // containing a description of analysis tool parameters. // JsonObject funClassParams = client . getAnalysisParameters ( \"Functional classification\" ); Writer writer = new StringWriter (); funClassParams . writeTo ( writer , PrettyPrint . indentWithSpaces ( 4 )); System . out . println ( writer . toString ()); con . logout (); } }","title":"Getting importer types and platform tool parameters"},{"location":"first_example.html#java-program-for-functional-classification","text":"The code of this section is provided with the tutorial material as FirstExample.java . Please note that some parts require editing before running the program, including username, password, project name. The Java class can be compiled and executed with commands like the following. 1 2 javac -cp .:genexplain-api.jar FirstExample.java java -cp .:genexplain-api.jar FirstExample In the Java program we import the core classes and interfaces from com.genexplain.api.core and log into a geneXplain platform account. Then we prepare a project as well as a data folder for the analysis files. The data/Projects path contains all projects and associated data folders. The path of a data folder within a project follows the pattern data/Projects/<project name>/Data/<folder name> . We import the gene list file using the importTable function. This is a specialized function for tabular data. The Functional classification analysis is invoked by the analyze method of the client. Information about the elements of the parameter object can be obtained by the parameters command line tool described above or as shown here . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 import com.eclipsesource.json.JsonValue ; import com.eclipsesource.json.JsonObject ; import com.eclipsesource.json.PrettyPrint ; import com.genexplain.api.core.GxHttpClient ; import com.genexplain.api.core.GxHttpClientImpl ; import com.genexplain.api.core.GxHttpConnection ; import com.genexplain.api.core.GxHttpConnectionImpl ; import java.io.StringWriter ; import java.io.Writer ; public class FirstExample { public static void main ( String [] args ) throws Exception { // The GxHttpConnectionImpl holds the connection to the specified // platform server. Username and password need to correspond to a // valid account on that server. // GxHttpConnectionImpl con = new GxHttpConnectionImpl (); con . setServer ( \"https://platform.genexplain.com\" ); con . setUsername ( \"someuser@email.io\" ); con . setPassword ( \"12345\" ); con . setVerbose ( true ); con . login (); // The connection is given to a client object. The client is the // main component to interact with the connected platform server. // GxHttpClientImpl client = new GxHttpClientImpl (); client . setConnection ( con ); // The createProject method creates a new project in the user // workspace. The project name must be new and unique on the // platform instance. The platform path of the new project is // \"data/Projects/<project name>\". // Map < String , String > projectParams = new HashMap <> (); projectParams . put ( \"user\" , \"someuser@email.io\" ); projectParams . put ( \"pass\" , \"12345\" ); projectParams . put ( \"project\" , \"api2022_tutorial\" ); projectParams . put ( \"description\" , \"API 2022 tutorial project\" ); client . createProject ( projectParams ) // The createFolder function creates the folder if it does not // already exist. // client . createFolder ( \"data/Projects/api2022_tutorial/Data\" , \"first_example_functional_class\" ); // The API provides for a specialized method to import tabular // data. // client . importTable ( \"../data/functional_classification_genes_GSE156063.tsv\" , \"data/Projects/api2022_tutorial/Data/first_example_functional_class\" , \"funclass_genes_covid-19\" , false , GxHttpClient . ColumnDelimiter . Tab , 1 , 2 , \"\" , \"ID\" , false , \"Genes: Ensembl\" , \"Human (Homo sapiens)\" ); // After data import it is often advisable to let background // processes on the server finish their work, before proceeding // with analyzing the uploaded data. // Thread . sleep ( 1000 ); // The analyze function submits analysis tasks to the connected // platform server. // JsonObject params = new JsonObject () . add ( \"sourcePath\" , \"data/Projects/api2022_tutorial/Data/first_example_functional_class/funclass_genes_covid-19\" ) . add ( \"species\" , \"Human (Homo sapiens)\" ) . add ( \"bioHub\" , \"Full gene ontology classification\" ) . add ( \"minHits\" , 1 ) . add ( \"pvalueThreshold\" , 1 ) . add ( \"outputTable\" , \"data/Projects/api2022_tutorial/Data/first_example_functional_class/funclass_genes_covid-19 GO\" ); client . analyze ( \"Functional classification\" , params , false , true , true ); con . logout (); } }","title":"Java program for functional classification"},{"location":"first_example.html#functional-classification-using-the-commandline","text":"","title":"Functional classification using the commandline"},{"location":"first_example.html#commandline-and-json","text":"The exec application, provided by the genexplain-api JAR package, is invoked with a configuration file in JSON format. 1 java -jar genexplain-api.jar exec first_example.json The content of the JSON file to run the example analysis workflow (named first_example.json in the example above) is shown below . It contains a JSON object with server, username and password parameters as well as a task list. Please note that server , user , password as well as the project name ( api2022_tutorial used as example) need to be replaced with proper values. The reconnect property instructs the program to try to reconnect in case of interruption. The JSON configuration is provided with the tutorial material as first_example.json . Please note that some parts require editing before running the program, including username, password, project name. The tasks property is a JSON array with the sequence of tasks that exec shall perform. Each task is described by an object that firstly defines an executor using the do property. The exec application has a set of executors for different kinds of tasks which typically resemble functions and methods of the R and Java APIs. The executors are described in detail here . The example functional classification analysis uses four executors. The createFolder executor creates a folder named first_example_functional_class within the api2022_tutorial project. The imPort executor imports the gene list file into the analysis folder. After the import, external executes an external script to wait for one second, in order to allow background processes on the platform server to finish their work before proceeding with the analysis. The analyze executor invokes the platform tool Functional classification . The script invoked by external is a simple shell script: 1 2 3 #/bin/sh sleep 1 Information about the parameters required for importers and analysis tools can be obtained using the import and parameters applications, respectively, Another options is to use the itemParameters executor with exec . The list of available platform tools is provided by apps or by the listItems executor of exec . 1 2 3 java -jar genexplain-api.jar import ( ... ) java -jar genexplain-api.jar parameters ( ... ) java -jar genexplain-api.jar apps ( ... )","title":"Commandline and JSON"},{"location":"first_example.html#json-configuration-file-for-functional-classification","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 { \"server\" : \"https://platform.genexplain.com\" , \"user\" : \"someuser@email.io\" , \"password\" : \"12345\" , \"reconnect\" : true , \"tasks\" : [ { \"do\" : \"createFolder\" , \"showOutput\" : true , \"path\" : \"data/Projects/api2022_tutorial/Data\" , \"name\" : \"first_example_functional_class\" }, { \"do\" : \"imPort\" , \"file\" : \"../data/functional_classification_genes_GSE156063.tsv\" , \"path\" : \"data/Projects/api2022_tutorial/Data/first_example_functional_class\" , \"importer\" : \"Tabular (*.txt, *.xls, *.tab, etc.)\" , \"parameters\" : { \"columnForID\" : \"ID\" , \"tableType\" : \"Genes: Ensembl\" , \"species\" : \"Human (Homo sapiens)\" } }, { \"do\" : \"external\" , \"showOutput\" : true , \"bin\" : \"sh\" , \"params\" : [ \"waitns.sh\" ] }, { \"do\" : \"analyze\" , \"method\" : \"Functional classification\" , \"verbose\" : true , \"parameters\" : { \"sourcePath\" : \"data/Projects/api2022_tutorial/Data/first_example_functional_class/functional_classification_genes_GSE156063\" , \"species\" : \"Human (Homo sapiens)\" , \"bioHub\" : \"Full gene ontology classification\" , \"minHits\" : 1 , \"pvalueThreshold\" : 1 , \"outputTable\" : \"data/Projects/api2022_tutorial/Data/first_example_functional_class/functional_classification_genes_GSE156063 GO\" } } ] }","title":"JSON configuration file for functional classification"}]}